[
  {
    "job_id": "ad53f03b",
    "source": "Hadoop",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:51:19.698944+05",
    "log": "[JobID: ad53f03b] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T06:51:19.698944+05"
  },
  {
    "job_id": "d607a5be",
    "source": "Airflow",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:52:13.698944+05",
    "log": "[JobID: d607a5be] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T06:52:13.698944+05"
  },
  {
    "job_id": "14a13ec7",
    "source": "Airflow",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:52:37.698944+05",
    "log": "[JobID: 14a13ec7] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T06:52:37.698944+05"
  },
  {
    "job_id": "fe923224",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:53:07.698944+05",
    "log": "[JobID: fe923224] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T06:53:07.698944+05"
  },
  {
    "job_id": "ad53f03b",
    "source": "Hadoop",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:53:37.698944+05",
    "log": "[JobID: ad53f03b] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T06:53:37.698944+05"
  },
  {
    "job_id": "ad53f03b",
    "source": "Hadoop",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T06:54:23.698944+05",
    "log": "[JobID: ad53f03b] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T06:54:23.698944+05"
  },
  {
    "job_id": "498efd32",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:56:00.698944+05",
    "log": "[JobID: 498efd32] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T06:56:00.698944+05"
  },
  {
    "job_id": "d607a5be",
    "source": "Airflow",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:56:31.698944+05",
    "log": "[JobID: d607a5be] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T06:56:31.698944+05"
  },
  {
    "job_id": "d78858bb",
    "source": "Flink",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:56:40.698944+05",
    "log": "[JobID: d78858bb] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T06:56:40.698944+05"
  },
  {
    "job_id": "fe923224",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:56:53.698944+05",
    "log": "[JobID: fe923224] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T06:56:53.698944+05"
  },
  {
    "job_id": "498efd32",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:57:08.698944+05",
    "log": "[JobID: 498efd32] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T06:57:08.698944+05"
  },
  {
    "job_id": "ef2f6f66",
    "source": "Glue",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:57:25.698944+05",
    "log": "[JobID: ef2f6f66] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T06:57:25.698944+05"
  },
  {
    "job_id": "14a13ec7",
    "source": "Airflow",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:57:25.698944+05",
    "log": "[JobID: 14a13ec7] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T06:57:25.698944+05"
  },
  {
    "job_id": "d607a5be",
    "source": "Airflow",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T06:57:55.698944+05",
    "log": "[JobID: d607a5be] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T06:57:55.698944+05"
  },
  {
    "job_id": "498efd32",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T06:58:04.698944+05",
    "log": "[JobID: 498efd32] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T06:58:04.698944+05"
  },
  {
    "job_id": "09610c88",
    "source": "Spark",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:58:30.698944+05",
    "log": "[JobID: 09610c88] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T06:58:30.698944+05"
  },
  {
    "job_id": "d78858bb",
    "source": "Flink",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T06:58:49.698944+05",
    "log": "[JobID: d78858bb] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T06:58:49.698944+05"
  },
  {
    "job_id": "5c2d7824",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T06:59:52.698944+05",
    "log": "[JobID: 5c2d7824] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T06:59:52.698944+05"
  },
  {
    "job_id": "3dc0d33d",
    "source": "Airflow",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:00:16.698944+05",
    "log": "[JobID: 3dc0d33d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:00:16.698944+05"
  },
  {
    "job_id": "a04f9526",
    "source": "Flink",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:00:30.698944+05",
    "log": "[JobID: a04f9526] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:00:30.698944+05"
  },
  {
    "job_id": "84a55e23",
    "source": "Kafka",
    "filename": "countries10.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:00:33.698944+05",
    "log": "[JobID: 84a55e23] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:00:33.698944+05"
  },
  {
    "job_id": "fe923224",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:00:50.698944+05",
    "log": "[JobID: fe923224] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:00:50.698944+05"
  },
  {
    "job_id": "d78858bb",
    "source": "Flink",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:00:59.698944+05",
    "log": "[JobID: d78858bb] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:00:59.698944+05"
  },
  {
    "job_id": "14a13ec7",
    "source": "Airflow",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:02:04.698944+05",
    "log": "[JobID: 14a13ec7] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:02:04.698944+05"
  },
  {
    "job_id": "ef2f6f66",
    "source": "Glue",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:02:05.698944+05",
    "log": "[JobID: ef2f6f66] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:02:05.698944+05"
  },
  {
    "job_id": "a04f9526",
    "source": "Flink",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:02:19.698944+05",
    "log": "[JobID: a04f9526] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:02:19.698944+05"
  },
  {
    "job_id": "5c2d7824",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:03:04.698944+05",
    "log": "[JobID: 5c2d7824] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:03:04.698944+05"
  },
  {
    "job_id": "09610c88",
    "source": "Spark",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:03:19.698944+05",
    "log": "[JobID: 09610c88] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:03:19.698944+05"
  },
  {
    "job_id": "18013160",
    "source": "Kafka",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:03:26.698944+05",
    "log": "[JobID: 18013160] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:03:26.698944+05"
  },
  {
    "job_id": "14a13ec7",
    "source": "Airflow",
    "filename": "countries85.csv",
    "output_file": "sorted_countries85.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:03:28.698944+05",
    "log": "[JobID: 14a13ec7] Execution completed | Status: SUCCESS | Output file: 'sorted_countries85.csv' | Source: Airflow | Timestamp: 2025-06-12T07:03:28.698944+05"
  },
  {
    "job_id": "3dc0d33d",
    "source": "Airflow",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:03:52.698944+05",
    "log": "[JobID: 3dc0d33d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:03:52.698944+05"
  },
  {
    "job_id": "ef2f6f66",
    "source": "Glue",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:03:54.698944+05",
    "log": "[JobID: ef2f6f66] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:03:54.698944+05"
  },
  {
    "job_id": "ef2f6f66",
    "source": "Glue",
    "filename": "countries93.csv",
    "output_file": "sorted_countries93.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:04:19.698944+05",
    "log": "[JobID: ef2f6f66] Execution completed | Status: SUCCESS | Output file: 'sorted_countries93.csv' | Source: Glue | Timestamp: 2025-06-12T07:04:19.698944+05"
  },
  {
    "job_id": "5c2d7824",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:04:27.698944+05",
    "log": "[JobID: 5c2d7824] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:04:27.698944+05"
  },
  {
    "job_id": "53bb7356",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:04:44.698944+05",
    "log": "[JobID: 53bb7356] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:04:44.698944+05"
  },
  {
    "job_id": "3dc0d33d",
    "source": "Airflow",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:04:54.698944+05",
    "log": "[JobID: 3dc0d33d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:04:54.698944+05"
  },
  {
    "job_id": "7a260a35",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:05:04.698944+05",
    "log": "[JobID: 7a260a35] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:05:04.698944+05"
  },
  {
    "job_id": "84a55e23",
    "source": "Kafka",
    "filename": "countries10.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:05:19.698944+05",
    "log": "[JobID: 84a55e23] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:05:19.698944+05"
  },
  {
    "job_id": "53bb7356",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:05:29.698944+05",
    "log": "[JobID: 53bb7356] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:05:29.698944+05"
  },
  {
    "job_id": "9d2afd00",
    "source": "Flink",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:05:32.698944+05",
    "log": "[JobID: 9d2afd00] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:05:32.698944+05"
  },
  {
    "job_id": "53bb7356",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:06:01.698944+05",
    "log": "[JobID: 53bb7356] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:06:01.698944+05"
  },
  {
    "job_id": "09610c88",
    "source": "Spark",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:06:10.698944+05",
    "log": "[JobID: 09610c88] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:06:10.698944+05"
  },
  {
    "job_id": "a04f9526",
    "source": "Flink",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:06:42.698944+05",
    "log": "[JobID: a04f9526] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:06:42.698944+05"
  },
  {
    "job_id": "9d2afd00",
    "source": "Flink",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:06:54.698944+05",
    "log": "[JobID: 9d2afd00] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:06:54.698944+05"
  },
  {
    "job_id": "5d7e1263",
    "source": "Glue",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:07:38.698944+05",
    "log": "[JobID: 5d7e1263] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:07:38.698944+05"
  },
  {
    "job_id": "18013160",
    "source": "Kafka",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:07:59.698944+05",
    "log": "[JobID: 18013160] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:07:59.698944+05"
  },
  {
    "job_id": "9d2afd00",
    "source": "Flink",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:08:01.698944+05",
    "log": "[JobID: 9d2afd00] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:08:01.698944+05"
  },
  {
    "job_id": "7a260a35",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:08:33.698944+05",
    "log": "[JobID: 7a260a35] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:08:33.698944+05"
  },
  {
    "job_id": "18013160",
    "source": "Kafka",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:08:35.698944+05",
    "log": "[JobID: 18013160] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:08:35.698944+05"
  },
  {
    "job_id": "5d7e1263",
    "source": "Glue",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:08:51.698944+05",
    "log": "[JobID: 5d7e1263] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:08:51.698944+05"
  },
  {
    "job_id": "20d8cc93",
    "source": "Kafka",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:09:25.698944+05",
    "log": "[JobID: 20d8cc93] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:09:25.698944+05"
  },
  {
    "job_id": "84a55e23",
    "source": "Kafka",
    "filename": "countries10.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:09:26.698944+05",
    "log": "[JobID: 84a55e23] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:09:26.698944+05"
  },
  {
    "job_id": "1ca23801",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:09:43.698944+05",
    "log": "[JobID: 1ca23801] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:09:43.698944+05"
  },
  {
    "job_id": "3c028402",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:09:47.698944+05",
    "log": "[JobID: 3c028402] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:09:47.698944+05"
  },
  {
    "job_id": "33b84a69",
    "source": "Glue",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:09:49.698944+05",
    "log": "[JobID: 33b84a69] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:09:49.698944+05"
  },
  {
    "job_id": "5d7e1263",
    "source": "Glue",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:10:07.698944+05",
    "log": "[JobID: 5d7e1263] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:10:07.698944+05"
  },
  {
    "job_id": "3c028402",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:10:31.698944+05",
    "log": "[JobID: 3c028402] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:10:31.698944+05"
  },
  {
    "job_id": "09610c88",
    "source": "Spark",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:11:00.698944+05",
    "log": "[JobID: 09610c88] Execution failed | Status: FAILED | Error: java.lang.ClassCastException: com.example.StringValue cannot be cast to java.lang.Integer | Source: Spark | Timestamp: 2025-06-12T07:11:00.698944+05\njava.lang.ClassCastException: com.example.StringValue cannot be cast to java.lang.Integer\n\tat com.example.TypeChecker.check(TypeChecker.java:34)\n\tat com.example.Main.execute(Main.java:50)"
  },
  {
    "job_id": "5b535292",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:11:05.698944+05",
    "log": "[JobID: 5b535292] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:11:05.698944+05"
  },
  {
    "job_id": "20d8cc93",
    "source": "Kafka",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:11:08.698944+05",
    "log": "[JobID: 20d8cc93] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:11:08.698944+05"
  },
  {
    "job_id": "7a260a35",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:11:09.698944+05",
    "log": "[JobID: 7a260a35] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:11:09.698944+05"
  },
  {
    "job_id": "b109874e",
    "source": "Kafka",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:12:29.698944+05",
    "log": "[JobID: b109874e] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:12:29.698944+05"
  },
  {
    "job_id": "1ca23801",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:13:03.698944+05",
    "log": "[JobID: 1ca23801] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:13:03.698944+05"
  },
  {
    "job_id": "cd77ffcb",
    "source": "Airflow",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:13:18.698944+05",
    "log": "[JobID: cd77ffcb] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:13:18.698944+05"
  },
  {
    "job_id": "7fbc7cf2",
    "source": "Spark",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:13:37.698944+05",
    "log": "[JobID: 7fbc7cf2] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:13:37.698944+05"
  },
  {
    "job_id": "3dc0d33d",
    "source": "Airflow",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:13:44.698944+05",
    "log": "[JobID: 3dc0d33d] Execution failed | Status: FAILED | Error: java.lang.IllegalStateException: Kafka consumer is not subscribed to any topics | Source: Airflow | Timestamp: 2025-06-12T07:13:44.698944+05\njava.lang.IllegalStateException: Kafka consumer is not subscribed to any topics\n\tat org.apache.kafka.clients.consumer.ConsumerImpl.poll(ConsumerImpl.java:1010)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "5b535292",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:14:10.698944+05",
    "log": "[JobID: 5b535292] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:14:10.698944+05"
  },
  {
    "job_id": "7fbc7cf2",
    "source": "Spark",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:14:21.698944+05",
    "log": "[JobID: 7fbc7cf2] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:14:21.698944+05"
  },
  {
    "job_id": "cd77ffcb",
    "source": "Airflow",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:14:23.698944+05",
    "log": "[JobID: cd77ffcb] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:14:23.698944+05"
  },
  {
    "job_id": "84a55e23",
    "source": "Kafka",
    "filename": "countries10.csv",
    "output_file": "sorted_countries10.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:14:40.698944+05",
    "log": "[JobID: 84a55e23] Execution completed | Status: SUCCESS | Output file: 'sorted_countries10.csv' | Source: Kafka | Timestamp: 2025-06-12T07:14:40.698944+05"
  },
  {
    "job_id": "33b84a69",
    "source": "Glue",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:14:42.698944+05",
    "log": "[JobID: 33b84a69] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:14:42.698944+05"
  },
  {
    "job_id": "fe923224",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:14:44.698944+05",
    "log": "[JobID: fe923224] Execution failed | Status: FAILED | Error: ValueError: invalid literal for int() with base 10: 'abc' | Source: Kafka | Timestamp: 2025-06-12T07:14:44.698944+05\nValueError: invalid literal for int() with base 10: 'abc'\n\tat pandas_read.py:127\n\tat data_processing.py:42"
  },
  {
    "job_id": "9d2afd00",
    "source": "Flink",
    "filename": "countries45.csv",
    "output_file": "sorted_countries45.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:15:14.698944+05",
    "log": "[JobID: 9d2afd00] Execution completed | Status: SUCCESS | Output file: 'sorted_countries45.csv' | Source: Flink | Timestamp: 2025-06-12T07:15:14.698944+05"
  },
  {
    "job_id": "a04f9526",
    "source": "Flink",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:15:14.698944+05",
    "log": "[JobID: a04f9526] Execution failed | Status: FAILED | Error: java.lang.NullPointerException: Cannot invoke \"String.toString()\" because \"input\" is null | Source: Flink | Timestamp: 2025-06-12T07:15:14.698944+05\njava.lang.NullPointerException: Cannot invoke \"String.toString()\" because \"input\" is null\n\tat com.example.DataProcessor.process(DataProcessor.java:42)\n\tat com.example.Main.run(Main.java:17)"
  },
  {
    "job_id": "18013160",
    "source": "Kafka",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:15:27.698944+05",
    "log": "[JobID: 18013160] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Kafka | Timestamp: 2025-06-12T07:15:27.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "3c028402",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:15:29.698944+05",
    "log": "[JobID: 3c028402] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:15:29.698944+05"
  },
  {
    "job_id": "20d8cc93",
    "source": "Kafka",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:15:41.698944+05",
    "log": "[JobID: 20d8cc93] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:15:41.698944+05"
  },
  {
    "job_id": "cd77ffcb",
    "source": "Airflow",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:16:21.698944+05",
    "log": "[JobID: cd77ffcb] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:16:21.698944+05"
  },
  {
    "job_id": "c414ef05",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:16:28.698944+05",
    "log": "[JobID: c414ef05] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:16:28.698944+05"
  },
  {
    "job_id": "33b84a69",
    "source": "Glue",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:16:56.698944+05",
    "log": "[JobID: 33b84a69] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:16:56.698944+05"
  },
  {
    "job_id": "7fbc7cf2",
    "source": "Spark",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:16:58.698944+05",
    "log": "[JobID: 7fbc7cf2] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:16:58.698944+05"
  },
  {
    "job_id": "b109874e",
    "source": "Kafka",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:17:00.698944+05",
    "log": "[JobID: b109874e] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:17:00.698944+05"
  },
  {
    "job_id": "1ca23801",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:17:05.698944+05",
    "log": "[JobID: 1ca23801] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:17:05.698944+05"
  },
  {
    "job_id": "c414ef05",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:18:02.698944+05",
    "log": "[JobID: c414ef05] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:18:02.698944+05"
  },
  {
    "job_id": "498efd32",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": "sorted_countries20.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:18:26.698944+05",
    "log": "[JobID: 498efd32] Execution completed | Status: SUCCESS | Output file: 'sorted_countries20.csv' | Source: Glue | Timestamp: 2025-06-12T07:18:26.698944+05"
  },
  {
    "job_id": "5b535292",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:18:49.698944+05",
    "log": "[JobID: 5b535292] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:18:49.698944+05"
  },
  {
    "job_id": "ad53f03b",
    "source": "Hadoop",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:19:10.698944+05",
    "log": "[JobID: ad53f03b] Execution failed | Status: FAILED | Error: java.lang.IllegalStateException: Kafka consumer is not subscribed to any topics | Source: Hadoop | Timestamp: 2025-06-12T07:19:10.698944+05\njava.lang.IllegalStateException: Kafka consumer is not subscribed to any topics\n\tat org.apache.kafka.clients.consumer.ConsumerImpl.poll(ConsumerImpl.java:1010)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "a3e4da14",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:20:30.698944+05",
    "log": "[JobID: a3e4da14] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:20:30.698944+05"
  },
  {
    "job_id": "5c2d7824",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:21:15.698944+05",
    "log": "[JobID: 5c2d7824] Execution failed | Status: FAILED | Error: ValueError: math domain error | Source: Glue | Timestamp: 2025-06-12T07:21:15.698944+05\nValueError: math domain error\n\tat compute_math.py:88\n\tat process.py:15"
  },
  {
    "job_id": "725a0056",
    "source": "Kafka",
    "filename": "countries80.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:21:20.698944+05",
    "log": "[JobID: 725a0056] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:21:20.698944+05"
  },
  {
    "job_id": "a8bccaa4",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:21:30.698944+05",
    "log": "[JobID: a8bccaa4] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:21:30.698944+05"
  },
  {
    "job_id": "b109874e",
    "source": "Kafka",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:21:37.698944+05",
    "log": "[JobID: b109874e] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:21:37.698944+05"
  },
  {
    "job_id": "c414ef05",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:22:06.698944+05",
    "log": "[JobID: c414ef05] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:22:06.698944+05"
  },
  {
    "job_id": "725a0056",
    "source": "Kafka",
    "filename": "countries80.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:22:08.698944+05",
    "log": "[JobID: 725a0056] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:22:08.698944+05"
  },
  {
    "job_id": "a8bccaa4",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:22:23.698944+05",
    "log": "[JobID: a8bccaa4] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:22:23.698944+05"
  },
  {
    "job_id": "e25060dd",
    "source": "Airflow",
    "filename": "countries18.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:22:27.698944+05",
    "log": "[JobID: e25060dd] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:22:27.698944+05"
  },
  {
    "job_id": "7fbc7cf2",
    "source": "Spark",
    "filename": "countries90.csv",
    "output_file": "sorted_countries90.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:22:57.698944+05",
    "log": "[JobID: 7fbc7cf2] Execution completed | Status: SUCCESS | Output file: 'sorted_countries90.csv' | Source: Spark | Timestamp: 2025-06-12T07:22:57.698944+05"
  },
  {
    "job_id": "d50acfd3",
    "source": "Glue",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:23:00.698944+05",
    "log": "[JobID: d50acfd3] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:23:00.698944+05"
  },
  {
    "job_id": "a3e4da14",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:23:17.698944+05",
    "log": "[JobID: a3e4da14] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:23:17.698944+05"
  },
  {
    "job_id": "5d7e1263",
    "source": "Glue",
    "filename": "countries59.csv",
    "output_file": "sorted_countries59.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:23:25.698944+05",
    "log": "[JobID: 5d7e1263] Execution completed | Status: SUCCESS | Output file: 'sorted_countries59.csv' | Source: Glue | Timestamp: 2025-06-12T07:23:25.698944+05"
  },
  {
    "job_id": "1ca23801",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": "sorted_countries8.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:24:21.698944+05",
    "log": "[JobID: 1ca23801] Execution completed | Status: SUCCESS | Output file: 'sorted_countries8.csv' | Source: Spark | Timestamp: 2025-06-12T07:24:21.698944+05"
  },
  {
    "job_id": "a3e4da14",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:24:48.698944+05",
    "log": "[JobID: a3e4da14] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:24:48.698944+05"
  },
  {
    "job_id": "725a0056",
    "source": "Kafka",
    "filename": "countries80.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:25:43.698944+05",
    "log": "[JobID: 725a0056] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:25:43.698944+05"
  },
  {
    "job_id": "a8bccaa4",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:26:04.698944+05",
    "log": "[JobID: a8bccaa4] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:26:04.698944+05"
  },
  {
    "job_id": "37f7e572",
    "source": "Kafka",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:26:47.698944+05",
    "log": "[JobID: 37f7e572] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:26:47.698944+05"
  },
  {
    "job_id": "e25060dd",
    "source": "Airflow",
    "filename": "countries18.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:27:07.698944+05",
    "log": "[JobID: e25060dd] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:27:07.698944+05"
  },
  {
    "job_id": "d78858bb",
    "source": "Flink",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:27:08.698944+05",
    "log": "[JobID: d78858bb] Execution failed | Status: FAILED | Error: ImportError: cannot import name 'DataFrame' from 'pandas' | Source: Flink | Timestamp: 2025-06-12T07:27:08.698944+05\nImportError: cannot import name 'DataFrame' from 'pandas'\n\tat analysis.py:25\n\tat main_script.py:12"
  },
  {
    "job_id": "323eca48",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:27:09.698944+05",
    "log": "[JobID: 323eca48] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T07:27:09.698944+05"
  },
  {
    "job_id": "d50acfd3",
    "source": "Glue",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:27:18.698944+05",
    "log": "[JobID: d50acfd3] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:27:18.698944+05"
  },
  {
    "job_id": "d607a5be",
    "source": "Airflow",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:27:28.698944+05",
    "log": "[JobID: d607a5be] Execution failed | Status: FAILED | Error: SyntaxError: EOL while scanning string literal | Source: Airflow | Timestamp: 2025-06-12T07:27:28.698944+05\nSyntaxError: EOL while scanning string literal\n\tat config_loader.py:12\n\tat main.py:6"
  },
  {
    "job_id": "510b9f84",
    "source": "Hadoop",
    "filename": "countries87.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:27:53.698944+05",
    "log": "[JobID: 510b9f84] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T07:27:53.698944+05"
  },
  {
    "job_id": "7a260a35",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": "sorted_countries70.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:28:02.698944+05",
    "log": "[JobID: 7a260a35] Execution completed | Status: SUCCESS | Output file: 'sorted_countries70.csv' | Source: Flink | Timestamp: 2025-06-12T07:28:02.698944+05"
  },
  {
    "job_id": "323eca48",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:28:06.698944+05",
    "log": "[JobID: 323eca48] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T07:28:06.698944+05"
  },
  {
    "job_id": "510b9f84",
    "source": "Hadoop",
    "filename": "countries87.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:28:45.698944+05",
    "log": "[JobID: 510b9f84] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T07:28:45.698944+05"
  },
  {
    "job_id": "460b7e58",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:28:52.698944+05",
    "log": "[JobID: 460b7e58] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:28:52.698944+05"
  },
  {
    "job_id": "e25060dd",
    "source": "Airflow",
    "filename": "countries18.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:29:49.698944+05",
    "log": "[JobID: e25060dd] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:29:49.698944+05"
  },
  {
    "job_id": "861a3585",
    "source": "Glue",
    "filename": "countries22.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:29:50.698944+05",
    "log": "[JobID: 861a3585] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T07:29:50.698944+05"
  },
  {
    "job_id": "37f7e572",
    "source": "Kafka",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:29:57.698944+05",
    "log": "[JobID: 37f7e572] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:29:57.698944+05"
  },
  {
    "job_id": "510b9f84",
    "source": "Hadoop",
    "filename": "countries87.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:29:58.698944+05",
    "log": "[JobID: 510b9f84] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T07:29:58.698944+05"
  },
  {
    "job_id": "d50acfd3",
    "source": "Glue",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:30:30.698944+05",
    "log": "[JobID: d50acfd3] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:30:30.698944+05"
  },
  {
    "job_id": "725a0056",
    "source": "Kafka",
    "filename": "countries80.csv",
    "output_file": "sorted_countries80.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:30:52.698944+05",
    "log": "[JobID: 725a0056] Execution completed | Status: SUCCESS | Output file: 'sorted_countries80.csv' | Source: Kafka | Timestamp: 2025-06-12T07:30:52.698944+05"
  },
  {
    "job_id": "323eca48",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:31:37.698944+05",
    "log": "[JobID: 323eca48] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T07:31:37.698944+05"
  },
  {
    "job_id": "a3e4da14",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": "sorted_countries55.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:31:38.698944+05",
    "log": "[JobID: a3e4da14] Execution completed | Status: SUCCESS | Output file: 'sorted_countries55.csv' | Source: Spark | Timestamp: 2025-06-12T07:31:38.698944+05"
  },
  {
    "job_id": "861a3585",
    "source": "Glue",
    "filename": "countries22.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:31:40.698944+05",
    "log": "[JobID: 861a3585] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T07:31:40.698944+05"
  },
  {
    "job_id": "2d2e9c45",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:31:43.698944+05",
    "log": "[JobID: 2d2e9c45] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:31:43.698944+05"
  },
  {
    "job_id": "db123a45",
    "source": "Airflow",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:31:53.698944+05",
    "log": "[JobID: db123a45] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:31:53.698944+05"
  },
  {
    "job_id": "460b7e58",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:32:19.698944+05",
    "log": "[JobID: 460b7e58] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:32:19.698944+05"
  },
  {
    "job_id": "3505affe",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:32:54.698944+05",
    "log": "[JobID: 3505affe] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:32:54.698944+05"
  },
  {
    "job_id": "861a3585",
    "source": "Glue",
    "filename": "countries22.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:33:21.698944+05",
    "log": "[JobID: 861a3585] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T07:33:21.698944+05"
  },
  {
    "job_id": "a702c85d",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:33:29.698944+05",
    "log": "[JobID: a702c85d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:33:29.698944+05"
  },
  {
    "job_id": "37f7e572",
    "source": "Kafka",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:33:40.698944+05",
    "log": "[JobID: 37f7e572] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:33:40.698944+05"
  },
  {
    "job_id": "460b7e58",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:34:00.698944+05",
    "log": "[JobID: 460b7e58] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:34:00.698944+05"
  },
  {
    "job_id": "2d2e9c45",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:34:20.698944+05",
    "log": "[JobID: 2d2e9c45] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:34:20.698944+05"
  },
  {
    "job_id": "2d2e9c45",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:34:59.698944+05",
    "log": "[JobID: 2d2e9c45] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:34:59.698944+05"
  },
  {
    "job_id": "53bb7356",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:35:35.698944+05",
    "log": "[JobID: 53bb7356] Execution failed | Status: FAILED | Error: org.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist | Source: Flink | Timestamp: 2025-06-12T07:35:35.698944+05\norg.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist\n\tat org.apache.hadoop.fs.LocalFileSystem.open(LocalFileSystem.java:123)\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:67)"
  },
  {
    "job_id": "460b7e58",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:35:36.698944+05",
    "log": "[JobID: 460b7e58] Execution failed | Status: FAILED | Error: java.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod() | Source: Airflow | Timestamp: 2025-06-12T07:35:36.698944+05\njava.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod()\n\tat com.example.Updater.runUpdate(Updater.java:47)\n\tat com.example.Main.start(Main.java:30)"
  },
  {
    "job_id": "db123a45",
    "source": "Airflow",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:36:23.698944+05",
    "log": "[JobID: db123a45] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:36:23.698944+05"
  },
  {
    "job_id": "6c69a229",
    "source": "Hadoop",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:36:34.698944+05",
    "log": "[JobID: 6c69a229] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T07:36:34.698944+05"
  },
  {
    "job_id": "44fe8e24",
    "source": "Kafka",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:36:36.698944+05",
    "log": "[JobID: 44fe8e24] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:36:36.698944+05"
  },
  {
    "job_id": "3505affe",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:36:42.698944+05",
    "log": "[JobID: 3505affe] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:36:42.698944+05"
  },
  {
    "job_id": "a702c85d",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:36:52.698944+05",
    "log": "[JobID: a702c85d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:36:52.698944+05"
  },
  {
    "job_id": "6c69a229",
    "source": "Hadoop",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:37:15.698944+05",
    "log": "[JobID: 6c69a229] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T07:37:15.698944+05"
  },
  {
    "job_id": "45d26e37",
    "source": "Spark",
    "filename": "countries31.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:37:55.698944+05",
    "log": "[JobID: 45d26e37] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:37:55.698944+05"
  },
  {
    "job_id": "db123a45",
    "source": "Airflow",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:38:11.698944+05",
    "log": "[JobID: db123a45] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:38:11.698944+05"
  },
  {
    "job_id": "d50acfd3",
    "source": "Glue",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:38:24.698944+05",
    "log": "[JobID: d50acfd3] Execution failed | Status: FAILED | Error: AttributeError: 'NoneType' object has no attribute 'split' | Source: Glue | Timestamp: 2025-06-12T07:38:24.698944+05\nAttributeError: 'NoneType' object has no attribute 'split'\n\tat preprocess_data.py:33\n\tat main.py:78"
  },
  {
    "job_id": "45d26e37",
    "source": "Spark",
    "filename": "countries31.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:39:22.698944+05",
    "log": "[JobID: 45d26e37] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:39:22.698944+05"
  },
  {
    "job_id": "3505affe",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:39:25.698944+05",
    "log": "[JobID: 3505affe] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:39:25.698944+05"
  },
  {
    "job_id": "8b93aeac",
    "source": "Kafka",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:39:34.698944+05",
    "log": "[JobID: 8b93aeac] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:39:34.698944+05"
  },
  {
    "job_id": "45d26e37",
    "source": "Spark",
    "filename": "countries31.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:40:08.698944+05",
    "log": "[JobID: 45d26e37] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:40:08.698944+05"
  },
  {
    "job_id": "44fe8e24",
    "source": "Kafka",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:40:28.698944+05",
    "log": "[JobID: 44fe8e24] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:40:28.698944+05"
  },
  {
    "job_id": "45d26e37",
    "source": "Spark",
    "filename": "countries31.csv",
    "output_file": "sorted_countries31.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:40:44.698944+05",
    "log": "[JobID: 45d26e37] Execution completed | Status: SUCCESS | Output file: 'sorted_countries31.csv' | Source: Spark | Timestamp: 2025-06-12T07:40:44.698944+05"
  },
  {
    "job_id": "cd77ffcb",
    "source": "Airflow",
    "filename": "countries95.csv",
    "output_file": "sorted_countries95.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:40:52.698944+05",
    "log": "[JobID: cd77ffcb] Execution completed | Status: SUCCESS | Output file: 'sorted_countries95.csv' | Source: Airflow | Timestamp: 2025-06-12T07:40:52.698944+05"
  },
  {
    "job_id": "a702c85d",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:41:27.698944+05",
    "log": "[JobID: a702c85d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:41:27.698944+05"
  },
  {
    "job_id": "c414ef05",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": "sorted_countries63.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:41:27.698944+05",
    "log": "[JobID: c414ef05] Execution completed | Status: SUCCESS | Output file: 'sorted_countries63.csv' | Source: Flink | Timestamp: 2025-06-12T07:41:27.698944+05"
  },
  {
    "job_id": "1bdf21ca",
    "source": "Airflow",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:41:28.698944+05",
    "log": "[JobID: 1bdf21ca] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:41:28.698944+05"
  },
  {
    "job_id": "c0e04785",
    "source": "Kafka",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:41:37.698944+05",
    "log": "[JobID: c0e04785] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:41:37.698944+05"
  },
  {
    "job_id": "8b93aeac",
    "source": "Kafka",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:41:44.698944+05",
    "log": "[JobID: 8b93aeac] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:41:44.698944+05"
  },
  {
    "job_id": "6c69a229",
    "source": "Hadoop",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:42:07.698944+05",
    "log": "[JobID: 6c69a229] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T07:42:07.698944+05"
  },
  {
    "job_id": "966a32b4",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:42:20.698944+05",
    "log": "[JobID: 966a32b4] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:42:20.698944+05"
  },
  {
    "job_id": "5c8edb10",
    "source": "Kafka",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:42:33.698944+05",
    "log": "[JobID: 5c8edb10] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T07:42:33.698944+05"
  },
  {
    "job_id": "2d2e9c45",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": "sorted_countries78.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:42:35.698944+05",
    "log": "[JobID: 2d2e9c45] Execution completed | Status: SUCCESS | Output file: 'sorted_countries78.csv' | Source: Kafka | Timestamp: 2025-06-12T07:42:35.698944+05"
  },
  {
    "job_id": "20d8cc93",
    "source": "Kafka",
    "filename": "countries65.csv",
    "output_file": "sorted_countries65.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:42:38.698944+05",
    "log": "[JobID: 20d8cc93] Execution completed | Status: SUCCESS | Output file: 'sorted_countries65.csv' | Source: Kafka | Timestamp: 2025-06-12T07:42:38.698944+05"
  },
  {
    "job_id": "1bdf21ca",
    "source": "Airflow",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:42:39.698944+05",
    "log": "[JobID: 1bdf21ca] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:42:39.698944+05"
  },
  {
    "job_id": "3c028402",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": "sorted_countries20.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:43:26.698944+05",
    "log": "[JobID: 3c028402] Execution completed | Status: SUCCESS | Output file: 'sorted_countries20.csv' | Source: Glue | Timestamp: 2025-06-12T07:43:26.698944+05"
  },
  {
    "job_id": "966a32b4",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:43:38.698944+05",
    "log": "[JobID: 966a32b4] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T07:43:38.698944+05"
  },
  {
    "job_id": "c0e04785",
    "source": "Kafka",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:44:08.698944+05",
    "log": "[JobID: c0e04785] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:44:08.698944+05"
  },
  {
    "job_id": "a8bccaa4",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:44:19.698944+05",
    "log": "[JobID: a8bccaa4] Execution failed | Status: FAILED | Error: ValueError: invalid literal for int() with base 10: 'abc' | Source: Glue | Timestamp: 2025-06-12T07:44:19.698944+05\nValueError: invalid literal for int() with base 10: 'abc'\n\tat pandas_read.py:127\n\tat data_processing.py:42"
  },
  {
    "job_id": "1bdf21ca",
    "source": "Airflow",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:44:38.698944+05",
    "log": "[JobID: 1bdf21ca] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:44:38.698944+05"
  },
  {
    "job_id": "33b84a69",
    "source": "Glue",
    "filename": "countries34.csv",
    "output_file": "sorted_countries34.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:45:05.698944+05",
    "log": "[JobID: 33b84a69] Execution completed | Status: SUCCESS | Output file: 'sorted_countries34.csv' | Source: Glue | Timestamp: 2025-06-12T07:45:05.698944+05"
  },
  {
    "job_id": "44fe8e24",
    "source": "Kafka",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:45:19.698944+05",
    "log": "[JobID: 44fe8e24] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:45:19.698944+05"
  },
  {
    "job_id": "966a32b4",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:45:52.698944+05",
    "log": "[JobID: 966a32b4] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T07:45:52.698944+05"
  },
  {
    "job_id": "8b93aeac",
    "source": "Kafka",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:46:14.698944+05",
    "log": "[JobID: 8b93aeac] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:46:14.698944+05"
  },
  {
    "job_id": "5c8edb10",
    "source": "Kafka",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:46:18.698944+05",
    "log": "[JobID: 5c8edb10] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T07:46:18.698944+05"
  },
  {
    "job_id": "510b9f84",
    "source": "Hadoop",
    "filename": "countries87.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:46:44.698944+05",
    "log": "[JobID: 510b9f84] Execution failed | Status: FAILED | Error: org.apache.spark.SparkException: Job aborted due to stage failure | Source: Hadoop | Timestamp: 2025-06-12T07:46:44.698944+05\norg.apache.spark.SparkException: Job aborted due to stage failure\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)"
  },
  {
    "job_id": "c0e04785",
    "source": "Kafka",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:47:05.698944+05",
    "log": "[JobID: c0e04785] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:47:05.698944+05"
  },
  {
    "job_id": "6c680112",
    "source": "Airflow",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:47:30.698944+05",
    "log": "[JobID: 6c680112] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:47:30.698944+05"
  },
  {
    "job_id": "3505affe",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:47:50.698944+05",
    "log": "[JobID: 3505affe] Execution failed | Status: FAILED | Error: org.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist | Source: Flink | Timestamp: 2025-06-12T07:47:50.698944+05\norg.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist\n\tat org.apache.hadoop.fs.LocalFileSystem.open(LocalFileSystem.java:123)\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:67)"
  },
  {
    "job_id": "5b535292",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:48:06.698944+05",
    "log": "[JobID: 5b535292] Execution failed | Status: FAILED | Error: AttributeError: 'NoneType' object has no attribute 'split' | Source: Glue | Timestamp: 2025-06-12T07:48:06.698944+05\nAttributeError: 'NoneType' object has no attribute 'split'\n\tat preprocess_data.py:33\n\tat main.py:78"
  },
  {
    "job_id": "861a3585",
    "source": "Glue",
    "filename": "countries22.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:49:23.698944+05",
    "log": "[JobID: 861a3585] Execution failed | Status: FAILED | Error: TypeError: 'NoneType' object is not callable | Source: Glue | Timestamp: 2025-06-12T07:49:23.698944+05\nTypeError: 'NoneType' object is not callable\n\tat lambda_handler.py:11\n\tat app.py:58"
  },
  {
    "job_id": "5c8edb10",
    "source": "Kafka",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:49:44.698944+05",
    "log": "[JobID: 5c8edb10] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T07:49:44.698944+05"
  },
  {
    "job_id": "b109874e",
    "source": "Kafka",
    "filename": "countries42.csv",
    "output_file": "sorted_countries42.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:49:54.698944+05",
    "log": "[JobID: b109874e] Execution completed | Status: SUCCESS | Output file: 'sorted_countries42.csv' | Source: Kafka | Timestamp: 2025-06-12T07:49:54.698944+05"
  },
  {
    "job_id": "44fe8e24",
    "source": "Kafka",
    "filename": "countries9.csv",
    "output_file": "sorted_countries9.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:50:28.698944+05",
    "log": "[JobID: 44fe8e24] Execution completed | Status: SUCCESS | Output file: 'sorted_countries9.csv' | Source: Kafka | Timestamp: 2025-06-12T07:50:28.698944+05"
  },
  {
    "job_id": "3d2f2b6c",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:51:31.698944+05",
    "log": "[JobID: 3d2f2b6c] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:51:31.698944+05"
  },
  {
    "job_id": "6c680112",
    "source": "Airflow",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:52:11.698944+05",
    "log": "[JobID: 6c680112] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:52:11.698944+05"
  },
  {
    "job_id": "e25060dd",
    "source": "Airflow",
    "filename": "countries18.csv",
    "output_file": "sorted_countries18.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:52:38.698944+05",
    "log": "[JobID: e25060dd] Execution completed | Status: SUCCESS | Output file: 'sorted_countries18.csv' | Source: Airflow | Timestamp: 2025-06-12T07:52:38.698944+05"
  },
  {
    "job_id": "f0e597f8",
    "source": "Hadoop",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:52:49.698944+05",
    "log": "[JobID: f0e597f8] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T07:52:49.698944+05"
  },
  {
    "job_id": "3d2f2b6c",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:53:11.698944+05",
    "log": "[JobID: 3d2f2b6c] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T07:53:11.698944+05"
  },
  {
    "job_id": "323eca48",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:54:24.698944+05",
    "log": "[JobID: 323eca48] Execution failed | Status: FAILED | Error: ImportError: cannot import name 'DataFrame' from 'pandas' | Source: Hadoop | Timestamp: 2025-06-12T07:54:24.698944+05\nImportError: cannot import name 'DataFrame' from 'pandas'\n\tat analysis.py:25\n\tat main_script.py:12"
  },
  {
    "job_id": "3d2f2b6c",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:54:49.698944+05",
    "log": "[JobID: 3d2f2b6c] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T07:54:49.698944+05"
  },
  {
    "job_id": "6c680112",
    "source": "Airflow",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:55:38.698944+05",
    "log": "[JobID: 6c680112] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T07:55:38.698944+05"
  },
  {
    "job_id": "e653541d",
    "source": "Airflow",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:56:00.698944+05",
    "log": "[JobID: e653541d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T07:56:00.698944+05"
  },
  {
    "job_id": "f0e597f8",
    "source": "Hadoop",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:56:42.698944+05",
    "log": "[JobID: f0e597f8] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T07:56:42.698944+05"
  },
  {
    "job_id": "2d23b546",
    "source": "Spark",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:56:47.698944+05",
    "log": "[JobID: 2d23b546] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T07:56:47.698944+05"
  },
  {
    "job_id": "e653541d",
    "source": "Airflow",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T07:57:07.698944+05",
    "log": "[JobID: e653541d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T07:57:07.698944+05"
  },
  {
    "job_id": "0ad42e99",
    "source": "Flink",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:57:26.698944+05",
    "log": "[JobID: 0ad42e99] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T07:57:26.698944+05"
  },
  {
    "job_id": "a702c85d",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": "sorted_countries15.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:57:41.698944+05",
    "log": "[JobID: a702c85d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries15.csv' | Source: Airflow | Timestamp: 2025-06-12T07:57:41.698944+05"
  },
  {
    "job_id": "c0e04785",
    "source": "Kafka",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T07:58:05.698944+05",
    "log": "[JobID: c0e04785] Execution failed | Status: FAILED | Error: TypeError: cannot concatenate 'str' and 'int' objects | Source: Kafka | Timestamp: 2025-06-12T07:58:05.698944+05\nTypeError: cannot concatenate 'str' and 'int' objects\n\tat transform_data.py:56\n\tat main_workflow.py:112"
  },
  {
    "job_id": "8360ec7d",
    "source": "Hadoop",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T07:58:30.698944+05",
    "log": "[JobID: 8360ec7d] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T07:58:30.698944+05"
  },
  {
    "job_id": "8b93aeac",
    "source": "Kafka",
    "filename": "countries39.csv",
    "output_file": "sorted_countries39.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T07:59:02.698944+05",
    "log": "[JobID: 8b93aeac] Execution completed | Status: SUCCESS | Output file: 'sorted_countries39.csv' | Source: Kafka | Timestamp: 2025-06-12T07:59:02.698944+05"
  },
  {
    "job_id": "f0e597f8",
    "source": "Hadoop",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T07:59:48.698944+05",
    "log": "[JobID: f0e597f8] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T07:59:48.698944+05"
  },
  {
    "job_id": "e653541d",
    "source": "Airflow",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:00:05.698944+05",
    "log": "[JobID: e653541d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:00:05.698944+05"
  },
  {
    "job_id": "2d23b546",
    "source": "Spark",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:00:42.698944+05",
    "log": "[JobID: 2d23b546] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:00:42.698944+05"
  },
  {
    "job_id": "6c680112",
    "source": "Airflow",
    "filename": "countries72.csv",
    "output_file": "sorted_countries72.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:00:46.698944+05",
    "log": "[JobID: 6c680112] Execution completed | Status: SUCCESS | Output file: 'sorted_countries72.csv' | Source: Airflow | Timestamp: 2025-06-12T08:00:46.698944+05"
  },
  {
    "job_id": "966a32b4",
    "source": "Flink",
    "filename": "countries15.csv",
    "output_file": "sorted_countries15.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:00:47.698944+05",
    "log": "[JobID: 966a32b4] Execution completed | Status: SUCCESS | Output file: 'sorted_countries15.csv' | Source: Flink | Timestamp: 2025-06-12T08:00:47.698944+05"
  },
  {
    "job_id": "3d2f2b6c",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:00:59.698944+05",
    "log": "[JobID: 3d2f2b6c] Execution failed | Status: FAILED | Error: IOError: [Errno 13] Permission denied: '/var/log/app.log' | Source: Spark | Timestamp: 2025-06-12T08:00:59.698944+05\nIOError: [Errno 13] Permission denied: '/var/log/app.log'\n\tat log_writer.py:59\n\tat main.py:20"
  },
  {
    "job_id": "8360ec7d",
    "source": "Hadoop",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:01:18.698944+05",
    "log": "[JobID: 8360ec7d] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:01:18.698944+05"
  },
  {
    "job_id": "2d23b546",
    "source": "Spark",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:01:23.698944+05",
    "log": "[JobID: 2d23b546] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:01:23.698944+05"
  },
  {
    "job_id": "37f7e572",
    "source": "Kafka",
    "filename": "countries26.csv",
    "output_file": "sorted_countries26.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:01:27.698944+05",
    "log": "[JobID: 37f7e572] Execution completed | Status: SUCCESS | Output file: 'sorted_countries26.csv' | Source: Kafka | Timestamp: 2025-06-12T08:01:27.698944+05"
  },
  {
    "job_id": "96095f85",
    "source": "Hadoop",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:02:15.698944+05",
    "log": "[JobID: 96095f85] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:02:15.698944+05"
  },
  {
    "job_id": "0ad42e99",
    "source": "Flink",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:02:24.698944+05",
    "log": "[JobID: 0ad42e99] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:02:24.698944+05"
  },
  {
    "job_id": "f2370800",
    "source": "Hadoop",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:02:42.698944+05",
    "log": "[JobID: f2370800] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:02:42.698944+05"
  },
  {
    "job_id": "96095f85",
    "source": "Hadoop",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:03:11.698944+05",
    "log": "[JobID: 96095f85] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:03:11.698944+05"
  },
  {
    "job_id": "0ad42e99",
    "source": "Flink",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:03:13.698944+05",
    "log": "[JobID: 0ad42e99] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:03:13.698944+05"
  },
  {
    "job_id": "db123a45",
    "source": "Airflow",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:04:07.698944+05",
    "log": "[JobID: db123a45] Execution failed | Status: FAILED | Error: java.lang.UnsupportedOperationException: This operation is not supported | Source: Airflow | Timestamp: 2025-06-12T08:04:07.698944+05\njava.lang.UnsupportedOperationException: This operation is not supported\n\tat java.util.Collections$UnmodifiableList.add(Collections.java:1055)\n\tat com.example.ListModifier.modify(ListModifier.java:33)"
  },
  {
    "job_id": "96095f85",
    "source": "Hadoop",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:05:49.698944+05",
    "log": "[JobID: 96095f85] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:05:49.698944+05"
  },
  {
    "job_id": "f2370800",
    "source": "Hadoop",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:05:53.698944+05",
    "log": "[JobID: f2370800] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:05:53.698944+05"
  },
  {
    "job_id": "8360ec7d",
    "source": "Hadoop",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:05:53.698944+05",
    "log": "[JobID: 8360ec7d] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:05:53.698944+05"
  },
  {
    "job_id": "2d1b98cf",
    "source": "Glue",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:06:43.698944+05",
    "log": "[JobID: 2d1b98cf] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:06:43.698944+05"
  },
  {
    "job_id": "1bdf21ca",
    "source": "Airflow",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:07:58.698944+05",
    "log": "[JobID: 1bdf21ca] Execution failed | Status: FAILED | Error: org.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file | Source: Airflow | Timestamp: 2025-06-12T08:07:58.698944+05\norg.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file\n\tat org.apache.hadoop.hdfs.DFSUtilClient.call(DFSUtilClient.java:103)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.exists(DistributedFileSystem.java:219)"
  },
  {
    "job_id": "2d1b98cf",
    "source": "Glue",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:08:26.698944+05",
    "log": "[JobID: 2d1b98cf] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:08:26.698944+05"
  },
  {
    "job_id": "f2370800",
    "source": "Hadoop",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:08:40.698944+05",
    "log": "[JobID: f2370800] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:08:40.698944+05"
  },
  {
    "job_id": "e310a78a",
    "source": "Kafka",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:09:13.698944+05",
    "log": "[JobID: e310a78a] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T08:09:13.698944+05"
  },
  {
    "job_id": "2d1b98cf",
    "source": "Glue",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:10:11.698944+05",
    "log": "[JobID: 2d1b98cf] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:10:11.698944+05"
  },
  {
    "job_id": "0ced5be1",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:10:19.698944+05",
    "log": "[JobID: 0ced5be1] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:10:19.698944+05"
  },
  {
    "job_id": "e310a78a",
    "source": "Kafka",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:10:36.698944+05",
    "log": "[JobID: e310a78a] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T08:10:36.698944+05"
  },
  {
    "job_id": "c79bee8e",
    "source": "Glue",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:10:39.698944+05",
    "log": "[JobID: c79bee8e] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:10:39.698944+05"
  },
  {
    "job_id": "6c69a229",
    "source": "Hadoop",
    "filename": "countries37.csv",
    "output_file": "sorted_countries37.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:11:13.698944+05",
    "log": "[JobID: 6c69a229] Execution completed | Status: SUCCESS | Output file: 'sorted_countries37.csv' | Source: Hadoop | Timestamp: 2025-06-12T08:11:13.698944+05"
  },
  {
    "job_id": "0ced5be1",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:11:18.698944+05",
    "log": "[JobID: 0ced5be1] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:11:18.698944+05"
  },
  {
    "job_id": "f2370800",
    "source": "Hadoop",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:11:24.698944+05",
    "log": "[JobID: f2370800] Execution failed | Status: FAILED | Error: java.lang.IllegalArgumentException: Port number out of range: 70000 | Source: Hadoop | Timestamp: 2025-06-12T08:11:24.698944+05\njava.lang.IllegalArgumentException: Port number out of range: 70000\n\tat java.net.ServerSocket.bind(ServerSocket.java:223)\n\tat com.example.NetworkService.start(NetworkService.java:89)"
  },
  {
    "job_id": "f0e597f8",
    "source": "Hadoop",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:12:15.698944+05",
    "log": "[JobID: f0e597f8] Execution failed | Status: FAILED | Error: java.io.FileNotFoundException: /path/to/output/file (No such file or directory) | Source: Hadoop | Timestamp: 2025-06-12T08:12:15.698944+05\njava.io.FileNotFoundException: /path/to/output/file (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)"
  },
  {
    "job_id": "c79bee8e",
    "source": "Glue",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:13:26.698944+05",
    "log": "[JobID: c79bee8e] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:13:26.698944+05"
  },
  {
    "job_id": "0ced5be1",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:14:15.698944+05",
    "log": "[JobID: 0ced5be1] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:14:15.698944+05"
  },
  {
    "job_id": "e310a78a",
    "source": "Kafka",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:14:20.698944+05",
    "log": "[JobID: e310a78a] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T08:14:20.698944+05"
  },
  {
    "job_id": "2d1b98cf",
    "source": "Glue",
    "filename": "countries94.csv",
    "output_file": "sorted_countries94.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:15:18.698944+05",
    "log": "[JobID: 2d1b98cf] Execution completed | Status: SUCCESS | Output file: 'sorted_countries94.csv' | Source: Glue | Timestamp: 2025-06-12T08:15:18.698944+05"
  },
  {
    "job_id": "f7103702",
    "source": "Airflow",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:15:30.698944+05",
    "log": "[JobID: f7103702] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:15:30.698944+05"
  },
  {
    "job_id": "5c8edb10",
    "source": "Kafka",
    "filename": "countries58.csv",
    "output_file": "sorted_countries58.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:16:20.698944+05",
    "log": "[JobID: 5c8edb10] Execution completed | Status: SUCCESS | Output file: 'sorted_countries58.csv' | Source: Kafka | Timestamp: 2025-06-12T08:16:20.698944+05"
  },
  {
    "job_id": "4607b67f",
    "source": "Kafka",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:16:28.698944+05",
    "log": "[JobID: 4607b67f] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T08:16:28.698944+05"
  },
  {
    "job_id": "a0260b15",
    "source": "Flink",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:17:00.698944+05",
    "log": "[JobID: a0260b15] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:17:00.698944+05"
  },
  {
    "job_id": "aa791888",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:17:09.698944+05",
    "log": "[JobID: aa791888] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:17:09.698944+05"
  },
  {
    "job_id": "67ecbc6c",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:17:26.698944+05",
    "log": "[JobID: 67ecbc6c] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:17:26.698944+05"
  },
  {
    "job_id": "4607b67f",
    "source": "Kafka",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:17:36.698944+05",
    "log": "[JobID: 4607b67f] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T08:17:36.698944+05"
  },
  {
    "job_id": "c79bee8e",
    "source": "Glue",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:17:47.698944+05",
    "log": "[JobID: c79bee8e] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:17:47.698944+05"
  },
  {
    "job_id": "d61849f8",
    "source": "Kafka",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:18:32.698944+05",
    "log": "[JobID: d61849f8] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T08:18:32.698944+05"
  },
  {
    "job_id": "1efac7de",
    "source": "Glue",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:18:57.698944+05",
    "log": "[JobID: 1efac7de] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:18:57.698944+05"
  },
  {
    "job_id": "4607b67f",
    "source": "Kafka",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:19:12.698944+05",
    "log": "[JobID: 4607b67f] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T08:19:12.698944+05"
  },
  {
    "job_id": "a0260b15",
    "source": "Flink",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:19:27.698944+05",
    "log": "[JobID: a0260b15] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:19:27.698944+05"
  },
  {
    "job_id": "f7103702",
    "source": "Airflow",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:19:43.698944+05",
    "log": "[JobID: f7103702] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:19:43.698944+05"
  },
  {
    "job_id": "aa791888",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:20:12.698944+05",
    "log": "[JobID: aa791888] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:20:12.698944+05"
  },
  {
    "job_id": "f7103702",
    "source": "Airflow",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:20:22.698944+05",
    "log": "[JobID: f7103702] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:20:22.698944+05"
  },
  {
    "job_id": "b75b1fa0",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:20:50.698944+05",
    "log": "[JobID: b75b1fa0] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:20:50.698944+05"
  },
  {
    "job_id": "a0260b15",
    "source": "Flink",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:21:06.698944+05",
    "log": "[JobID: a0260b15] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:21:06.698944+05"
  },
  {
    "job_id": "67ecbc6c",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:21:27.698944+05",
    "log": "[JobID: 67ecbc6c] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:21:27.698944+05"
  },
  {
    "job_id": "d61849f8",
    "source": "Kafka",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:21:46.698944+05",
    "log": "[JobID: d61849f8] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T08:21:46.698944+05"
  },
  {
    "job_id": "8360ec7d",
    "source": "Hadoop",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:21:53.698944+05",
    "log": "[JobID: 8360ec7d] Execution failed | Status: FAILED | Error: SyntaxError: invalid syntax in ctrl_flow.py | Source: Hadoop | Timestamp: 2025-06-12T08:21:53.698944+05\nSyntaxError: invalid syntax in ctrl_flow.py\n\tat ctrl_flow.py:101\n\tat main.py:5"
  },
  {
    "job_id": "e6ac7df6",
    "source": "Hadoop",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:21:54.698944+05",
    "log": "[JobID: e6ac7df6] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:21:54.698944+05"
  },
  {
    "job_id": "1efac7de",
    "source": "Glue",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:22:06.698944+05",
    "log": "[JobID: 1efac7de] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:22:06.698944+05"
  },
  {
    "job_id": "aa791888",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:22:16.698944+05",
    "log": "[JobID: aa791888] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:22:16.698944+05"
  },
  {
    "job_id": "a0260b15",
    "source": "Flink",
    "filename": "countries61.csv",
    "output_file": "sorted_countries61.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:22:45.698944+05",
    "log": "[JobID: a0260b15] Execution completed | Status: SUCCESS | Output file: 'sorted_countries61.csv' | Source: Flink | Timestamp: 2025-06-12T08:22:45.698944+05"
  },
  {
    "job_id": "2d23b546",
    "source": "Spark",
    "filename": "countries98.csv",
    "output_file": "sorted_countries98.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:22:52.698944+05",
    "log": "[JobID: 2d23b546] Execution completed | Status: SUCCESS | Output file: 'sorted_countries98.csv' | Source: Spark | Timestamp: 2025-06-12T08:22:52.698944+05"
  },
  {
    "job_id": "67ecbc6c",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:22:57.698944+05",
    "log": "[JobID: 67ecbc6c] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:22:57.698944+05"
  },
  {
    "job_id": "4c76a2ce",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:23:15.698944+05",
    "log": "[JobID: 4c76a2ce] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:23:15.698944+05"
  },
  {
    "job_id": "0ad42e99",
    "source": "Flink",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:23:24.698944+05",
    "log": "[JobID: 0ad42e99] Execution failed | Status: FAILED | Error: AttributeError: 'NoneType' object has no attribute 'split' | Source: Flink | Timestamp: 2025-06-12T08:23:24.698944+05\nAttributeError: 'NoneType' object has no attribute 'split'\n\tat preprocess_data.py:33\n\tat main.py:78"
  },
  {
    "job_id": "66c66624",
    "source": "Spark",
    "filename": "countries30.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:23:28.698944+05",
    "log": "[JobID: 66c66624] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:23:28.698944+05"
  },
  {
    "job_id": "e6ac7df6",
    "source": "Hadoop",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:23:29.698944+05",
    "log": "[JobID: e6ac7df6] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:23:29.698944+05"
  },
  {
    "job_id": "d61849f8",
    "source": "Kafka",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:23:41.698944+05",
    "log": "[JobID: d61849f8] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T08:23:41.698944+05"
  },
  {
    "job_id": "e653541d",
    "source": "Airflow",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:25:28.698944+05",
    "log": "[JobID: e653541d] Execution failed | Status: FAILED | Error: org.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist | Source: Airflow | Timestamp: 2025-06-12T08:25:28.698944+05\norg.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist\n\tat org.apache.hadoop.fs.LocalFileSystem.open(LocalFileSystem.java:123)\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:67)"
  },
  {
    "job_id": "e6ac7df6",
    "source": "Hadoop",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:25:37.698944+05",
    "log": "[JobID: e6ac7df6] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:25:37.698944+05"
  },
  {
    "job_id": "1efac7de",
    "source": "Glue",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:25:46.698944+05",
    "log": "[JobID: 1efac7de] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:25:46.698944+05"
  },
  {
    "job_id": "b75b1fa0",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:25:48.698944+05",
    "log": "[JobID: b75b1fa0] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:25:48.698944+05"
  },
  {
    "job_id": "e28b2003",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:27:36.698944+05",
    "log": "[JobID: e28b2003] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:27:36.698944+05"
  },
  {
    "job_id": "e6ac7df6",
    "source": "Hadoop",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:27:53.698944+05",
    "log": "[JobID: e6ac7df6] Execution failed | Status: FAILED | Error: KeyError: 'user_id' | Source: Hadoop | Timestamp: 2025-06-12T08:27:53.698944+05\nKeyError: 'user_id'\n\tat transform_dict.py:75\n\tat process_request.py:34"
  },
  {
    "job_id": "03adfd94",
    "source": "Spark",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:27:55.698944+05",
    "log": "[JobID: 03adfd94] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:27:55.698944+05"
  },
  {
    "job_id": "4c76a2ce",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:28:03.698944+05",
    "log": "[JobID: 4c76a2ce] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:28:03.698944+05"
  },
  {
    "job_id": "66c66624",
    "source": "Spark",
    "filename": "countries30.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:28:07.698944+05",
    "log": "[JobID: 66c66624] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:28:07.698944+05"
  },
  {
    "job_id": "2ce26237",
    "source": "Spark",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:28:21.698944+05",
    "log": "[JobID: 2ce26237] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:28:21.698944+05"
  },
  {
    "job_id": "03adfd94",
    "source": "Spark",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:28:43.698944+05",
    "log": "[JobID: 03adfd94] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:28:43.698944+05"
  },
  {
    "job_id": "4c76a2ce",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:29:24.698944+05",
    "log": "[JobID: 4c76a2ce] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:29:24.698944+05"
  },
  {
    "job_id": "5144268d",
    "source": "Airflow",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:29:36.698944+05",
    "log": "[JobID: 5144268d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:29:36.698944+05"
  },
  {
    "job_id": "762faed2",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:29:58.698944+05",
    "log": "[JobID: 762faed2] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:29:58.698944+05"
  },
  {
    "job_id": "0b9f9cf0",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:30:18.698944+05",
    "log": "[JobID: 0b9f9cf0] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:30:18.698944+05"
  },
  {
    "job_id": "051cfd48",
    "source": "Glue",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:30:24.698944+05",
    "log": "[JobID: 051cfd48] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:30:24.698944+05"
  },
  {
    "job_id": "0ced5be1",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": "sorted_countries2.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:30:30.698944+05",
    "log": "[JobID: 0ced5be1] Execution completed | Status: SUCCESS | Output file: 'sorted_countries2.csv' | Source: Flink | Timestamp: 2025-06-12T08:30:30.698944+05"
  },
  {
    "job_id": "b75b1fa0",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:30:33.698944+05",
    "log": "[JobID: b75b1fa0] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:30:33.698944+05"
  },
  {
    "job_id": "66c66624",
    "source": "Spark",
    "filename": "countries30.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:30:51.698944+05",
    "log": "[JobID: 66c66624] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:30:51.698944+05"
  },
  {
    "job_id": "9292c162",
    "source": "Flink",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:30:57.698944+05",
    "log": "[JobID: 9292c162] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:30:57.698944+05"
  },
  {
    "job_id": "051cfd48",
    "source": "Glue",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:31:02.698944+05",
    "log": "[JobID: 051cfd48] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:31:02.698944+05"
  },
  {
    "job_id": "9292c162",
    "source": "Flink",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:31:38.698944+05",
    "log": "[JobID: 9292c162] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:31:38.698944+05"
  },
  {
    "job_id": "e28b2003",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:31:44.698944+05",
    "log": "[JobID: e28b2003] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:31:44.698944+05"
  },
  {
    "job_id": "0b9f9cf0",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:32:17.698944+05",
    "log": "[JobID: 0b9f9cf0] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:32:17.698944+05"
  },
  {
    "job_id": "03adfd94",
    "source": "Spark",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:32:22.698944+05",
    "log": "[JobID: 03adfd94] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:32:22.698944+05"
  },
  {
    "job_id": "46d7eca2",
    "source": "Hadoop",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:32:40.698944+05",
    "log": "[JobID: 46d7eca2] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:32:40.698944+05"
  },
  {
    "job_id": "5144268d",
    "source": "Airflow",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:33:08.698944+05",
    "log": "[JobID: 5144268d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:33:08.698944+05"
  },
  {
    "job_id": "4a1cb4f9",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:33:11.698944+05",
    "log": "[JobID: 4a1cb4f9] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T08:33:11.698944+05"
  },
  {
    "job_id": "051cfd48",
    "source": "Glue",
    "filename": "countries12.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:33:15.698944+05",
    "log": "[JobID: 051cfd48] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:33:15.698944+05"
  },
  {
    "job_id": "2ce26237",
    "source": "Spark",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:33:18.698944+05",
    "log": "[JobID: 2ce26237] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:33:18.698944+05"
  },
  {
    "job_id": "b75b1fa0",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": "sorted_countries26.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:33:32.698944+05",
    "log": "[JobID: b75b1fa0] Execution completed | Status: SUCCESS | Output file: 'sorted_countries26.csv' | Source: Flink | Timestamp: 2025-06-12T08:33:32.698944+05"
  },
  {
    "job_id": "e28b2003",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:33:43.698944+05",
    "log": "[JobID: e28b2003] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:33:43.698944+05"
  },
  {
    "job_id": "762faed2",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:33:45.698944+05",
    "log": "[JobID: 762faed2] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:33:45.698944+05"
  },
  {
    "job_id": "66c66624",
    "source": "Spark",
    "filename": "countries30.csv",
    "output_file": "sorted_countries30.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:33:47.698944+05",
    "log": "[JobID: 66c66624] Execution completed | Status: SUCCESS | Output file: 'sorted_countries30.csv' | Source: Spark | Timestamp: 2025-06-12T08:33:47.698944+05"
  },
  {
    "job_id": "46d7eca2",
    "source": "Hadoop",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:34:21.698944+05",
    "log": "[JobID: 46d7eca2] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:34:21.698944+05"
  },
  {
    "job_id": "4c76a2ce",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": "sorted_countries79.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:34:26.698944+05",
    "log": "[JobID: 4c76a2ce] Execution completed | Status: SUCCESS | Output file: 'sorted_countries79.csv' | Source: Spark | Timestamp: 2025-06-12T08:34:26.698944+05"
  },
  {
    "job_id": "b5639f5d",
    "source": "Spark",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:34:34.698944+05",
    "log": "[JobID: b5639f5d] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:34:34.698944+05"
  },
  {
    "job_id": "e310a78a",
    "source": "Kafka",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:34:50.698944+05",
    "log": "[JobID: e310a78a] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Kafka | Timestamp: 2025-06-12T08:34:50.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "46d7eca2",
    "source": "Hadoop",
    "filename": "countries62.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:35:04.698944+05",
    "log": "[JobID: 46d7eca2] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:35:04.698944+05"
  },
  {
    "job_id": "5e39090e",
    "source": "Flink",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:35:07.698944+05",
    "log": "[JobID: 5e39090e] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:35:07.698944+05"
  },
  {
    "job_id": "96095f85",
    "source": "Hadoop",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:35:14.698944+05",
    "log": "[JobID: 96095f85] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Hadoop | Timestamp: 2025-06-12T08:35:14.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "4a1cb4f9",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:35:19.698944+05",
    "log": "[JobID: 4a1cb4f9] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T08:35:19.698944+05"
  },
  {
    "job_id": "0b9f9cf0",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:35:41.698944+05",
    "log": "[JobID: 0b9f9cf0] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:35:41.698944+05"
  },
  {
    "job_id": "03adfd94",
    "source": "Spark",
    "filename": "countries45.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:36:01.698944+05",
    "log": "[JobID: 03adfd94] Execution failed | Status: FAILED | Error: org.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist | Source: Spark | Timestamp: 2025-06-12T08:36:01.698944+05\norg.apache.hadoop.fs.FileNotFoundException: File /user/hadoop/input.txt does not exist\n\tat org.apache.hadoop.fs.LocalFileSystem.open(LocalFileSystem.java:123)\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:67)"
  },
  {
    "job_id": "5144268d",
    "source": "Airflow",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:36:16.698944+05",
    "log": "[JobID: 5144268d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:36:16.698944+05"
  },
  {
    "job_id": "9292c162",
    "source": "Flink",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:36:30.698944+05",
    "log": "[JobID: 9292c162] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:36:30.698944+05"
  },
  {
    "job_id": "f7103702",
    "source": "Airflow",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:37:07.698944+05",
    "log": "[JobID: f7103702] Execution failed | Status: FAILED | Error: ImportError: cannot import name 'DataFrame' from 'pandas' | Source: Airflow | Timestamp: 2025-06-12T08:37:07.698944+05\nImportError: cannot import name 'DataFrame' from 'pandas'\n\tat analysis.py:25\n\tat main_script.py:12"
  },
  {
    "job_id": "1efac7de",
    "source": "Glue",
    "filename": "countries50.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:37:12.698944+05",
    "log": "[JobID: 1efac7de] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db' | Source: Glue | Timestamp: 2025-06-12T08:37:12.698944+05\ncom.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db'\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:350)\n\tat com.amazonaws.services.glue.AWSGlueClient.getTable(AWSGlueClient.java:115)"
  },
  {
    "job_id": "2ce26237",
    "source": "Spark",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:37:15.698944+05",
    "log": "[JobID: 2ce26237] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:37:15.698944+05"
  },
  {
    "job_id": "4a1cb4f9",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:37:23.698944+05",
    "log": "[JobID: 4a1cb4f9] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T08:37:23.698944+05"
  },
  {
    "job_id": "256542ab",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:37:47.698944+05",
    "log": "[JobID: 256542ab] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:37:47.698944+05"
  },
  {
    "job_id": "d1f1aecb",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:38:03.698944+05",
    "log": "[JobID: d1f1aecb] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:38:03.698944+05"
  },
  {
    "job_id": "762faed2",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:38:20.698944+05",
    "log": "[JobID: 762faed2] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:38:20.698944+05"
  },
  {
    "job_id": "35771c9c",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:38:30.698944+05",
    "log": "[JobID: 35771c9c] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:38:30.698944+05"
  },
  {
    "job_id": "b5639f5d",
    "source": "Spark",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:38:41.698944+05",
    "log": "[JobID: b5639f5d] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:38:41.698944+05"
  },
  {
    "job_id": "256542ab",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:39:17.698944+05",
    "log": "[JobID: 256542ab] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:39:17.698944+05"
  },
  {
    "job_id": "5e39090e",
    "source": "Flink",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:39:22.698944+05",
    "log": "[JobID: 5e39090e] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:39:22.698944+05"
  },
  {
    "job_id": "ccf193e7",
    "source": "Glue",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:39:22.698944+05",
    "log": "[JobID: ccf193e7] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:39:22.698944+05"
  },
  {
    "job_id": "9292c162",
    "source": "Flink",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:39:31.698944+05",
    "log": "[JobID: 9292c162] Execution failed | Status: FAILED | Error: java.lang.IllegalStateException: Kafka consumer is not subscribed to any topics | Source: Flink | Timestamp: 2025-06-12T08:39:31.698944+05\njava.lang.IllegalStateException: Kafka consumer is not subscribed to any topics\n\tat org.apache.kafka.clients.consumer.ConsumerImpl.poll(ConsumerImpl.java:1010)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "b5639f5d",
    "source": "Spark",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:40:39.698944+05",
    "log": "[JobID: b5639f5d] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:40:39.698944+05"
  },
  {
    "job_id": "7e711bfd",
    "source": "Flink",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:41:00.698944+05",
    "log": "[JobID: 7e711bfd] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:41:00.698944+05"
  },
  {
    "job_id": "256542ab",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:41:05.698944+05",
    "log": "[JobID: 256542ab] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:41:05.698944+05"
  },
  {
    "job_id": "c79bee8e",
    "source": "Glue",
    "filename": "countries39.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:41:11.698944+05",
    "log": "[JobID: c79bee8e] Execution failed | Status: FAILED | Error: org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Input path does not exist: file:/data/missing.csv | Source: Glue | Timestamp: 2025-06-12T08:41:11.698944+05\norg.apache.hadoop.mapreduce.lib.input.FileInputFormat: Input path does not exist: file:/data/missing.csv\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:275)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJob(JobSubmitter.java:145)"
  },
  {
    "job_id": "527c3b78",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:41:15.698944+05",
    "log": "[JobID: 527c3b78] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:41:15.698944+05"
  },
  {
    "job_id": "35771c9c",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:41:29.698944+05",
    "log": "[JobID: 35771c9c] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:41:29.698944+05"
  },
  {
    "job_id": "d61849f8",
    "source": "Kafka",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:41:36.698944+05",
    "log": "[JobID: d61849f8] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Unable to create job due to insufficient permissions | Source: Kafka | Timestamp: 2025-06-12T08:41:36.698944+05\ncom.amazonaws.services.glue.GlueException: Unable to create job due to insufficient permissions\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:275)\n\tat com.amazonaws.services.glue.AWSGlueClient.createJob(AWSGlueClient.java:99)"
  },
  {
    "job_id": "4a1cb4f9",
    "source": "Kafka",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:41:39.698944+05",
    "log": "[JobID: 4a1cb4f9] Execution failed | Status: FAILED | Error: ZeroDivisionError: division by zero | Source: Kafka | Timestamp: 2025-06-12T08:41:39.698944+05\nZeroDivisionError: division by zero\n\tat calculate.py:87\n\tat main.py:54"
  },
  {
    "job_id": "46d7eca2",
    "source": "Hadoop",
    "filename": "countries62.csv",
    "output_file": "sorted_countries62.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:41:41.698944+05",
    "log": "[JobID: 46d7eca2] Execution completed | Status: SUCCESS | Output file: 'sorted_countries62.csv' | Source: Hadoop | Timestamp: 2025-06-12T08:41:41.698944+05"
  },
  {
    "job_id": "1f78cdf5",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:41:52.698944+05",
    "log": "[JobID: 1f78cdf5] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:41:52.698944+05"
  },
  {
    "job_id": "5e39090e",
    "source": "Flink",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:42:46.698944+05",
    "log": "[JobID: 5e39090e] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:42:46.698944+05"
  },
  {
    "job_id": "d1f1aecb",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:42:51.698944+05",
    "log": "[JobID: d1f1aecb] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:42:51.698944+05"
  },
  {
    "job_id": "05123010",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:42:58.698944+05",
    "log": "[JobID: 05123010] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:42:58.698944+05"
  },
  {
    "job_id": "1f78cdf5",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:43:22.698944+05",
    "log": "[JobID: 1f78cdf5] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:43:22.698944+05"
  },
  {
    "job_id": "4e160cec",
    "source": "Spark",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:43:38.698944+05",
    "log": "[JobID: 4e160cec] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:43:38.698944+05"
  },
  {
    "job_id": "1a6f0fe0",
    "source": "Airflow",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:43:48.698944+05",
    "log": "[JobID: 1a6f0fe0] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:43:48.698944+05"
  },
  {
    "job_id": "5ca95681",
    "source": "Airflow",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:44:01.698944+05",
    "log": "[JobID: 5ca95681] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:44:01.698944+05"
  },
  {
    "job_id": "ccf193e7",
    "source": "Glue",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:44:01.698944+05",
    "log": "[JobID: ccf193e7] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:44:01.698944+05"
  },
  {
    "job_id": "4e160cec",
    "source": "Spark",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:44:12.698944+05",
    "log": "[JobID: 4e160cec] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:44:12.698944+05"
  },
  {
    "job_id": "527c3b78",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:44:34.698944+05",
    "log": "[JobID: 527c3b78] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:44:34.698944+05"
  },
  {
    "job_id": "35771c9c",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:44:35.698944+05",
    "log": "[JobID: 35771c9c] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:44:35.698944+05"
  },
  {
    "job_id": "1a6f0fe0",
    "source": "Airflow",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:44:55.698944+05",
    "log": "[JobID: 1a6f0fe0] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:44:55.698944+05"
  },
  {
    "job_id": "7e711bfd",
    "source": "Flink",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:45:00.698944+05",
    "log": "[JobID: 7e711bfd] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:45:00.698944+05"
  },
  {
    "job_id": "527c3b78",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:45:07.698944+05",
    "log": "[JobID: 527c3b78] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:45:07.698944+05"
  },
  {
    "job_id": "051cfd48",
    "source": "Glue",
    "filename": "countries12.csv",
    "output_file": "sorted_countries12.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:45:13.698944+05",
    "log": "[JobID: 051cfd48] Execution completed | Status: SUCCESS | Output file: 'sorted_countries12.csv' | Source: Glue | Timestamp: 2025-06-12T08:45:13.698944+05"
  },
  {
    "job_id": "5ca95681",
    "source": "Airflow",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:45:25.698944+05",
    "log": "[JobID: 5ca95681] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:45:25.698944+05"
  },
  {
    "job_id": "1f78cdf5",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:45:44.698944+05",
    "log": "[JobID: 1f78cdf5] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:45:44.698944+05"
  },
  {
    "job_id": "150346b3",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:45:48.698944+05",
    "log": "[JobID: 150346b3] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:45:48.698944+05"
  },
  {
    "job_id": "4e160cec",
    "source": "Spark",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:46:27.698944+05",
    "log": "[JobID: 4e160cec] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:46:27.698944+05"
  },
  {
    "job_id": "150346b3",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:46:38.698944+05",
    "log": "[JobID: 150346b3] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:46:38.698944+05"
  },
  {
    "job_id": "05123010",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:46:39.698944+05",
    "log": "[JobID: 05123010] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:46:39.698944+05"
  },
  {
    "job_id": "f8abea5c",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:46:57.698944+05",
    "log": "[JobID: f8abea5c] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:46:57.698944+05"
  },
  {
    "job_id": "5ca95681",
    "source": "Airflow",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:47:06.698944+05",
    "log": "[JobID: 5ca95681] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:47:06.698944+05"
  },
  {
    "job_id": "aa791888",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": "sorted_countries86.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:47:10.698944+05",
    "log": "[JobID: aa791888] Execution completed | Status: SUCCESS | Output file: 'sorted_countries86.csv' | Source: Hadoop | Timestamp: 2025-06-12T08:47:10.698944+05"
  },
  {
    "job_id": "7e711bfd",
    "source": "Flink",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:47:18.698944+05",
    "log": "[JobID: 7e711bfd] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:47:18.698944+05"
  },
  {
    "job_id": "9904393e",
    "source": "Airflow",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:47:23.698944+05",
    "log": "[JobID: 9904393e] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:47:23.698944+05"
  },
  {
    "job_id": "d1f1aecb",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:47:36.698944+05",
    "log": "[JobID: d1f1aecb] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:47:36.698944+05"
  },
  {
    "job_id": "5ca95681",
    "source": "Airflow",
    "filename": "countries20.csv",
    "output_file": "sorted_countries20.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:47:58.698944+05",
    "log": "[JobID: 5ca95681] Execution completed | Status: SUCCESS | Output file: 'sorted_countries20.csv' | Source: Airflow | Timestamp: 2025-06-12T08:47:58.698944+05"
  },
  {
    "job_id": "ca260433",
    "source": "Glue",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:48:03.698944+05",
    "log": "[JobID: ca260433] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:48:03.698944+05"
  },
  {
    "job_id": "9904393e",
    "source": "Airflow",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:48:03.698944+05",
    "log": "[JobID: 9904393e] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:48:03.698944+05"
  },
  {
    "job_id": "4607b67f",
    "source": "Kafka",
    "filename": "countries64.csv",
    "output_file": "sorted_countries64.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:48:11.698944+05",
    "log": "[JobID: 4607b67f] Execution completed | Status: SUCCESS | Output file: 'sorted_countries64.csv' | Source: Kafka | Timestamp: 2025-06-12T08:48:11.698944+05"
  },
  {
    "job_id": "f8abea5c",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:48:31.698944+05",
    "log": "[JobID: f8abea5c] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:48:31.698944+05"
  },
  {
    "job_id": "ccf193e7",
    "source": "Glue",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:48:55.698944+05",
    "log": "[JobID: ccf193e7] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:48:55.698944+05"
  },
  {
    "job_id": "1a6f0fe0",
    "source": "Airflow",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:49:08.698944+05",
    "log": "[JobID: 1a6f0fe0] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:49:08.698944+05"
  },
  {
    "job_id": "150346b3",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:49:27.698944+05",
    "log": "[JobID: 150346b3] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:49:27.698944+05"
  },
  {
    "job_id": "0b9f9cf0",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": "sorted_countries29.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:49:35.698944+05",
    "log": "[JobID: 0b9f9cf0] Execution completed | Status: SUCCESS | Output file: 'sorted_countries29.csv' | Source: Glue | Timestamp: 2025-06-12T08:49:35.698944+05"
  },
  {
    "job_id": "ca260433",
    "source": "Glue",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:49:49.698944+05",
    "log": "[JobID: ca260433] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:49:49.698944+05"
  },
  {
    "job_id": "f8abea5c",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:50:13.698944+05",
    "log": "[JobID: f8abea5c] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:50:13.698944+05"
  },
  {
    "job_id": "2442226e",
    "source": "Flink",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:50:17.698944+05",
    "log": "[JobID: 2442226e] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:50:17.698944+05"
  },
  {
    "job_id": "05123010",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:50:36.698944+05",
    "log": "[JobID: 05123010] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T08:50:36.698944+05"
  },
  {
    "job_id": "67ecbc6c",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:51:35.698944+05",
    "log": "[JobID: 67ecbc6c] Execution failed | Status: FAILED | Error: FileExistsError: [Errno 17] File exists: '/tmp/output.csv' | Source: Spark | Timestamp: 2025-06-12T08:51:35.698944+05\nFileExistsError: [Errno 17] File exists: '/tmp/output.csv'\n\tat file_writer.py:66\n\tat main.py:25"
  },
  {
    "job_id": "9904393e",
    "source": "Airflow",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:52:18.698944+05",
    "log": "[JobID: 9904393e] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:52:18.698944+05"
  },
  {
    "job_id": "afbdc509",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:52:20.698944+05",
    "log": "[JobID: afbdc509] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T08:52:20.698944+05"
  },
  {
    "job_id": "5cd4a86d",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:52:21.698944+05",
    "log": "[JobID: 5cd4a86d] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T08:52:21.698944+05"
  },
  {
    "job_id": "ca260433",
    "source": "Glue",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:52:33.698944+05",
    "log": "[JobID: ca260433] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:52:33.698944+05"
  },
  {
    "job_id": "2442226e",
    "source": "Flink",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:52:50.698944+05",
    "log": "[JobID: 2442226e] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T08:52:50.698944+05"
  },
  {
    "job_id": "e28b2003",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:53:22.698944+05",
    "log": "[JobID: e28b2003] Execution failed | Status: FAILED | Error: KeyError: 'user_id' | Source: Airflow | Timestamp: 2025-06-12T08:53:22.698944+05\nKeyError: 'user_id'\n\tat transform_dict.py:75\n\tat process_request.py:34"
  },
  {
    "job_id": "5cd4a86d",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:53:29.698944+05",
    "log": "[JobID: 5cd4a86d] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T08:53:29.698944+05"
  },
  {
    "job_id": "afbdc509",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:53:35.698944+05",
    "log": "[JobID: afbdc509] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T08:53:35.698944+05"
  },
  {
    "job_id": "05123010",
    "source": "Spark",
    "filename": "countries95.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:53:42.698944+05",
    "log": "[JobID: 05123010] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: cannot resolve '`missingColumn`' given input columns: [id, name, age] | Source: Spark | Timestamp: 2025-06-12T08:53:42.698944+05\norg.apache.spark.sql.AnalysisException: cannot resolve '`missingColumn`' given input columns: [id, name, age]\n\tat org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.error(AnalysisError.scala:46)\n\tat org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.error(AnalysisError.scala:26)"
  },
  {
    "job_id": "b5639f5d",
    "source": "Spark",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:54:21.698944+05",
    "log": "[JobID: b5639f5d] Execution failed | Status: FAILED | Error: java.io.FileNotFoundException: /path/to/output/file (No such file or directory) | Source: Spark | Timestamp: 2025-06-12T08:54:21.698944+05\njava.io.FileNotFoundException: /path/to/output/file (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)"
  },
  {
    "job_id": "4e160cec",
    "source": "Spark",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:54:28.698944+05",
    "log": "[JobID: 4e160cec] Execution failed | Status: FAILED | Error: ValueError: invalid literal for int() with base 10: 'abc' | Source: Spark | Timestamp: 2025-06-12T08:54:28.698944+05\nValueError: invalid literal for int() with base 10: 'abc'\n\tat pandas_read.py:127\n\tat data_processing.py:42"
  },
  {
    "job_id": "5144268d",
    "source": "Airflow",
    "filename": "countries96.csv",
    "output_file": "sorted_countries96.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:54:31.698944+05",
    "log": "[JobID: 5144268d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries96.csv' | Source: Airflow | Timestamp: 2025-06-12T08:54:31.698944+05"
  },
  {
    "job_id": "1c21f3f6",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:54:39.698944+05",
    "log": "[JobID: 1c21f3f6] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:54:39.698944+05"
  },
  {
    "job_id": "150346b3",
    "source": "Hadoop",
    "filename": "countries86.csv",
    "output_file": "sorted_countries86.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T08:55:07.698944+05",
    "log": "[JobID: 150346b3] Execution completed | Status: SUCCESS | Output file: 'sorted_countries86.csv' | Source: Hadoop | Timestamp: 2025-06-12T08:55:07.698944+05"
  },
  {
    "job_id": "1c21f3f6",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:55:09.698944+05",
    "log": "[JobID: 1c21f3f6] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T08:55:09.698944+05"
  },
  {
    "job_id": "a9986e2a",
    "source": "Spark",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:56:34.698944+05",
    "log": "[JobID: a9986e2a] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T08:56:34.698944+05"
  },
  {
    "job_id": "1c21f3f6",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:56:45.698944+05",
    "log": "[JobID: 1c21f3f6] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T08:56:45.698944+05"
  },
  {
    "job_id": "5cd4a86d",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:57:24.698944+05",
    "log": "[JobID: 5cd4a86d] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T08:57:24.698944+05"
  },
  {
    "job_id": "2442226e",
    "source": "Flink",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:57:30.698944+05",
    "log": "[JobID: 2442226e] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T08:57:30.698944+05"
  },
  {
    "job_id": "ca260433",
    "source": "Glue",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:58:00.698944+05",
    "log": "[JobID: ca260433] Execution failed | Status: FAILED | Error: java.lang.RuntimeException: Failed to execute the Hadoop job | Source: Glue | Timestamp: 2025-06-12T08:58:00.698944+05\njava.lang.RuntimeException: Failed to execute the Hadoop job\n\tat org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:2119)\n\tat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:145)"
  },
  {
    "job_id": "e38c7da8",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:58:02.698944+05",
    "log": "[JobID: e38c7da8] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T08:58:02.698944+05"
  },
  {
    "job_id": "2535c586",
    "source": "Kafka",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:58:04.698944+05",
    "log": "[JobID: 2535c586] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T08:58:04.698944+05"
  },
  {
    "job_id": "afbdc509",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T08:58:12.698944+05",
    "log": "[JobID: afbdc509] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T08:58:12.698944+05"
  },
  {
    "job_id": "1a6f0fe0",
    "source": "Airflow",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T08:58:47.698944+05",
    "log": "[JobID: 1a6f0fe0] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db' | Source: Airflow | Timestamp: 2025-06-12T08:58:47.698944+05\ncom.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db'\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:350)\n\tat com.amazonaws.services.glue.AWSGlueClient.getTable(AWSGlueClient.java:115)"
  },
  {
    "job_id": "896b9278",
    "source": "Flink",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T08:59:22.698944+05",
    "log": "[JobID: 896b9278] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T08:59:22.698944+05"
  },
  {
    "job_id": "a9986e2a",
    "source": "Spark",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T08:59:35.698944+05",
    "log": "[JobID: a9986e2a] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T08:59:35.698944+05"
  },
  {
    "job_id": "35771c9c",
    "source": "Glue",
    "filename": "countries16.csv",
    "output_file": "sorted_countries16.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:00:13.698944+05",
    "log": "[JobID: 35771c9c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries16.csv' | Source: Glue | Timestamp: 2025-06-12T09:00:13.698944+05"
  },
  {
    "job_id": "896b9278",
    "source": "Flink",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:00:27.698944+05",
    "log": "[JobID: 896b9278] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:00:27.698944+05"
  },
  {
    "job_id": "0141a9b7",
    "source": "Glue",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:01:27.698944+05",
    "log": "[JobID: 0141a9b7] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:01:27.698944+05"
  },
  {
    "job_id": "c23841d0",
    "source": "Flink",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:02:08.698944+05",
    "log": "[JobID: c23841d0] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:02:08.698944+05"
  },
  {
    "job_id": "b3d8188a",
    "source": "Hadoop",
    "filename": "countries44.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:02:09.698944+05",
    "log": "[JobID: b3d8188a] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:02:09.698944+05"
  },
  {
    "job_id": "93535d2f",
    "source": "Flink",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:02:14.698944+05",
    "log": "[JobID: 93535d2f] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:02:14.698944+05"
  },
  {
    "job_id": "1c21f3f6",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": "sorted_countries58.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:02:26.698944+05",
    "log": "[JobID: 1c21f3f6] Execution completed | Status: SUCCESS | Output file: 'sorted_countries58.csv' | Source: Glue | Timestamp: 2025-06-12T09:02:26.698944+05"
  },
  {
    "job_id": "7e711bfd",
    "source": "Flink",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:02:37.698944+05",
    "log": "[JobID: 7e711bfd] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection | Source: Flink | Timestamp: 2025-06-12T09:02:37.698944+05\norg.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection\n\tat org.apache.spark.sql.catalyst.ScalaReflection$class.extract(ScalaReflection.scala:178)\n\tat org.apache.spark.sql.catalyst.ScalaReflection.extract(ScalaReflection.scala:55)"
  },
  {
    "job_id": "e38c7da8",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:02:41.698944+05",
    "log": "[JobID: e38c7da8] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:02:41.698944+05"
  },
  {
    "job_id": "2535c586",
    "source": "Kafka",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:02:49.698944+05",
    "log": "[JobID: 2535c586] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:02:49.698944+05"
  },
  {
    "job_id": "a9986e2a",
    "source": "Spark",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:02:54.698944+05",
    "log": "[JobID: a9986e2a] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T09:02:54.698944+05"
  },
  {
    "job_id": "4c269935",
    "source": "Kafka",
    "filename": "countries74.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:03:20.698944+05",
    "log": "[JobID: 4c269935] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:03:20.698944+05"
  },
  {
    "job_id": "2ce26237",
    "source": "Spark",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:03:33.698944+05",
    "log": "[JobID: 2ce26237] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db' | Source: Spark | Timestamp: 2025-06-12T09:03:33.698944+05\ncom.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db'\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:350)\n\tat com.amazonaws.services.glue.AWSGlueClient.getTable(AWSGlueClient.java:115)"
  },
  {
    "job_id": "896b9278",
    "source": "Flink",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:03:35.698944+05",
    "log": "[JobID: 896b9278] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:03:35.698944+05"
  },
  {
    "job_id": "2535c586",
    "source": "Kafka",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:03:39.698944+05",
    "log": "[JobID: 2535c586] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:03:39.698944+05"
  },
  {
    "job_id": "e38c7da8",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:03:40.698944+05",
    "log": "[JobID: e38c7da8] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:03:40.698944+05"
  },
  {
    "job_id": "f8abea5c",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": "sorted_countries66.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:04:00.698944+05",
    "log": "[JobID: f8abea5c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries66.csv' | Source: Hadoop | Timestamp: 2025-06-12T09:04:00.698944+05"
  },
  {
    "job_id": "762faed2",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:04:11.698944+05",
    "log": "[JobID: 762faed2] Execution failed | Status: FAILED | Error: FileNotFoundError: [Errno 2] No such file or directory: 'config.yaml' | Source: Glue | Timestamp: 2025-06-12T09:04:11.698944+05\nFileNotFoundError: [Errno 2] No such file or directory: 'config.yaml'\n\tat open_config.py:45\n\tat initialize.py:12"
  },
  {
    "job_id": "0141a9b7",
    "source": "Glue",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:04:20.698944+05",
    "log": "[JobID: 0141a9b7] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:04:20.698944+05"
  },
  {
    "job_id": "93535d2f",
    "source": "Flink",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:05:10.698944+05",
    "log": "[JobID: 93535d2f] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:05:10.698944+05"
  },
  {
    "job_id": "256542ab",
    "source": "Airflow",
    "filename": "countries71.csv",
    "output_file": "sorted_countries71.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:06:10.698944+05",
    "log": "[JobID: 256542ab] Execution completed | Status: SUCCESS | Output file: 'sorted_countries71.csv' | Source: Airflow | Timestamp: 2025-06-12T09:06:10.698944+05"
  },
  {
    "job_id": "0141a9b7",
    "source": "Glue",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:06:32.698944+05",
    "log": "[JobID: 0141a9b7] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:06:32.698944+05"
  },
  {
    "job_id": "57d0bc09",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:06:40.698944+05",
    "log": "[JobID: 57d0bc09] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:06:40.698944+05"
  },
  {
    "job_id": "c23841d0",
    "source": "Flink",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:06:46.698944+05",
    "log": "[JobID: c23841d0] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:06:46.698944+05"
  },
  {
    "job_id": "b3d8188a",
    "source": "Hadoop",
    "filename": "countries44.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:06:48.698944+05",
    "log": "[JobID: b3d8188a] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:06:48.698944+05"
  },
  {
    "job_id": "39698c06",
    "source": "Flink",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:06:53.698944+05",
    "log": "[JobID: 39698c06] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:06:53.698944+05"
  },
  {
    "job_id": "afbdc509",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:07:36.698944+05",
    "log": "[JobID: afbdc509] Execution failed | Status: FAILED | Error: java.io.FileNotFoundException: /path/to/output/file (No such file or directory) | Source: Airflow | Timestamp: 2025-06-12T09:07:36.698944+05\njava.io.FileNotFoundException: /path/to/output/file (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)"
  },
  {
    "job_id": "5e418aa8",
    "source": "Airflow",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:07:38.698944+05",
    "log": "[JobID: 5e418aa8] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:07:38.698944+05"
  },
  {
    "job_id": "4c269935",
    "source": "Kafka",
    "filename": "countries74.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:07:46.698944+05",
    "log": "[JobID: 4c269935] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:07:46.698944+05"
  },
  {
    "job_id": "c23841d0",
    "source": "Flink",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:07:52.698944+05",
    "log": "[JobID: c23841d0] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:07:52.698944+05"
  },
  {
    "job_id": "93535d2f",
    "source": "Flink",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:08:13.698944+05",
    "log": "[JobID: 93535d2f] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:08:13.698944+05"
  },
  {
    "job_id": "c6c2ecd5",
    "source": "Airflow",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:08:27.698944+05",
    "log": "[JobID: c6c2ecd5] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:08:27.698944+05"
  },
  {
    "job_id": "b3d8188a",
    "source": "Hadoop",
    "filename": "countries44.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:08:58.698944+05",
    "log": "[JobID: b3d8188a] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:08:58.698944+05"
  },
  {
    "job_id": "896b9278",
    "source": "Flink",
    "filename": "countries4.csv",
    "output_file": "sorted_countries4.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:09:03.698944+05",
    "log": "[JobID: 896b9278] Execution completed | Status: SUCCESS | Output file: 'sorted_countries4.csv' | Source: Flink | Timestamp: 2025-06-12T09:09:03.698944+05"
  },
  {
    "job_id": "d1bf4fcf",
    "source": "Glue",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:09:10.698944+05",
    "log": "[JobID: d1bf4fcf] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:09:10.698944+05"
  },
  {
    "job_id": "5e39090e",
    "source": "Flink",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:09:35.698944+05",
    "log": "[JobID: 5e39090e] Execution failed | Status: FAILED | Error: ValueError: time data '2025/13/01' does not match format '%Y-%m-%d' | Source: Flink | Timestamp: 2025-06-12T09:09:35.698944+05\nValueError: time data '2025/13/01' does not match format '%Y-%m-%d'\n\tat date_parser.py:78\n\tat scheduler.py:14"
  },
  {
    "job_id": "5e418aa8",
    "source": "Airflow",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:10:01.698944+05",
    "log": "[JobID: 5e418aa8] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:10:01.698944+05"
  },
  {
    "job_id": "f4814f96",
    "source": "Glue",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:10:26.698944+05",
    "log": "[JobID: f4814f96] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:10:26.698944+05"
  },
  {
    "job_id": "1f78cdf5",
    "source": "Glue",
    "filename": "countries36.csv",
    "output_file": "sorted_countries36.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:10:40.698944+05",
    "log": "[JobID: 1f78cdf5] Execution completed | Status: SUCCESS | Output file: 'sorted_countries36.csv' | Source: Glue | Timestamp: 2025-06-12T09:10:40.698944+05"
  },
  {
    "job_id": "2535c586",
    "source": "Kafka",
    "filename": "countries51.csv",
    "output_file": "sorted_countries51.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:11:04.698944+05",
    "log": "[JobID: 2535c586] Execution completed | Status: SUCCESS | Output file: 'sorted_countries51.csv' | Source: Kafka | Timestamp: 2025-06-12T09:11:04.698944+05"
  },
  {
    "job_id": "5e418aa8",
    "source": "Airflow",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:11:08.698944+05",
    "log": "[JobID: 5e418aa8] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:11:08.698944+05"
  },
  {
    "job_id": "c6c2ecd5",
    "source": "Airflow",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:11:08.698944+05",
    "log": "[JobID: c6c2ecd5] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:11:08.698944+05"
  },
  {
    "job_id": "57d0bc09",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:11:34.698944+05",
    "log": "[JobID: 57d0bc09] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:11:34.698944+05"
  },
  {
    "job_id": "39698c06",
    "source": "Flink",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:11:52.698944+05",
    "log": "[JobID: 39698c06] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:11:52.698944+05"
  },
  {
    "job_id": "57d0bc09",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:12:12.698944+05",
    "log": "[JobID: 57d0bc09] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:12:12.698944+05"
  },
  {
    "job_id": "4c269935",
    "source": "Kafka",
    "filename": "countries74.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:12:22.698944+05",
    "log": "[JobID: 4c269935] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:12:22.698944+05"
  },
  {
    "job_id": "fbcc24bd",
    "source": "Spark",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:12:25.698944+05",
    "log": "[JobID: fbcc24bd] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T09:12:25.698944+05"
  },
  {
    "job_id": "d1bf4fcf",
    "source": "Glue",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:12:51.698944+05",
    "log": "[JobID: d1bf4fcf] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:12:51.698944+05"
  },
  {
    "job_id": "056aaccd",
    "source": "Flink",
    "filename": "countries13.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:12:54.698944+05",
    "log": "[JobID: 056aaccd] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:12:54.698944+05"
  },
  {
    "job_id": "abc9e8d3",
    "source": "Airflow",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:13:30.698944+05",
    "log": "[JobID: abc9e8d3] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:13:30.698944+05"
  },
  {
    "job_id": "f4814f96",
    "source": "Glue",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:13:32.698944+05",
    "log": "[JobID: f4814f96] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:13:32.698944+05"
  },
  {
    "job_id": "f15a7b3f",
    "source": "Hadoop",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:13:48.698944+05",
    "log": "[JobID: f15a7b3f] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:13:48.698944+05"
  },
  {
    "job_id": "bb51154f",
    "source": "Hadoop",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:13:51.698944+05",
    "log": "[JobID: bb51154f] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:13:51.698944+05"
  },
  {
    "job_id": "527c3b78",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:13:52.698944+05",
    "log": "[JobID: 527c3b78] Execution failed | Status: FAILED | Error: FileExistsError: [Errno 17] File exists: '/tmp/output.csv' | Source: Glue | Timestamp: 2025-06-12T09:13:52.698944+05\nFileExistsError: [Errno 17] File exists: '/tmp/output.csv'\n\tat file_writer.py:66\n\tat main.py:25"
  },
  {
    "job_id": "c6c2ecd5",
    "source": "Airflow",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:14:16.698944+05",
    "log": "[JobID: c6c2ecd5] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:14:16.698944+05"
  },
  {
    "job_id": "39698c06",
    "source": "Flink",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:14:20.698944+05",
    "log": "[JobID: 39698c06] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:14:20.698944+05"
  },
  {
    "job_id": "fbcc24bd",
    "source": "Spark",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:14:20.698944+05",
    "log": "[JobID: fbcc24bd] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T09:14:20.698944+05"
  },
  {
    "job_id": "abc9e8d3",
    "source": "Airflow",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:14:41.698944+05",
    "log": "[JobID: abc9e8d3] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:14:41.698944+05"
  },
  {
    "job_id": "f15a7b3f",
    "source": "Hadoop",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:14:53.698944+05",
    "log": "[JobID: f15a7b3f] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:14:53.698944+05"
  },
  {
    "job_id": "056aaccd",
    "source": "Flink",
    "filename": "countries13.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:14:58.698944+05",
    "log": "[JobID: 056aaccd] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:14:58.698944+05"
  },
  {
    "job_id": "f8b441ca",
    "source": "Flink",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:15:05.698944+05",
    "log": "[JobID: f8b441ca] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:15:05.698944+05"
  },
  {
    "job_id": "abc9e8d3",
    "source": "Airflow",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:15:13.698944+05",
    "log": "[JobID: abc9e8d3] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:15:13.698944+05"
  },
  {
    "job_id": "d1f1aecb",
    "source": "Glue",
    "filename": "countries20.csv",
    "output_file": "sorted_countries20.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:15:28.698944+05",
    "log": "[JobID: d1f1aecb] Execution completed | Status: SUCCESS | Output file: 'sorted_countries20.csv' | Source: Glue | Timestamp: 2025-06-12T09:15:28.698944+05"
  },
  {
    "job_id": "f15a7b3f",
    "source": "Hadoop",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:16:07.698944+05",
    "log": "[JobID: f15a7b3f] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:16:07.698944+05"
  },
  {
    "job_id": "2442226e",
    "source": "Flink",
    "filename": "countries14.csv",
    "output_file": "sorted_countries14.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:16:36.698944+05",
    "log": "[JobID: 2442226e] Execution completed | Status: SUCCESS | Output file: 'sorted_countries14.csv' | Source: Flink | Timestamp: 2025-06-12T09:16:36.698944+05"
  },
  {
    "job_id": "056aaccd",
    "source": "Flink",
    "filename": "countries13.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:16:38.698944+05",
    "log": "[JobID: 056aaccd] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:16:38.698944+05"
  },
  {
    "job_id": "fbcc24bd",
    "source": "Spark",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:16:56.698944+05",
    "log": "[JobID: fbcc24bd] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T09:16:56.698944+05"
  },
  {
    "job_id": "d1bf4fcf",
    "source": "Glue",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:17:04.698944+05",
    "log": "[JobID: d1bf4fcf] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:17:04.698944+05"
  },
  {
    "job_id": "f8b441ca",
    "source": "Flink",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:17:07.698944+05",
    "log": "[JobID: f8b441ca] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:17:07.698944+05"
  },
  {
    "job_id": "9904393e",
    "source": "Airflow",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:17:28.698944+05",
    "log": "[JobID: 9904393e] Execution failed | Status: FAILED | Error: java.lang.IllegalStateException: Kafka consumer is not subscribed to any topics | Source: Airflow | Timestamp: 2025-06-12T09:17:28.698944+05\njava.lang.IllegalStateException: Kafka consumer is not subscribed to any topics\n\tat org.apache.kafka.clients.consumer.ConsumerImpl.poll(ConsumerImpl.java:1010)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "5cd4a86d",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:17:58.698944+05",
    "log": "[JobID: 5cd4a86d] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.RecordTooLargeException: The message is 112345 bytes, which is larger than the maximum request size 1048576 bytes | Source: Hadoop | Timestamp: 2025-06-12T09:17:58.698944+05\norg.apache.kafka.common.errors.RecordTooLargeException: The message is 112345 bytes, which is larger than the maximum request size 1048576 bytes\n\tat org.apache.kafka.common.record.MemoryRecordsBuilder.append(MemoryRecordsBuilder.java:88)\n\tat org.apache.kafka.clients.producer.internals.TransactionManager.sendPrepare(TransactionManager.java:211)"
  },
  {
    "job_id": "f4814f96",
    "source": "Glue",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:18:10.698944+05",
    "log": "[JobID: f4814f96] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:18:10.698944+05"
  },
  {
    "job_id": "b3d8188a",
    "source": "Hadoop",
    "filename": "countries44.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:18:11.698944+05",
    "log": "[JobID: b3d8188a] Execution failed | Status: FAILED | Error: ValueError: not enough values to unpack (expected 3, got 2) | Source: Hadoop | Timestamp: 2025-06-12T09:18:11.698944+05\nValueError: not enough values to unpack (expected 3, got 2)\n\tat unpacker.py:44\n\tat main.py:27"
  },
  {
    "job_id": "bb51154f",
    "source": "Hadoop",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:18:43.698944+05",
    "log": "[JobID: bb51154f] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:18:43.698944+05"
  },
  {
    "job_id": "ccf193e7",
    "source": "Glue",
    "filename": "countries82.csv",
    "output_file": "sorted_countries82.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:18:50.698944+05",
    "log": "[JobID: ccf193e7] Execution completed | Status: SUCCESS | Output file: 'sorted_countries82.csv' | Source: Glue | Timestamp: 2025-06-12T09:18:50.698944+05"
  },
  {
    "job_id": "f15a7b3f",
    "source": "Hadoop",
    "filename": "countries94.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:19:00.698944+05",
    "log": "[JobID: f15a7b3f] Execution failed | Status: FAILED | Error: IOError: [Errno 13] Permission denied: '/var/log/app.log' | Source: Hadoop | Timestamp: 2025-06-12T09:19:00.698944+05\nIOError: [Errno 13] Permission denied: '/var/log/app.log'\n\tat log_writer.py:59\n\tat main.py:20"
  },
  {
    "job_id": "f8b441ca",
    "source": "Flink",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:19:13.698944+05",
    "log": "[JobID: f8b441ca] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:19:13.698944+05"
  },
  {
    "job_id": "57f1bd6c",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:20:41.698944+05",
    "log": "[JobID: 57f1bd6c] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:20:41.698944+05"
  },
  {
    "job_id": "de00b083",
    "source": "Spark",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:22:00.698944+05",
    "log": "[JobID: de00b083] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T09:22:00.698944+05"
  },
  {
    "job_id": "fbcc24bd",
    "source": "Spark",
    "filename": "countries71.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:22:00.698944+05",
    "log": "[JobID: fbcc24bd] Execution failed | Status: FAILED | Error: KeyError: 'user_id' | Source: Spark | Timestamp: 2025-06-12T09:22:00.698944+05\nKeyError: 'user_id'\n\tat transform_dict.py:75\n\tat process_request.py:34"
  },
  {
    "job_id": "bb51154f",
    "source": "Hadoop",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:22:32.698944+05",
    "log": "[JobID: bb51154f] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:22:32.698944+05"
  },
  {
    "job_id": "de00b083",
    "source": "Spark",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:22:43.698944+05",
    "log": "[JobID: de00b083] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T09:22:43.698944+05"
  },
  {
    "job_id": "39698c06",
    "source": "Flink",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:22:56.698944+05",
    "log": "[JobID: 39698c06] Execution failed | Status: FAILED | Error: java.net.ConnectException: Connection refused (Connection refused) | Source: Flink | Timestamp: 2025-06-12T09:22:56.698944+05\njava.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)"
  },
  {
    "job_id": "57f1bd6c",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:23:15.698944+05",
    "log": "[JobID: 57f1bd6c] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:23:15.698944+05"
  },
  {
    "job_id": "3846a243",
    "source": "Kafka",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:24:18.698944+05",
    "log": "[JobID: 3846a243] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:24:18.698944+05"
  },
  {
    "job_id": "57f1bd6c",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:25:13.698944+05",
    "log": "[JobID: 57f1bd6c] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:25:13.698944+05"
  },
  {
    "job_id": "3846a243",
    "source": "Kafka",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:25:20.698944+05",
    "log": "[JobID: 3846a243] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:25:20.698944+05"
  },
  {
    "job_id": "de00b083",
    "source": "Spark",
    "filename": "countries54.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:25:24.698944+05",
    "log": "[JobID: de00b083] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T09:25:24.698944+05"
  },
  {
    "job_id": "f5d04123",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:25:32.698944+05",
    "log": "[JobID: f5d04123] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:25:32.698944+05"
  },
  {
    "job_id": "f4814f96",
    "source": "Glue",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:25:53.698944+05",
    "log": "[JobID: f4814f96] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection | Source: Glue | Timestamp: 2025-06-12T09:25:53.698944+05\norg.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection\n\tat org.apache.spark.sql.catalyst.ScalaReflection$class.extract(ScalaReflection.scala:178)\n\tat org.apache.spark.sql.catalyst.ScalaReflection.extract(ScalaReflection.scala:55)"
  },
  {
    "job_id": "c6c2ecd5",
    "source": "Airflow",
    "filename": "countries51.csv",
    "output_file": "sorted_countries51.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:25:59.698944+05",
    "log": "[JobID: c6c2ecd5] Execution completed | Status: SUCCESS | Output file: 'sorted_countries51.csv' | Source: Airflow | Timestamp: 2025-06-12T09:25:59.698944+05"
  },
  {
    "job_id": "f8b441ca",
    "source": "Flink",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:26:18.698944+05",
    "log": "[JobID: f8b441ca] Execution failed | Status: FAILED | Error: java.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod() | Source: Flink | Timestamp: 2025-06-12T09:26:18.698944+05\njava.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod()\n\tat com.example.Updater.runUpdate(Updater.java:47)\n\tat com.example.Main.start(Main.java:30)"
  },
  {
    "job_id": "3846a243",
    "source": "Kafka",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:26:25.698944+05",
    "log": "[JobID: 3846a243] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:26:25.698944+05"
  },
  {
    "job_id": "3846a243",
    "source": "Kafka",
    "filename": "countries59.csv",
    "output_file": "sorted_countries59.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:26:50.698944+05",
    "log": "[JobID: 3846a243] Execution completed | Status: SUCCESS | Output file: 'sorted_countries59.csv' | Source: Kafka | Timestamp: 2025-06-12T09:26:50.698944+05"
  },
  {
    "job_id": "f5d04123",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:27:32.698944+05",
    "log": "[JobID: f5d04123] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:27:32.698944+05"
  },
  {
    "job_id": "d34e2507",
    "source": "Glue",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:27:43.698944+05",
    "log": "[JobID: d34e2507] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:27:43.698944+05"
  },
  {
    "job_id": "a9986e2a",
    "source": "Spark",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:27:46.698944+05",
    "log": "[JobID: a9986e2a] Execution failed | Status: FAILED | Error: RuntimeError: maximum recursion depth exceeded while calling a Python object | Source: Spark | Timestamp: 2025-06-12T09:27:46.698944+05\nRuntimeError: maximum recursion depth exceeded while calling a Python object\n\tat recursion.py:33\n\tat main.py:78"
  },
  {
    "job_id": "f5d04123",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:28:48.698944+05",
    "log": "[JobID: f5d04123] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:28:48.698944+05"
  },
  {
    "job_id": "b607bbb0",
    "source": "Glue",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:29:04.698944+05",
    "log": "[JobID: b607bbb0] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:29:04.698944+05"
  },
  {
    "job_id": "e38c7da8",
    "source": "Glue",
    "filename": "countries29.csv",
    "output_file": "sorted_countries29.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:29:38.698944+05",
    "log": "[JobID: e38c7da8] Execution completed | Status: SUCCESS | Output file: 'sorted_countries29.csv' | Source: Glue | Timestamp: 2025-06-12T09:29:38.698944+05"
  },
  {
    "job_id": "5e418aa8",
    "source": "Airflow",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:30:11.698944+05",
    "log": "[JobID: 5e418aa8] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.AuthenticationException: The broker requires authentication | Source: Airflow | Timestamp: 2025-06-12T09:30:11.698944+05\norg.apache.kafka.common.errors.AuthenticationException: The broker requires authentication\n\tat org.apache.kafka.clients.NetworkClient.initiateHandshake(NetworkClient.java:450)\n\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:45)"
  },
  {
    "job_id": "60f70701",
    "source": "Airflow",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:30:54.698944+05",
    "log": "[JobID: 60f70701] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:30:54.698944+05"
  },
  {
    "job_id": "d34e2507",
    "source": "Glue",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:31:37.698944+05",
    "log": "[JobID: d34e2507] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:31:37.698944+05"
  },
  {
    "job_id": "b607bbb0",
    "source": "Glue",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:31:41.698944+05",
    "log": "[JobID: b607bbb0] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:31:41.698944+05"
  },
  {
    "job_id": "d34e2507",
    "source": "Glue",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:32:09.698944+05",
    "log": "[JobID: d34e2507] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:32:09.698944+05"
  },
  {
    "job_id": "f56ded2b",
    "source": "Kafka",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:32:15.698944+05",
    "log": "[JobID: f56ded2b] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:32:15.698944+05"
  },
  {
    "job_id": "93535d2f",
    "source": "Flink",
    "filename": "countries56.csv",
    "output_file": "sorted_countries56.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:32:49.698944+05",
    "log": "[JobID: 93535d2f] Execution completed | Status: SUCCESS | Output file: 'sorted_countries56.csv' | Source: Flink | Timestamp: 2025-06-12T09:32:49.698944+05"
  },
  {
    "job_id": "0141a9b7",
    "source": "Glue",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:33:36.698944+05",
    "log": "[JobID: 0141a9b7] Execution failed | Status: FAILED | Error: ValueError: math domain error | Source: Glue | Timestamp: 2025-06-12T09:33:36.698944+05\nValueError: math domain error\n\tat compute_math.py:88\n\tat process.py:15"
  },
  {
    "job_id": "f56ded2b",
    "source": "Kafka",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:34:12.698944+05",
    "log": "[JobID: f56ded2b] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:34:12.698944+05"
  },
  {
    "job_id": "354eee1d",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:34:38.698944+05",
    "log": "[JobID: 354eee1d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:34:38.698944+05"
  },
  {
    "job_id": "911b3819",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:34:58.698944+05",
    "log": "[JobID: 911b3819] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:34:58.698944+05"
  },
  {
    "job_id": "abc9e8d3",
    "source": "Airflow",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:35:12.698944+05",
    "log": "[JobID: abc9e8d3] Execution failed | Status: FAILED | Error: FileExistsError: [Errno 17] File exists: '/tmp/output.csv' | Source: Airflow | Timestamp: 2025-06-12T09:35:12.698944+05\nFileExistsError: [Errno 17] File exists: '/tmp/output.csv'\n\tat file_writer.py:66\n\tat main.py:25"
  },
  {
    "job_id": "b607bbb0",
    "source": "Glue",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:35:22.698944+05",
    "log": "[JobID: b607bbb0] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:35:22.698944+05"
  },
  {
    "job_id": "d1bf4fcf",
    "source": "Glue",
    "filename": "countries42.csv",
    "output_file": "sorted_countries42.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:35:26.698944+05",
    "log": "[JobID: d1bf4fcf] Execution completed | Status: SUCCESS | Output file: 'sorted_countries42.csv' | Source: Glue | Timestamp: 2025-06-12T09:35:26.698944+05"
  },
  {
    "job_id": "c23841d0",
    "source": "Flink",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:35:47.698944+05",
    "log": "[JobID: c23841d0] Execution failed | Status: FAILED | Error: org.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file | Source: Flink | Timestamp: 2025-06-12T09:35:47.698944+05\norg.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file\n\tat org.apache.hadoop.hdfs.DFSUtilClient.call(DFSUtilClient.java:103)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.exists(DistributedFileSystem.java:219)"
  },
  {
    "job_id": "60f70701",
    "source": "Airflow",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:35:52.698944+05",
    "log": "[JobID: 60f70701] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:35:52.698944+05"
  },
  {
    "job_id": "6c3f793d",
    "source": "Flink",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:36:46.698944+05",
    "log": "[JobID: 6c3f793d] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:36:46.698944+05"
  },
  {
    "job_id": "f56ded2b",
    "source": "Kafka",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:37:07.698944+05",
    "log": "[JobID: f56ded2b] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:37:07.698944+05"
  },
  {
    "job_id": "4c269935",
    "source": "Kafka",
    "filename": "countries74.csv",
    "output_file": "sorted_countries74.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:37:15.698944+05",
    "log": "[JobID: 4c269935] Execution completed | Status: SUCCESS | Output file: 'sorted_countries74.csv' | Source: Kafka | Timestamp: 2025-06-12T09:37:15.698944+05"
  },
  {
    "job_id": "96e30a4f",
    "source": "Glue",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:37:16.698944+05",
    "log": "[JobID: 96e30a4f] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:37:16.698944+05"
  },
  {
    "job_id": "056aaccd",
    "source": "Flink",
    "filename": "countries13.csv",
    "output_file": "sorted_countries13.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:37:53.698944+05",
    "log": "[JobID: 056aaccd] Execution completed | Status: SUCCESS | Output file: 'sorted_countries13.csv' | Source: Flink | Timestamp: 2025-06-12T09:37:53.698944+05"
  },
  {
    "job_id": "354eee1d",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:38:24.698944+05",
    "log": "[JobID: 354eee1d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:38:24.698944+05"
  },
  {
    "job_id": "6c3f793d",
    "source": "Flink",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:39:13.698944+05",
    "log": "[JobID: 6c3f793d] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:39:13.698944+05"
  },
  {
    "job_id": "60f70701",
    "source": "Airflow",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:39:18.698944+05",
    "log": "[JobID: 60f70701] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:39:18.698944+05"
  },
  {
    "job_id": "911b3819",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:39:30.698944+05",
    "log": "[JobID: 911b3819] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:39:30.698944+05"
  },
  {
    "job_id": "aae02640",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:39:33.698944+05",
    "log": "[JobID: aae02640] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:39:33.698944+05"
  },
  {
    "job_id": "70fca041",
    "source": "Spark",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:39:54.698944+05",
    "log": "[JobID: 70fca041] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T09:39:54.698944+05"
  },
  {
    "job_id": "8c400645",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:39:55.698944+05",
    "log": "[JobID: 8c400645] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:39:55.698944+05"
  },
  {
    "job_id": "96e30a4f",
    "source": "Glue",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:40:00.698944+05",
    "log": "[JobID: 96e30a4f] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:40:00.698944+05"
  },
  {
    "job_id": "b9f61f11",
    "source": "Spark",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:40:20.698944+05",
    "log": "[JobID: b9f61f11] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T09:40:20.698944+05"
  },
  {
    "job_id": "bb51154f",
    "source": "Hadoop",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:40:38.698944+05",
    "log": "[JobID: bb51154f] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Resolved attribute(s) missing from input data: [id]. | Source: Hadoop | Timestamp: 2025-06-12T09:40:38.698944+05\norg.apache.spark.sql.AnalysisException: Resolved attribute(s) missing from input data: [id].\n\tat org.apache.spark.sql.catalyst.analysis.ResolveMissingColumns$.failAnalysis(AnalysisError.scala:100)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:500)"
  },
  {
    "job_id": "de00b083",
    "source": "Spark",
    "filename": "countries54.csv",
    "output_file": "sorted_countries54.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:40:49.698944+05",
    "log": "[JobID: de00b083] Execution completed | Status: SUCCESS | Output file: 'sorted_countries54.csv' | Source: Spark | Timestamp: 2025-06-12T09:40:49.698944+05"
  },
  {
    "job_id": "6c3f793d",
    "source": "Flink",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:41:03.698944+05",
    "log": "[JobID: 6c3f793d] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T09:41:03.698944+05"
  },
  {
    "job_id": "eb040bea",
    "source": "Kafka",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:41:22.698944+05",
    "log": "[JobID: eb040bea] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:41:22.698944+05"
  },
  {
    "job_id": "bd6c994c",
    "source": "Hadoop",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:41:23.698944+05",
    "log": "[JobID: bd6c994c] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T09:41:23.698944+05"
  },
  {
    "job_id": "57d0bc09",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": "sorted_countries56.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:41:41.698944+05",
    "log": "[JobID: 57d0bc09] Execution completed | Status: SUCCESS | Output file: 'sorted_countries56.csv' | Source: Hadoop | Timestamp: 2025-06-12T09:41:41.698944+05"
  },
  {
    "job_id": "8c400645",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:42:07.698944+05",
    "log": "[JobID: 8c400645] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:42:07.698944+05"
  },
  {
    "job_id": "96e30a4f",
    "source": "Glue",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:42:39.698944+05",
    "log": "[JobID: 96e30a4f] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:42:39.698944+05"
  },
  {
    "job_id": "911b3819",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:42:42.698944+05",
    "log": "[JobID: 911b3819] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:42:42.698944+05"
  },
  {
    "job_id": "d34e2507",
    "source": "Glue",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:42:42.698944+05",
    "log": "[JobID: d34e2507] Execution failed | Status: FAILED | Error: ZeroDivisionError: division by zero | Source: Glue | Timestamp: 2025-06-12T09:42:42.698944+05\nZeroDivisionError: division by zero\n\tat calculate.py:87\n\tat main.py:54"
  },
  {
    "job_id": "354eee1d",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:42:45.698944+05",
    "log": "[JobID: 354eee1d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:42:45.698944+05"
  },
  {
    "job_id": "aae02640",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:43:17.698944+05",
    "log": "[JobID: aae02640] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:43:17.698944+05"
  },
  {
    "job_id": "70fca041",
    "source": "Spark",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:43:48.698944+05",
    "log": "[JobID: 70fca041] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T09:43:48.698944+05"
  },
  {
    "job_id": "78b3c2e5",
    "source": "Glue",
    "filename": "countries92.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:43:59.698944+05",
    "log": "[JobID: 78b3c2e5] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:43:59.698944+05"
  },
  {
    "job_id": "70fca041",
    "source": "Spark",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:44:40.698944+05",
    "log": "[JobID: 70fca041] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T09:44:40.698944+05"
  },
  {
    "job_id": "bd6c994c",
    "source": "Hadoop",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:44:43.698944+05",
    "log": "[JobID: bd6c994c] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T09:44:43.698944+05"
  },
  {
    "job_id": "eb040bea",
    "source": "Kafka",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:45:00.698944+05",
    "log": "[JobID: eb040bea] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:45:00.698944+05"
  },
  {
    "job_id": "6c3f793d",
    "source": "Flink",
    "filename": "countries93.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:45:12.698944+05",
    "log": "[JobID: 6c3f793d] Execution failed | Status: FAILED | Error: java.io.FileNotFoundException: /path/to/output/file (No such file or directory) | Source: Flink | Timestamp: 2025-06-12T09:45:12.698944+05\njava.io.FileNotFoundException: /path/to/output/file (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)"
  },
  {
    "job_id": "b9f61f11",
    "source": "Spark",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:45:20.698944+05",
    "log": "[JobID: b9f61f11] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T09:45:20.698944+05"
  },
  {
    "job_id": "076cbadb",
    "source": "Airflow",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:45:28.698944+05",
    "log": "[JobID: 076cbadb] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T09:45:28.698944+05"
  },
  {
    "job_id": "b9f61f11",
    "source": "Spark",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:46:06.698944+05",
    "log": "[JobID: b9f61f11] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T09:46:06.698944+05"
  },
  {
    "job_id": "aae02640",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:46:06.698944+05",
    "log": "[JobID: aae02640] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:46:06.698944+05"
  },
  {
    "job_id": "60f70701",
    "source": "Airflow",
    "filename": "countries66.csv",
    "output_file": "sorted_countries66.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:46:51.698944+05",
    "log": "[JobID: 60f70701] Execution completed | Status: SUCCESS | Output file: 'sorted_countries66.csv' | Source: Airflow | Timestamp: 2025-06-12T09:46:51.698944+05"
  },
  {
    "job_id": "bd6c994c",
    "source": "Hadoop",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:46:52.698944+05",
    "log": "[JobID: bd6c994c] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T09:46:52.698944+05"
  },
  {
    "job_id": "8c400645",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:47:06.698944+05",
    "log": "[JobID: 8c400645] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:47:06.698944+05"
  },
  {
    "job_id": "78b3c2e5",
    "source": "Glue",
    "filename": "countries92.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:47:26.698944+05",
    "log": "[JobID: 78b3c2e5] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T09:47:26.698944+05"
  },
  {
    "job_id": "57f1bd6c",
    "source": "Hadoop",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:48:03.698944+05",
    "log": "[JobID: 57f1bd6c] Execution failed | Status: FAILED | Error: FileNotFoundError: [Errno 2] No such file or directory: 'config.yaml' | Source: Hadoop | Timestamp: 2025-06-12T09:48:03.698944+05\nFileNotFoundError: [Errno 2] No such file or directory: 'config.yaml'\n\tat open_config.py:45\n\tat initialize.py:12"
  },
  {
    "job_id": "78b3c2e5",
    "source": "Glue",
    "filename": "countries92.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:49:05.698944+05",
    "log": "[JobID: 78b3c2e5] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T09:49:05.698944+05"
  },
  {
    "job_id": "eb040bea",
    "source": "Kafka",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:49:09.698944+05",
    "log": "[JobID: eb040bea] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:49:09.698944+05"
  },
  {
    "job_id": "f5d04123",
    "source": "Glue",
    "filename": "countries83.csv",
    "output_file": "sorted_countries83.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:49:47.698944+05",
    "log": "[JobID: f5d04123] Execution completed | Status: SUCCESS | Output file: 'sorted_countries83.csv' | Source: Glue | Timestamp: 2025-06-12T09:49:47.698944+05"
  },
  {
    "job_id": "78b3c2e5",
    "source": "Glue",
    "filename": "countries92.csv",
    "output_file": "sorted_countries92.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:49:58.698944+05",
    "log": "[JobID: 78b3c2e5] Execution completed | Status: SUCCESS | Output file: 'sorted_countries92.csv' | Source: Glue | Timestamp: 2025-06-12T09:49:58.698944+05"
  },
  {
    "job_id": "076cbadb",
    "source": "Airflow",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:50:08.698944+05",
    "log": "[JobID: 076cbadb] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T09:50:08.698944+05"
  },
  {
    "job_id": "b607bbb0",
    "source": "Glue",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:50:12.698944+05",
    "log": "[JobID: b607bbb0] Execution failed | Status: FAILED | Error: java.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod() | Source: Glue | Timestamp: 2025-06-12T09:50:12.698944+05\njava.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod()\n\tat com.example.Updater.runUpdate(Updater.java:47)\n\tat com.example.Main.start(Main.java:30)"
  },
  {
    "job_id": "076cbadb",
    "source": "Airflow",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:51:21.698944+05",
    "log": "[JobID: 076cbadb] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T09:51:21.698944+05"
  },
  {
    "job_id": "bd6c994c",
    "source": "Hadoop",
    "filename": "countries1.csv",
    "output_file": "sorted_countries1.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:52:23.698944+05",
    "log": "[JobID: bd6c994c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries1.csv' | Source: Hadoop | Timestamp: 2025-06-12T09:52:23.698944+05"
  },
  {
    "job_id": "911b3819",
    "source": "Airflow",
    "filename": "countries17.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:52:31.698944+05",
    "log": "[JobID: 911b3819] Execution failed | Status: FAILED | Error: SyntaxError: invalid syntax in ctrl_flow.py | Source: Airflow | Timestamp: 2025-06-12T09:52:31.698944+05\nSyntaxError: invalid syntax in ctrl_flow.py\n\tat ctrl_flow.py:101\n\tat main.py:5"
  },
  {
    "job_id": "354eee1d",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:52:51.698944+05",
    "log": "[JobID: 354eee1d] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection | Source: Airflow | Timestamp: 2025-06-12T09:52:51.698944+05\norg.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection\n\tat org.apache.spark.sql.catalyst.ScalaReflection$class.extract(ScalaReflection.scala:178)\n\tat org.apache.spark.sql.catalyst.ScalaReflection.extract(ScalaReflection.scala:55)"
  },
  {
    "job_id": "cb0a622d",
    "source": "Spark",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:53:25.698944+05",
    "log": "[JobID: cb0a622d] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T09:53:25.698944+05"
  },
  {
    "job_id": "bb3aca16",
    "source": "Kafka",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:53:25.698944+05",
    "log": "[JobID: bb3aca16] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:53:25.698944+05"
  },
  {
    "job_id": "814fe1c4",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:53:40.698944+05",
    "log": "[JobID: 814fe1c4] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T09:53:40.698944+05"
  },
  {
    "job_id": "f56ded2b",
    "source": "Kafka",
    "filename": "countries24.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T09:54:21.698944+05",
    "log": "[JobID: f56ded2b] Execution failed | Status: FAILED | Error: java.lang.OutOfMemoryError: Java heap space | Source: Kafka | Timestamp: 2025-06-12T09:54:21.698944+05\njava.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)"
  },
  {
    "job_id": "814fe1c4",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:55:33.698944+05",
    "log": "[JobID: 814fe1c4] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:55:33.698944+05"
  },
  {
    "job_id": "814fe1c4",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T09:56:46.698944+05",
    "log": "[JobID: 814fe1c4] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T09:56:46.698944+05"
  },
  {
    "job_id": "cb0a622d",
    "source": "Spark",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:57:15.698944+05",
    "log": "[JobID: cb0a622d] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T09:57:15.698944+05"
  },
  {
    "job_id": "70fca041",
    "source": "Spark",
    "filename": "countries82.csv",
    "output_file": "sorted_countries82.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:57:19.698944+05",
    "log": "[JobID: 70fca041] Execution completed | Status: SUCCESS | Output file: 'sorted_countries82.csv' | Source: Spark | Timestamp: 2025-06-12T09:57:19.698944+05"
  },
  {
    "job_id": "bb3aca16",
    "source": "Kafka",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:57:57.698944+05",
    "log": "[JobID: bb3aca16] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T09:57:57.698944+05"
  },
  {
    "job_id": "953fe42d",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:57:59.698944+05",
    "log": "[JobID: 953fe42d] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T09:57:59.698944+05"
  },
  {
    "job_id": "953fe42d",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T09:59:04.698944+05",
    "log": "[JobID: 953fe42d] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T09:59:04.698944+05"
  },
  {
    "job_id": "6f44e7f6",
    "source": "Glue",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T09:59:36.698944+05",
    "log": "[JobID: 6f44e7f6] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T09:59:36.698944+05"
  },
  {
    "job_id": "96e30a4f",
    "source": "Glue",
    "filename": "countries68.csv",
    "output_file": "sorted_countries68.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T09:59:44.698944+05",
    "log": "[JobID: 96e30a4f] Execution completed | Status: SUCCESS | Output file: 'sorted_countries68.csv' | Source: Glue | Timestamp: 2025-06-12T09:59:44.698944+05"
  },
  {
    "job_id": "ad6d54e0",
    "source": "Airflow",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:00:14.698944+05",
    "log": "[JobID: ad6d54e0] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:00:14.698944+05"
  },
  {
    "job_id": "cb0a622d",
    "source": "Spark",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:01:50.698944+05",
    "log": "[JobID: cb0a622d] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:01:50.698944+05"
  },
  {
    "job_id": "076cbadb",
    "source": "Airflow",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:02:00.698944+05",
    "log": "[JobID: 076cbadb] Execution failed | Status: FAILED | Error: AttributeError: 'NoneType' object has no attribute 'split' | Source: Airflow | Timestamp: 2025-06-12T10:02:00.698944+05\nAttributeError: 'NoneType' object has no attribute 'split'\n\tat preprocess_data.py:33\n\tat main.py:78"
  },
  {
    "job_id": "bb3aca16",
    "source": "Kafka",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:02:33.698944+05",
    "log": "[JobID: bb3aca16] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:02:33.698944+05"
  },
  {
    "job_id": "ad6d54e0",
    "source": "Airflow",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:02:50.698944+05",
    "log": "[JobID: ad6d54e0] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:02:50.698944+05"
  },
  {
    "job_id": "953fe42d",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:03:31.698944+05",
    "log": "[JobID: 953fe42d] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:03:31.698944+05"
  },
  {
    "job_id": "6f44e7f6",
    "source": "Glue",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:03:33.698944+05",
    "log": "[JobID: 6f44e7f6] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:03:33.698944+05"
  },
  {
    "job_id": "9f53f366",
    "source": "Airflow",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:05:12.698944+05",
    "log": "[JobID: 9f53f366] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:05:12.698944+05"
  },
  {
    "job_id": "ad6d54e0",
    "source": "Airflow",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:05:29.698944+05",
    "log": "[JobID: ad6d54e0] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:05:29.698944+05"
  },
  {
    "job_id": "9619cff2",
    "source": "Airflow",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:05:55.698944+05",
    "log": "[JobID: 9619cff2] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:05:55.698944+05"
  },
  {
    "job_id": "18636b28",
    "source": "Airflow",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:05:58.698944+05",
    "log": "[JobID: 18636b28] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:05:58.698944+05"
  },
  {
    "job_id": "6f44e7f6",
    "source": "Glue",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:06:17.698944+05",
    "log": "[JobID: 6f44e7f6] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:06:17.698944+05"
  },
  {
    "job_id": "8c400645",
    "source": "Airflow",
    "filename": "countries15.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:06:36.698944+05",
    "log": "[JobID: 8c400645] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection | Source: Airflow | Timestamp: 2025-06-12T10:06:36.698944+05\norg.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection\n\tat org.apache.spark.sql.catalyst.ScalaReflection$class.extract(ScalaReflection.scala:178)\n\tat org.apache.spark.sql.catalyst.ScalaReflection.extract(ScalaReflection.scala:55)"
  },
  {
    "job_id": "9f53f366",
    "source": "Airflow",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:06:38.698944+05",
    "log": "[JobID: 9f53f366] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:06:38.698944+05"
  },
  {
    "job_id": "4b360b6c",
    "source": "Kafka",
    "filename": "countries97.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:06:56.698944+05",
    "log": "[JobID: 4b360b6c] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:06:56.698944+05"
  },
  {
    "job_id": "9619cff2",
    "source": "Airflow",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:07:20.698944+05",
    "log": "[JobID: 9619cff2] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:07:20.698944+05"
  },
  {
    "job_id": "b9f61f11",
    "source": "Spark",
    "filename": "countries72.csv",
    "output_file": "sorted_countries72.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:07:46.698944+05",
    "log": "[JobID: b9f61f11] Execution completed | Status: SUCCESS | Output file: 'sorted_countries72.csv' | Source: Spark | Timestamp: 2025-06-12T10:07:46.698944+05"
  },
  {
    "job_id": "4b360b6c",
    "source": "Kafka",
    "filename": "countries97.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:07:59.698944+05",
    "log": "[JobID: 4b360b6c] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:07:59.698944+05"
  },
  {
    "job_id": "9619cff2",
    "source": "Airflow",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:09:09.698944+05",
    "log": "[JobID: 9619cff2] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:09:09.698944+05"
  },
  {
    "job_id": "18636b28",
    "source": "Airflow",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:09:36.698944+05",
    "log": "[JobID: 18636b28] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:09:36.698944+05"
  },
  {
    "job_id": "9f53f366",
    "source": "Airflow",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:10:30.698944+05",
    "log": "[JobID: 9f53f366] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:10:30.698944+05"
  },
  {
    "job_id": "4b360b6c",
    "source": "Kafka",
    "filename": "countries97.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:10:53.698944+05",
    "log": "[JobID: 4b360b6c] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:10:53.698944+05"
  },
  {
    "job_id": "08fae712",
    "source": "Hadoop",
    "filename": "countries48.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:11:39.698944+05",
    "log": "[JobID: 08fae712] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:11:39.698944+05"
  },
  {
    "job_id": "bb3aca16",
    "source": "Kafka",
    "filename": "countries37.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:11:43.698944+05",
    "log": "[JobID: bb3aca16] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Resolved attribute(s) missing from input data: [id]. | Source: Kafka | Timestamp: 2025-06-12T10:11:43.698944+05\norg.apache.spark.sql.AnalysisException: Resolved attribute(s) missing from input data: [id].\n\tat org.apache.spark.sql.catalyst.analysis.ResolveMissingColumns$.failAnalysis(AnalysisError.scala:100)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:500)"
  },
  {
    "job_id": "014c087d",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:11:56.698944+05",
    "log": "[JobID: 014c087d] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:11:56.698944+05"
  },
  {
    "job_id": "3bfe2f2f",
    "source": "Glue",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:12:06.698944+05",
    "log": "[JobID: 3bfe2f2f] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:12:06.698944+05"
  },
  {
    "job_id": "9e0e023e",
    "source": "Airflow",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:12:17.698944+05",
    "log": "[JobID: 9e0e023e] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:12:17.698944+05"
  },
  {
    "job_id": "814fe1c4",
    "source": "Kafka",
    "filename": "countries78.csv",
    "output_file": "sorted_countries78.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:12:19.698944+05",
    "log": "[JobID: 814fe1c4] Execution completed | Status: SUCCESS | Output file: 'sorted_countries78.csv' | Source: Kafka | Timestamp: 2025-06-12T10:12:19.698944+05"
  },
  {
    "job_id": "014c087d",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:13:22.698944+05",
    "log": "[JobID: 014c087d] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:13:22.698944+05"
  },
  {
    "job_id": "08fae712",
    "source": "Hadoop",
    "filename": "countries48.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:13:28.698944+05",
    "log": "[JobID: 08fae712] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:13:28.698944+05"
  },
  {
    "job_id": "3bfe2f2f",
    "source": "Glue",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:13:34.698944+05",
    "log": "[JobID: 3bfe2f2f] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:13:34.698944+05"
  },
  {
    "job_id": "671c5cee",
    "source": "Glue",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:13:45.698944+05",
    "log": "[JobID: 671c5cee] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:13:45.698944+05"
  },
  {
    "job_id": "d8b860cb",
    "source": "Kafka",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:13:50.698944+05",
    "log": "[JobID: d8b860cb] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:13:50.698944+05"
  },
  {
    "job_id": "6f44e7f6",
    "source": "Glue",
    "filename": "countries37.csv",
    "output_file": "sorted_countries37.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:13:56.698944+05",
    "log": "[JobID: 6f44e7f6] Execution completed | Status: SUCCESS | Output file: 'sorted_countries37.csv' | Source: Glue | Timestamp: 2025-06-12T10:13:56.698944+05"
  },
  {
    "job_id": "18636b28",
    "source": "Airflow",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:14:29.698944+05",
    "log": "[JobID: 18636b28] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:14:29.698944+05"
  },
  {
    "job_id": "d8b860cb",
    "source": "Kafka",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:14:50.698944+05",
    "log": "[JobID: d8b860cb] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:14:50.698944+05"
  },
  {
    "job_id": "cb0a622d",
    "source": "Spark",
    "filename": "countries3.csv",
    "output_file": "sorted_countries3.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:15:39.698944+05",
    "log": "[JobID: cb0a622d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries3.csv' | Source: Spark | Timestamp: 2025-06-12T10:15:39.698944+05"
  },
  {
    "job_id": "63377ba2",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:15:41.698944+05",
    "log": "[JobID: 63377ba2] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:15:41.698944+05"
  },
  {
    "job_id": "aae02640",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:15:44.698944+05",
    "log": "[JobID: aae02640] Execution failed | Status: FAILED | Error: FileNotFoundError: [Errno 2] No such file or directory: 'config.yaml' | Source: Hadoop | Timestamp: 2025-06-12T10:15:44.698944+05\nFileNotFoundError: [Errno 2] No such file or directory: 'config.yaml'\n\tat open_config.py:45\n\tat initialize.py:12"
  },
  {
    "job_id": "9cff831c",
    "source": "Kafka",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:15:52.698944+05",
    "log": "[JobID: 9cff831c] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:15:52.698944+05"
  },
  {
    "job_id": "d8b860cb",
    "source": "Kafka",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:16:06.698944+05",
    "log": "[JobID: d8b860cb] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:16:06.698944+05"
  },
  {
    "job_id": "eb040bea",
    "source": "Kafka",
    "filename": "countries84.csv",
    "output_file": "sorted_countries84.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:16:21.698944+05",
    "log": "[JobID: eb040bea] Execution completed | Status: SUCCESS | Output file: 'sorted_countries84.csv' | Source: Kafka | Timestamp: 2025-06-12T10:16:21.698944+05"
  },
  {
    "job_id": "014c087d",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:16:28.698944+05",
    "log": "[JobID: 014c087d] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:16:28.698944+05"
  },
  {
    "job_id": "1d563588",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:16:29.698944+05",
    "log": "[JobID: 1d563588] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:16:29.698944+05"
  },
  {
    "job_id": "671c5cee",
    "source": "Glue",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:16:36.698944+05",
    "log": "[JobID: 671c5cee] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:16:36.698944+05"
  },
  {
    "job_id": "3bfe2f2f",
    "source": "Glue",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:16:52.698944+05",
    "log": "[JobID: 3bfe2f2f] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:16:52.698944+05"
  },
  {
    "job_id": "08fae712",
    "source": "Hadoop",
    "filename": "countries48.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:16:54.698944+05",
    "log": "[JobID: 08fae712] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:16:54.698944+05"
  },
  {
    "job_id": "9e0e023e",
    "source": "Airflow",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:16:54.698944+05",
    "log": "[JobID: 9e0e023e] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:16:54.698944+05"
  },
  {
    "job_id": "c26c4d60",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:17:20.698944+05",
    "log": "[JobID: c26c4d60] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:17:20.698944+05"
  },
  {
    "job_id": "671c5cee",
    "source": "Glue",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:18:05.698944+05",
    "log": "[JobID: 671c5cee] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:18:05.698944+05"
  },
  {
    "job_id": "eed34099",
    "source": "Kafka",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:18:17.698944+05",
    "log": "[JobID: eed34099] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:18:17.698944+05"
  },
  {
    "job_id": "9cff831c",
    "source": "Kafka",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:18:21.698944+05",
    "log": "[JobID: 9cff831c] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:18:21.698944+05"
  },
  {
    "job_id": "63377ba2",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:18:21.698944+05",
    "log": "[JobID: 63377ba2] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:18:21.698944+05"
  },
  {
    "job_id": "65f9f1b2",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:19:01.698944+05",
    "log": "[JobID: 65f9f1b2] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:19:01.698944+05"
  },
  {
    "job_id": "ac2497e0",
    "source": "Kafka",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:19:12.698944+05",
    "log": "[JobID: ac2497e0] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:19:12.698944+05"
  },
  {
    "job_id": "97552ee4",
    "source": "Hadoop",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:19:27.698944+05",
    "log": "[JobID: 97552ee4] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:19:27.698944+05"
  },
  {
    "job_id": "eed34099",
    "source": "Kafka",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:19:28.698944+05",
    "log": "[JobID: eed34099] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:19:28.698944+05"
  },
  {
    "job_id": "4b360b6c",
    "source": "Kafka",
    "filename": "countries97.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:19:34.698944+05",
    "log": "[JobID: 4b360b6c] Execution failed | Status: FAILED | Error: FileExistsError: [Errno 17] File exists: '/tmp/output.csv' | Source: Kafka | Timestamp: 2025-06-12T10:19:34.698944+05\nFileExistsError: [Errno 17] File exists: '/tmp/output.csv'\n\tat file_writer.py:66\n\tat main.py:25"
  },
  {
    "job_id": "9e0e023e",
    "source": "Airflow",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:19:54.698944+05",
    "log": "[JobID: 9e0e023e] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:19:54.698944+05"
  },
  {
    "job_id": "104328a8",
    "source": "Glue",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:20:06.698944+05",
    "log": "[JobID: 104328a8] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:20:06.698944+05"
  },
  {
    "job_id": "9619cff2",
    "source": "Airflow",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:20:18.698944+05",
    "log": "[JobID: 9619cff2] Execution failed | Status: FAILED | Error: java.lang.OutOfMemoryError: Java heap space | Source: Airflow | Timestamp: 2025-06-12T10:20:18.698944+05\njava.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)"
  },
  {
    "job_id": "522d65fc",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:20:19.698944+05",
    "log": "[JobID: 522d65fc] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:20:19.698944+05"
  },
  {
    "job_id": "63377ba2",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:20:30.698944+05",
    "log": "[JobID: 63377ba2] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:20:30.698944+05"
  },
  {
    "job_id": "1d563588",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:20:53.698944+05",
    "log": "[JobID: 1d563588] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:20:53.698944+05"
  },
  {
    "job_id": "ac2497e0",
    "source": "Kafka",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:21:08.698944+05",
    "log": "[JobID: ac2497e0] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:21:08.698944+05"
  },
  {
    "job_id": "ee331d9d",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:21:43.698944+05",
    "log": "[JobID: ee331d9d] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:21:43.698944+05"
  },
  {
    "job_id": "c26c4d60",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:21:58.698944+05",
    "log": "[JobID: c26c4d60] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:21:58.698944+05"
  },
  {
    "job_id": "1d563588",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:22:00.698944+05",
    "log": "[JobID: 1d563588] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:22:00.698944+05"
  },
  {
    "job_id": "dddeca91",
    "source": "Hadoop",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:22:12.698944+05",
    "log": "[JobID: dddeca91] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:22:12.698944+05"
  },
  {
    "job_id": "104328a8",
    "source": "Glue",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:22:19.698944+05",
    "log": "[JobID: 104328a8] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:22:19.698944+05"
  },
  {
    "job_id": "522d65fc",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:22:52.698944+05",
    "log": "[JobID: 522d65fc] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:22:52.698944+05"
  },
  {
    "job_id": "65f9f1b2",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:22:55.698944+05",
    "log": "[JobID: 65f9f1b2] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:22:55.698944+05"
  },
  {
    "job_id": "97552ee4",
    "source": "Hadoop",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:23:06.698944+05",
    "log": "[JobID: 97552ee4] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:23:06.698944+05"
  },
  {
    "job_id": "9cff831c",
    "source": "Kafka",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:23:08.698944+05",
    "log": "[JobID: 9cff831c] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:23:08.698944+05"
  },
  {
    "job_id": "dddeca91",
    "source": "Hadoop",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:23:38.698944+05",
    "log": "[JobID: dddeca91] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:23:38.698944+05"
  },
  {
    "job_id": "104328a8",
    "source": "Glue",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:23:45.698944+05",
    "log": "[JobID: 104328a8] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:23:45.698944+05"
  },
  {
    "job_id": "bf652591",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:24:00.698944+05",
    "log": "[JobID: bf652591] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:24:00.698944+05"
  },
  {
    "job_id": "eed34099",
    "source": "Kafka",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:24:14.698944+05",
    "log": "[JobID: eed34099] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:24:14.698944+05"
  },
  {
    "job_id": "0a5117bc",
    "source": "Hadoop",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:24:30.698944+05",
    "log": "[JobID: 0a5117bc] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:24:30.698944+05"
  },
  {
    "job_id": "ee331d9d",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:24:44.698944+05",
    "log": "[JobID: ee331d9d] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:24:44.698944+05"
  },
  {
    "job_id": "522d65fc",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:24:50.698944+05",
    "log": "[JobID: 522d65fc] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:24:50.698944+05"
  },
  {
    "job_id": "18636b28",
    "source": "Airflow",
    "filename": "countries55.csv",
    "output_file": "sorted_countries55.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:24:51.698944+05",
    "log": "[JobID: 18636b28] Execution completed | Status: SUCCESS | Output file: 'sorted_countries55.csv' | Source: Airflow | Timestamp: 2025-06-12T10:24:51.698944+05"
  },
  {
    "job_id": "65f9f1b2",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:25:12.698944+05",
    "log": "[JobID: 65f9f1b2] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:25:12.698944+05"
  },
  {
    "job_id": "97552ee4",
    "source": "Hadoop",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:25:12.698944+05",
    "log": "[JobID: 97552ee4] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:25:12.698944+05"
  },
  {
    "job_id": "ad6d54e0",
    "source": "Airflow",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:25:23.698944+05",
    "log": "[JobID: ad6d54e0] Execution failed | Status: FAILED | Error: IOError: [Errno 13] Permission denied: '/var/log/app.log' | Source: Airflow | Timestamp: 2025-06-12T10:25:23.698944+05\nIOError: [Errno 13] Permission denied: '/var/log/app.log'\n\tat log_writer.py:59\n\tat main.py:20"
  },
  {
    "job_id": "014c087d",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": "sorted_countries42.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:25:24.698944+05",
    "log": "[JobID: 014c087d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries42.csv' | Source: Hadoop | Timestamp: 2025-06-12T10:25:24.698944+05"
  },
  {
    "job_id": "ac2497e0",
    "source": "Kafka",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:25:53.698944+05",
    "log": "[JobID: ac2497e0] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:25:53.698944+05"
  },
  {
    "job_id": "2e9a7c5c",
    "source": "Airflow",
    "filename": "countries81.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:26:09.698944+05",
    "log": "[JobID: 2e9a7c5c] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:26:09.698944+05"
  },
  {
    "job_id": "c26c4d60",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:26:56.698944+05",
    "log": "[JobID: c26c4d60] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:26:56.698944+05"
  },
  {
    "job_id": "0a5117bc",
    "source": "Hadoop",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:27:12.698944+05",
    "log": "[JobID: 0a5117bc] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:27:12.698944+05"
  },
  {
    "job_id": "8da1cfef",
    "source": "Flink",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:27:41.698944+05",
    "log": "[JobID: 8da1cfef] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:27:41.698944+05"
  },
  {
    "job_id": "953fe42d",
    "source": "Flink",
    "filename": "countries26.csv",
    "output_file": "sorted_countries26.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:27:45.698944+05",
    "log": "[JobID: 953fe42d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries26.csv' | Source: Flink | Timestamp: 2025-06-12T10:27:45.698944+05"
  },
  {
    "job_id": "9f53f366",
    "source": "Airflow",
    "filename": "countries14.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:27:53.698944+05",
    "log": "[JobID: 9f53f366] Execution failed | Status: FAILED | Error: RuntimeError: maximum recursion depth exceeded while calling a Python object | Source: Airflow | Timestamp: 2025-06-12T10:27:53.698944+05\nRuntimeError: maximum recursion depth exceeded while calling a Python object\n\tat recursion.py:33\n\tat main.py:78"
  },
  {
    "job_id": "dddeca91",
    "source": "Hadoop",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:27:55.698944+05",
    "log": "[JobID: dddeca91] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:27:55.698944+05"
  },
  {
    "job_id": "671c5cee",
    "source": "Glue",
    "filename": "countries19.csv",
    "output_file": "sorted_countries19.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:28:08.698944+05",
    "log": "[JobID: 671c5cee] Execution completed | Status: SUCCESS | Output file: 'sorted_countries19.csv' | Source: Glue | Timestamp: 2025-06-12T10:28:08.698944+05"
  },
  {
    "job_id": "bf652591",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:28:30.698944+05",
    "log": "[JobID: bf652591] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:28:30.698944+05"
  },
  {
    "job_id": "ee331d9d",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:28:39.698944+05",
    "log": "[JobID: ee331d9d] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:28:39.698944+05"
  },
  {
    "job_id": "2e9a7c5c",
    "source": "Airflow",
    "filename": "countries81.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:29:04.698944+05",
    "log": "[JobID: 2e9a7c5c] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:29:04.698944+05"
  },
  {
    "job_id": "80c5cdef",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:29:05.698944+05",
    "log": "[JobID: 80c5cdef] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:29:05.698944+05"
  },
  {
    "job_id": "6837373a",
    "source": "Airflow",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:29:27.698944+05",
    "log": "[JobID: 6837373a] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:29:27.698944+05"
  },
  {
    "job_id": "08037347",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:29:47.698944+05",
    "log": "[JobID: 08037347] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:29:47.698944+05"
  },
  {
    "job_id": "f36e1555",
    "source": "Kafka",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:30:28.698944+05",
    "log": "[JobID: f36e1555] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:30:28.698944+05"
  },
  {
    "job_id": "2e9a7c5c",
    "source": "Airflow",
    "filename": "countries81.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:30:39.698944+05",
    "log": "[JobID: 2e9a7c5c] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:30:39.698944+05"
  },
  {
    "job_id": "8da1cfef",
    "source": "Flink",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:31:15.698944+05",
    "log": "[JobID: 8da1cfef] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:31:15.698944+05"
  },
  {
    "job_id": "81e4f257",
    "source": "Glue",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:31:16.698944+05",
    "log": "[JobID: 81e4f257] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:31:16.698944+05"
  },
  {
    "job_id": "f36e1555",
    "source": "Kafka",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:31:19.698944+05",
    "log": "[JobID: f36e1555] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:31:19.698944+05"
  },
  {
    "job_id": "08037347",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:31:58.698944+05",
    "log": "[JobID: 08037347] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:31:58.698944+05"
  },
  {
    "job_id": "0a5117bc",
    "source": "Hadoop",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:32:00.698944+05",
    "log": "[JobID: 0a5117bc] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:32:00.698944+05"
  },
  {
    "job_id": "8da1cfef",
    "source": "Flink",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:32:07.698944+05",
    "log": "[JobID: 8da1cfef] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:32:07.698944+05"
  },
  {
    "job_id": "3bfe2f2f",
    "source": "Glue",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:32:17.698944+05",
    "log": "[JobID: 3bfe2f2f] Execution failed | Status: FAILED | Error: java.net.ConnectException: Connection refused (Connection refused) | Source: Glue | Timestamp: 2025-06-12T10:32:17.698944+05\njava.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)"
  },
  {
    "job_id": "3b2211a9",
    "source": "Airflow",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:32:52.698944+05",
    "log": "[JobID: 3b2211a9] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:32:52.698944+05"
  },
  {
    "job_id": "bf652591",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:33:09.698944+05",
    "log": "[JobID: bf652591] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:33:09.698944+05"
  },
  {
    "job_id": "34bfe6de",
    "source": "Spark",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:33:09.698944+05",
    "log": "[JobID: 34bfe6de] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:33:09.698944+05"
  },
  {
    "job_id": "f36e1555",
    "source": "Kafka",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:33:25.698944+05",
    "log": "[JobID: f36e1555] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:33:25.698944+05"
  },
  {
    "job_id": "6837373a",
    "source": "Airflow",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:33:48.698944+05",
    "log": "[JobID: 6837373a] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:33:48.698944+05"
  },
  {
    "job_id": "80c5cdef",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:33:58.698944+05",
    "log": "[JobID: 80c5cdef] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:33:58.698944+05"
  },
  {
    "job_id": "40f1117e",
    "source": "Glue",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:34:03.698944+05",
    "log": "[JobID: 40f1117e] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:34:03.698944+05"
  },
  {
    "job_id": "81e4f257",
    "source": "Glue",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:34:10.698944+05",
    "log": "[JobID: 81e4f257] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:34:10.698944+05"
  },
  {
    "job_id": "a38ddb8a",
    "source": "Spark",
    "filename": "countries76.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:34:17.698944+05",
    "log": "[JobID: a38ddb8a] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:34:17.698944+05"
  },
  {
    "job_id": "80c5cdef",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:34:37.698944+05",
    "log": "[JobID: 80c5cdef] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:34:37.698944+05"
  },
  {
    "job_id": "08037347",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:34:41.698944+05",
    "log": "[JobID: 08037347] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:34:41.698944+05"
  },
  {
    "job_id": "63890623",
    "source": "Flink",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:34:43.698944+05",
    "log": "[JobID: 63890623] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:34:43.698944+05"
  },
  {
    "job_id": "34bfe6de",
    "source": "Spark",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:34:50.698944+05",
    "log": "[JobID: 34bfe6de] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:34:50.698944+05"
  },
  {
    "job_id": "d8b860cb",
    "source": "Kafka",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:35:17.698944+05",
    "log": "[JobID: d8b860cb] Execution failed | Status: FAILED | Error: KeyError: 'user_id' | Source: Kafka | Timestamp: 2025-06-12T10:35:17.698944+05\nKeyError: 'user_id'\n\tat transform_dict.py:75\n\tat process_request.py:34"
  },
  {
    "job_id": "34bfe6de",
    "source": "Spark",
    "filename": "countries57.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:35:24.698944+05",
    "log": "[JobID: 34bfe6de] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:35:24.698944+05"
  },
  {
    "job_id": "2e9a7c5c",
    "source": "Airflow",
    "filename": "countries81.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:35:40.698944+05",
    "log": "[JobID: 2e9a7c5c] Execution failed | Status: FAILED | Error: AttributeError: 'NoneType' object has no attribute 'split' | Source: Airflow | Timestamp: 2025-06-12T10:35:40.698944+05\nAttributeError: 'NoneType' object has no attribute 'split'\n\tat preprocess_data.py:33\n\tat main.py:78"
  },
  {
    "job_id": "81e4f257",
    "source": "Glue",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:36:04.698944+05",
    "log": "[JobID: 81e4f257] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:36:04.698944+05"
  },
  {
    "job_id": "81e4f257",
    "source": "Glue",
    "filename": "countries99.csv",
    "output_file": "sorted_countries99.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:36:26.698944+05",
    "log": "[JobID: 81e4f257] Execution completed | Status: SUCCESS | Output file: 'sorted_countries99.csv' | Source: Glue | Timestamp: 2025-06-12T10:36:26.698944+05"
  },
  {
    "job_id": "1d563588",
    "source": "Hadoop",
    "filename": "countries66.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:36:33.698944+05",
    "log": "[JobID: 1d563588] Execution failed | Status: FAILED | Error: java.net.ConnectException: Connection refused (Connection refused) | Source: Hadoop | Timestamp: 2025-06-12T10:36:33.698944+05\njava.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)"
  },
  {
    "job_id": "c26c4d60",
    "source": "Hadoop",
    "filename": "countries56.csv",
    "output_file": "sorted_countries56.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:36:44.698944+05",
    "log": "[JobID: c26c4d60] Execution completed | Status: SUCCESS | Output file: 'sorted_countries56.csv' | Source: Hadoop | Timestamp: 2025-06-12T10:36:44.698944+05"
  },
  {
    "job_id": "104328a8",
    "source": "Glue",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:36:51.698944+05",
    "log": "[JobID: 104328a8] Execution failed | Status: FAILED | Error: java.lang.UnsupportedOperationException: This operation is not supported | Source: Glue | Timestamp: 2025-06-12T10:36:51.698944+05\njava.lang.UnsupportedOperationException: This operation is not supported\n\tat java.util.Collections$UnmodifiableList.add(Collections.java:1055)\n\tat com.example.ListModifier.modify(ListModifier.java:33)"
  },
  {
    "job_id": "40f1117e",
    "source": "Glue",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:36:52.698944+05",
    "log": "[JobID: 40f1117e] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:36:52.698944+05"
  },
  {
    "job_id": "f3047387",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:37:06.698944+05",
    "log": "[JobID: f3047387] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:37:06.698944+05"
  },
  {
    "job_id": "3b2211a9",
    "source": "Airflow",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:37:08.698944+05",
    "log": "[JobID: 3b2211a9] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:37:08.698944+05"
  },
  {
    "job_id": "f3047387",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:37:37.698944+05",
    "log": "[JobID: f3047387] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:37:37.698944+05"
  },
  {
    "job_id": "6837373a",
    "source": "Airflow",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:37:49.698944+05",
    "log": "[JobID: 6837373a] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:37:49.698944+05"
  },
  {
    "job_id": "63890623",
    "source": "Flink",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:38:24.698944+05",
    "log": "[JobID: 63890623] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:38:24.698944+05"
  },
  {
    "job_id": "f3047387",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:38:37.698944+05",
    "log": "[JobID: f3047387] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:38:37.698944+05"
  },
  {
    "job_id": "a38ddb8a",
    "source": "Spark",
    "filename": "countries76.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:38:49.698944+05",
    "log": "[JobID: a38ddb8a] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:38:49.698944+05"
  },
  {
    "job_id": "0a5117bc",
    "source": "Hadoop",
    "filename": "countries89.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:39:41.698944+05",
    "log": "[JobID: 0a5117bc] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms | Source: Hadoop | Timestamp: 2025-06-12T10:39:41.698944+05\norg.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms\n\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:350)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "356ac895",
    "source": "Glue",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:39:43.698944+05",
    "log": "[JobID: 356ac895] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:39:43.698944+05"
  },
  {
    "job_id": "40f1117e",
    "source": "Glue",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:40:01.698944+05",
    "log": "[JobID: 40f1117e] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:40:01.698944+05"
  },
  {
    "job_id": "522d65fc",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:40:23.698944+05",
    "log": "[JobID: 522d65fc] Execution failed | Status: FAILED | Error: SyntaxError: invalid syntax in ctrl_flow.py | Source: Hadoop | Timestamp: 2025-06-12T10:40:23.698944+05\nSyntaxError: invalid syntax in ctrl_flow.py\n\tat ctrl_flow.py:101\n\tat main.py:5"
  },
  {
    "job_id": "a38ddb8a",
    "source": "Spark",
    "filename": "countries76.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:40:33.698944+05",
    "log": "[JobID: a38ddb8a] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:40:33.698944+05"
  },
  {
    "job_id": "eed34099",
    "source": "Kafka",
    "filename": "countries23.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:40:35.698944+05",
    "log": "[JobID: eed34099] Execution failed | Status: FAILED | Error: ModuleNotFoundError: No module named 'numpy' | Source: Kafka | Timestamp: 2025-06-12T10:40:35.698944+05\nModuleNotFoundError: No module named 'numpy'\n\tat import numpy as np\n\tat compute.py:10"
  },
  {
    "job_id": "9cff831c",
    "source": "Kafka",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:41:03.698944+05",
    "log": "[JobID: 9cff831c] Execution failed | Status: FAILED | Error: org.apache.spark.SparkException: Job aborted due to stage failure | Source: Kafka | Timestamp: 2025-06-12T10:41:03.698944+05\norg.apache.spark.SparkException: Job aborted due to stage failure\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)"
  },
  {
    "job_id": "63890623",
    "source": "Flink",
    "filename": "countries82.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:41:08.698944+05",
    "log": "[JobID: 63890623] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:41:08.698944+05"
  },
  {
    "job_id": "356ac895",
    "source": "Glue",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:41:31.698944+05",
    "log": "[JobID: 356ac895] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:41:31.698944+05"
  },
  {
    "job_id": "c90a5b33",
    "source": "Flink",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:41:42.698944+05",
    "log": "[JobID: c90a5b33] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:41:42.698944+05"
  },
  {
    "job_id": "80c5cdef",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:41:47.698944+05",
    "log": "[JobID: 80c5cdef] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection | Source: Flink | Timestamp: 2025-06-12T10:41:47.698944+05\norg.apache.spark.sql.AnalysisException: Invalid call to toJava on a Scala collection\n\tat org.apache.spark.sql.catalyst.ScalaReflection$class.extract(ScalaReflection.scala:178)\n\tat org.apache.spark.sql.catalyst.ScalaReflection.extract(ScalaReflection.scala:55)"
  },
  {
    "job_id": "3b2211a9",
    "source": "Airflow",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:42:05.698944+05",
    "log": "[JobID: 3b2211a9] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:42:05.698944+05"
  },
  {
    "job_id": "75784204",
    "source": "Airflow",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:42:09.698944+05",
    "log": "[JobID: 75784204] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:42:09.698944+05"
  },
  {
    "job_id": "8da1cfef",
    "source": "Flink",
    "filename": "countries75.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:42:12.698944+05",
    "log": "[JobID: 8da1cfef] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms | Source: Flink | Timestamp: 2025-06-12T10:42:12.698944+05\norg.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms\n\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:350)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "03a7c153",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:42:54.698944+05",
    "log": "[JobID: 03a7c153] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:42:54.698944+05"
  },
  {
    "job_id": "c90a5b33",
    "source": "Flink",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:43:07.698944+05",
    "log": "[JobID: c90a5b33] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:43:07.698944+05"
  },
  {
    "job_id": "08fae712",
    "source": "Hadoop",
    "filename": "countries48.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:43:22.698944+05",
    "log": "[JobID: 08fae712] Execution failed | Status: FAILED | Error: java.io.FileNotFoundException: /path/to/output/file (No such file or directory) | Source: Hadoop | Timestamp: 2025-06-12T10:43:22.698944+05\njava.io.FileNotFoundException: /path/to/output/file (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)"
  },
  {
    "job_id": "6837373a",
    "source": "Airflow",
    "filename": "countries3.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:43:22.698944+05",
    "log": "[JobID: 6837373a] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db' | Source: Airflow | Timestamp: 2025-06-12T10:43:22.698944+05\ncom.amazonaws.services.glue.GlueException: Entity not found: database 'sales_db'\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:350)\n\tat com.amazonaws.services.glue.AWSGlueClient.getTable(AWSGlueClient.java:115)"
  },
  {
    "job_id": "08037347",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:43:28.698944+05",
    "log": "[JobID: 08037347] Execution failed | Status: FAILED | Error: ZeroDivisionError: float division by zero | Source: Spark | Timestamp: 2025-06-12T10:43:28.698944+05\nZeroDivisionError: float division by zero\n\tat math_operations.py:101\n\tat compute.py:23"
  },
  {
    "job_id": "356ac895",
    "source": "Glue",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:43:46.698944+05",
    "log": "[JobID: 356ac895] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:43:46.698944+05"
  },
  {
    "job_id": "75784204",
    "source": "Airflow",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:44:06.698944+05",
    "log": "[JobID: 75784204] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:44:06.698944+05"
  },
  {
    "job_id": "73004c1d",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:45:04.698944+05",
    "log": "[JobID: 73004c1d] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:45:04.698944+05"
  },
  {
    "job_id": "d85dc258",
    "source": "Hadoop",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:45:37.698944+05",
    "log": "[JobID: d85dc258] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:45:37.698944+05"
  },
  {
    "job_id": "63377ba2",
    "source": "Hadoop",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:45:38.698944+05",
    "log": "[JobID: 63377ba2] Execution failed | Status: FAILED | Error: ModuleNotFoundError: No module named 'requests' | Source: Hadoop | Timestamp: 2025-06-12T10:45:38.698944+05\nModuleNotFoundError: No module named 'requests'\n\tat api_client.py:28\n\tat main.py:10"
  },
  {
    "job_id": "c90a5b33",
    "source": "Flink",
    "filename": "countries99.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:45:45.698944+05",
    "log": "[JobID: c90a5b33] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:45:45.698944+05"
  },
  {
    "job_id": "9e0e023e",
    "source": "Airflow",
    "filename": "countries29.csv",
    "output_file": "sorted_countries29.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:45:52.698944+05",
    "log": "[JobID: 9e0e023e] Execution completed | Status: SUCCESS | Output file: 'sorted_countries29.csv' | Source: Airflow | Timestamp: 2025-06-12T10:45:52.698944+05"
  },
  {
    "job_id": "5d4e9f06",
    "source": "Flink",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:45:59.698944+05",
    "log": "[JobID: 5d4e9f06] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:45:59.698944+05"
  },
  {
    "job_id": "03a7c153",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:46:22.698944+05",
    "log": "[JobID: 03a7c153] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:46:22.698944+05"
  },
  {
    "job_id": "84bd3463",
    "source": "Hadoop",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:46:24.698944+05",
    "log": "[JobID: 84bd3463] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:46:24.698944+05"
  },
  {
    "job_id": "5d4e9f06",
    "source": "Flink",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:46:30.698944+05",
    "log": "[JobID: 5d4e9f06] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:46:30.698944+05"
  },
  {
    "job_id": "8fa046ba",
    "source": "Glue",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:47:58.698944+05",
    "log": "[JobID: 8fa046ba] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:47:58.698944+05"
  },
  {
    "job_id": "03a7c153",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:48:13.698944+05",
    "log": "[JobID: 03a7c153] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:48:13.698944+05"
  },
  {
    "job_id": "8ea33276",
    "source": "Flink",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:48:20.698944+05",
    "log": "[JobID: 8ea33276] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T10:48:20.698944+05"
  },
  {
    "job_id": "75784204",
    "source": "Airflow",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:48:36.698944+05",
    "log": "[JobID: 75784204] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:48:36.698944+05"
  },
  {
    "job_id": "73004c1d",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:48:45.698944+05",
    "log": "[JobID: 73004c1d] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:48:45.698944+05"
  },
  {
    "job_id": "65f9f1b2",
    "source": "Glue",
    "filename": "countries58.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:49:10.698944+05",
    "log": "[JobID: 65f9f1b2] Execution failed | Status: FAILED | Error: RuntimeError: maximum recursion depth exceeded while calling a Python object | Source: Glue | Timestamp: 2025-06-12T10:49:10.698944+05\nRuntimeError: maximum recursion depth exceeded while calling a Python object\n\tat recursion.py:33\n\tat main.py:78"
  },
  {
    "job_id": "84bd3463",
    "source": "Hadoop",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:49:10.698944+05",
    "log": "[JobID: 84bd3463] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:49:10.698944+05"
  },
  {
    "job_id": "d85dc258",
    "source": "Hadoop",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:49:24.698944+05",
    "log": "[JobID: d85dc258] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:49:24.698944+05"
  },
  {
    "job_id": "5d4e9f06",
    "source": "Flink",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:49:39.698944+05",
    "log": "[JobID: 5d4e9f06] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:49:39.698944+05"
  },
  {
    "job_id": "bf652591",
    "source": "Flink",
    "filename": "countries63.csv",
    "output_file": "sorted_countries63.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:49:41.698944+05",
    "log": "[JobID: bf652591] Execution completed | Status: SUCCESS | Output file: 'sorted_countries63.csv' | Source: Flink | Timestamp: 2025-06-12T10:49:41.698944+05"
  },
  {
    "job_id": "d85dc258",
    "source": "Hadoop",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:50:09.698944+05",
    "log": "[JobID: d85dc258] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:50:09.698944+05"
  },
  {
    "job_id": "39a4a72f",
    "source": "Glue",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:50:21.698944+05",
    "log": "[JobID: 39a4a72f] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:50:21.698944+05"
  },
  {
    "job_id": "424a3bfd",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:50:33.698944+05",
    "log": "[JobID: 424a3bfd] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:50:33.698944+05"
  },
  {
    "job_id": "97552ee4",
    "source": "Hadoop",
    "filename": "countries82.csv",
    "output_file": "sorted_countries82.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:50:38.698944+05",
    "log": "[JobID: 97552ee4] Execution completed | Status: SUCCESS | Output file: 'sorted_countries82.csv' | Source: Hadoop | Timestamp: 2025-06-12T10:50:38.698944+05"
  },
  {
    "job_id": "4e9f1d3e",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:50:57.698944+05",
    "log": "[JobID: 4e9f1d3e] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T10:50:57.698944+05"
  },
  {
    "job_id": "73004c1d",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:51:07.698944+05",
    "log": "[JobID: 73004c1d] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:51:07.698944+05"
  },
  {
    "job_id": "356ac895",
    "source": "Glue",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:51:10.698944+05",
    "log": "[JobID: 356ac895] Execution failed | Status: FAILED | Error: TypeError: 'NoneType' object is not callable | Source: Glue | Timestamp: 2025-06-12T10:51:10.698944+05\nTypeError: 'NoneType' object is not callable\n\tat lambda_handler.py:11\n\tat app.py:58"
  },
  {
    "job_id": "ac2497e0",
    "source": "Kafka",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:51:38.698944+05",
    "log": "[JobID: ac2497e0] Execution failed | Status: FAILED | Error: java.lang.NullPointerException: Cannot invoke \"String.toString()\" because \"input\" is null | Source: Kafka | Timestamp: 2025-06-12T10:51:38.698944+05\njava.lang.NullPointerException: Cannot invoke \"String.toString()\" because \"input\" is null\n\tat com.example.DataProcessor.process(DataProcessor.java:42)\n\tat com.example.Main.run(Main.java:17)"
  },
  {
    "job_id": "8ea33276",
    "source": "Flink",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:52:03.698944+05",
    "log": "[JobID: 8ea33276] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T10:52:03.698944+05"
  },
  {
    "job_id": "d77a13fb",
    "source": "Kafka",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:52:11.698944+05",
    "log": "[JobID: d77a13fb] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:52:11.698944+05"
  },
  {
    "job_id": "5d4e9f06",
    "source": "Flink",
    "filename": "countries28.csv",
    "output_file": "sorted_countries28.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:52:25.698944+05",
    "log": "[JobID: 5d4e9f06] Execution completed | Status: SUCCESS | Output file: 'sorted_countries28.csv' | Source: Flink | Timestamp: 2025-06-12T10:52:25.698944+05"
  },
  {
    "job_id": "4e9f1d3e",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:52:26.698944+05",
    "log": "[JobID: 4e9f1d3e] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T10:52:26.698944+05"
  },
  {
    "job_id": "8fa046ba",
    "source": "Glue",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:52:31.698944+05",
    "log": "[JobID: 8fa046ba] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:52:31.698944+05"
  },
  {
    "job_id": "84bd3463",
    "source": "Hadoop",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:52:39.698944+05",
    "log": "[JobID: 84bd3463] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T10:52:39.698944+05"
  },
  {
    "job_id": "314b1271",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:52:40.698944+05",
    "log": "[JobID: 314b1271] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T10:52:40.698944+05"
  },
  {
    "job_id": "39a4a72f",
    "source": "Glue",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:52:58.698944+05",
    "log": "[JobID: 39a4a72f] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T10:52:58.698944+05"
  },
  {
    "job_id": "424a3bfd",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:53:02.698944+05",
    "log": "[JobID: 424a3bfd] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T10:53:02.698944+05"
  },
  {
    "job_id": "dddeca91",
    "source": "Hadoop",
    "filename": "countries75.csv",
    "output_file": "sorted_countries75.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:53:51.698944+05",
    "log": "[JobID: dddeca91] Execution completed | Status: SUCCESS | Output file: 'sorted_countries75.csv' | Source: Hadoop | Timestamp: 2025-06-12T10:53:51.698944+05"
  },
  {
    "job_id": "3e6709aa",
    "source": "Hadoop",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:54:39.698944+05",
    "log": "[JobID: 3e6709aa] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:54:39.698944+05"
  },
  {
    "job_id": "4e9f1d3e",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:54:58.698944+05",
    "log": "[JobID: 4e9f1d3e] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T10:54:58.698944+05"
  },
  {
    "job_id": "8fa046ba",
    "source": "Glue",
    "filename": "countries49.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:55:03.698944+05",
    "log": "[JobID: 8fa046ba] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:55:03.698944+05"
  },
  {
    "job_id": "314b1271",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:55:43.698944+05",
    "log": "[JobID: 314b1271] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:55:43.698944+05"
  },
  {
    "job_id": "39a4a72f",
    "source": "Glue",
    "filename": "countries67.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:55:57.698944+05",
    "log": "[JobID: 39a4a72f] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T10:55:57.698944+05"
  },
  {
    "job_id": "d77a13fb",
    "source": "Kafka",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:56:02.698944+05",
    "log": "[JobID: d77a13fb] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T10:56:02.698944+05"
  },
  {
    "job_id": "8ea33276",
    "source": "Flink",
    "filename": "countries29.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:56:45.698944+05",
    "log": "[JobID: 8ea33276] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T10:56:45.698944+05"
  },
  {
    "job_id": "34bfe6de",
    "source": "Spark",
    "filename": "countries57.csv",
    "output_file": "sorted_countries57.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:56:52.698944+05",
    "log": "[JobID: 34bfe6de] Execution completed | Status: SUCCESS | Output file: 'sorted_countries57.csv' | Source: Spark | Timestamp: 2025-06-12T10:56:52.698944+05"
  },
  {
    "job_id": "40f1117e",
    "source": "Glue",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:57:04.698944+05",
    "log": "[JobID: 40f1117e] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Glue | Timestamp: 2025-06-12T10:57:04.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "3e6709aa",
    "source": "Hadoop",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T10:57:14.698944+05",
    "log": "[JobID: 3e6709aa] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T10:57:14.698944+05"
  },
  {
    "job_id": "3ab2b31c",
    "source": "Spark",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:57:14.698944+05",
    "log": "[JobID: 3ab2b31c] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:57:14.698944+05"
  },
  {
    "job_id": "75784204",
    "source": "Airflow",
    "filename": "countries27.csv",
    "output_file": "sorted_countries27.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T10:57:20.698944+05",
    "log": "[JobID: 75784204] Execution completed | Status: SUCCESS | Output file: 'sorted_countries27.csv' | Source: Airflow | Timestamp: 2025-06-12T10:57:20.698944+05"
  },
  {
    "job_id": "c8e14599",
    "source": "Spark",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:57:41.698944+05",
    "log": "[JobID: c8e14599] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:57:41.698944+05"
  },
  {
    "job_id": "424a3bfd",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:57:46.698944+05",
    "log": "[JobID: 424a3bfd] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T10:57:46.698944+05"
  },
  {
    "job_id": "33564564",
    "source": "Spark",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:58:31.698944+05",
    "log": "[JobID: 33564564] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T10:58:31.698944+05"
  },
  {
    "job_id": "ee331d9d",
    "source": "Airflow",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T10:58:36.698944+05",
    "log": "[JobID: ee331d9d] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms | Source: Airflow | Timestamp: 2025-06-12T10:58:36.698944+05\norg.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms\n\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:350)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "a97bbc5e",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:59:08.698944+05",
    "log": "[JobID: a97bbc5e] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T10:59:08.698944+05"
  },
  {
    "job_id": "314b1271",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:59:19.698944+05",
    "log": "[JobID: 314b1271] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:59:19.698944+05"
  },
  {
    "job_id": "9610db1b",
    "source": "Glue",
    "filename": "countries33.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T10:59:28.698944+05",
    "log": "[JobID: 9610db1b] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T10:59:28.698944+05"
  },
  {
    "job_id": "d77a13fb",
    "source": "Kafka",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T10:59:55.698944+05",
    "log": "[JobID: d77a13fb] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T10:59:55.698944+05"
  },
  {
    "job_id": "3e6709aa",
    "source": "Hadoop",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:00:00.698944+05",
    "log": "[JobID: 3e6709aa] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:00:00.698944+05"
  },
  {
    "job_id": "9610db1b",
    "source": "Glue",
    "filename": "countries33.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:00:19.698944+05",
    "log": "[JobID: 9610db1b] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:00:19.698944+05"
  },
  {
    "job_id": "de61ba06",
    "source": "Glue",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:00:37.698944+05",
    "log": "[JobID: de61ba06] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:00:37.698944+05"
  },
  {
    "job_id": "c8e14599",
    "source": "Spark",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:00:41.698944+05",
    "log": "[JobID: c8e14599] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:00:41.698944+05"
  },
  {
    "job_id": "a97bbc5e",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:01:06.698944+05",
    "log": "[JobID: a97bbc5e] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:01:06.698944+05"
  },
  {
    "job_id": "33564564",
    "source": "Spark",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:01:15.698944+05",
    "log": "[JobID: 33564564] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:01:15.698944+05"
  },
  {
    "job_id": "3ab2b31c",
    "source": "Spark",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:01:24.698944+05",
    "log": "[JobID: 3ab2b31c] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:01:24.698944+05"
  },
  {
    "job_id": "f36e1555",
    "source": "Kafka",
    "filename": "countries89.csv",
    "output_file": "sorted_countries89.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:01:29.698944+05",
    "log": "[JobID: f36e1555] Execution completed | Status: SUCCESS | Output file: 'sorted_countries89.csv' | Source: Kafka | Timestamp: 2025-06-12T11:01:29.698944+05"
  },
  {
    "job_id": "9610db1b",
    "source": "Glue",
    "filename": "countries33.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:01:35.698944+05",
    "log": "[JobID: 9610db1b] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:01:35.698944+05"
  },
  {
    "job_id": "de61ba06",
    "source": "Glue",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:01:50.698944+05",
    "log": "[JobID: de61ba06] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:01:50.698944+05"
  },
  {
    "job_id": "3ab2b31c",
    "source": "Spark",
    "filename": "countries9.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:02:16.698944+05",
    "log": "[JobID: 3ab2b31c] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:02:16.698944+05"
  },
  {
    "job_id": "63890623",
    "source": "Flink",
    "filename": "countries82.csv",
    "output_file": "sorted_countries82.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:02:21.698944+05",
    "log": "[JobID: 63890623] Execution completed | Status: SUCCESS | Output file: 'sorted_countries82.csv' | Source: Flink | Timestamp: 2025-06-12T11:02:21.698944+05"
  },
  {
    "job_id": "e05a43d2",
    "source": "Glue",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:02:23.698944+05",
    "log": "[JobID: e05a43d2] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:02:23.698944+05"
  },
  {
    "job_id": "7d40ff41",
    "source": "Hadoop",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:02:26.698944+05",
    "log": "[JobID: 7d40ff41] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:02:26.698944+05"
  },
  {
    "job_id": "a97bbc5e",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:02:26.698944+05",
    "log": "[JobID: a97bbc5e] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:02:26.698944+05"
  },
  {
    "job_id": "3e6709aa",
    "source": "Hadoop",
    "filename": "countries91.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:02:44.698944+05",
    "log": "[JobID: 3e6709aa] Execution failed | Status: FAILED | Error: SyntaxError: invalid syntax in ctrl_flow.py | Source: Hadoop | Timestamp: 2025-06-12T11:02:44.698944+05\nSyntaxError: invalid syntax in ctrl_flow.py\n\tat ctrl_flow.py:101\n\tat main.py:5"
  },
  {
    "job_id": "8ea33276",
    "source": "Flink",
    "filename": "countries29.csv",
    "output_file": "sorted_countries29.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:03:11.698944+05",
    "log": "[JobID: 8ea33276] Execution completed | Status: SUCCESS | Output file: 'sorted_countries29.csv' | Source: Flink | Timestamp: 2025-06-12T11:03:11.698944+05"
  },
  {
    "job_id": "a38ddb8a",
    "source": "Spark",
    "filename": "countries76.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:03:15.698944+05",
    "log": "[JobID: a38ddb8a] Execution failed | Status: FAILED | Error: ValueError: invalid literal for int() with base 10: 'abc' | Source: Spark | Timestamp: 2025-06-12T11:03:15.698944+05\nValueError: invalid literal for int() with base 10: 'abc'\n\tat pandas_read.py:127\n\tat data_processing.py:42"
  },
  {
    "job_id": "55a0e72d",
    "source": "Kafka",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:03:19.698944+05",
    "log": "[JobID: 55a0e72d] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:03:19.698944+05"
  },
  {
    "job_id": "c8e14599",
    "source": "Spark",
    "filename": "countries19.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:03:26.698944+05",
    "log": "[JobID: c8e14599] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:03:26.698944+05"
  },
  {
    "job_id": "97d66ea9",
    "source": "Flink",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:03:27.698944+05",
    "log": "[JobID: 97d66ea9] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:03:27.698944+05"
  },
  {
    "job_id": "f3047387",
    "source": "Glue",
    "filename": "countries96.csv",
    "output_file": "sorted_countries96.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:03:30.698944+05",
    "log": "[JobID: f3047387] Execution completed | Status: SUCCESS | Output file: 'sorted_countries96.csv' | Source: Glue | Timestamp: 2025-06-12T11:03:30.698944+05"
  },
  {
    "job_id": "33564564",
    "source": "Spark",
    "filename": "countries56.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:03:37.698944+05",
    "log": "[JobID: 33564564] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:03:37.698944+05"
  },
  {
    "job_id": "97d66ea9",
    "source": "Flink",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:04:08.698944+05",
    "log": "[JobID: 97d66ea9] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:04:08.698944+05"
  },
  {
    "job_id": "1974a7a7",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:04:13.698944+05",
    "log": "[JobID: 1974a7a7] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:04:13.698944+05"
  },
  {
    "job_id": "e05a43d2",
    "source": "Glue",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:04:17.698944+05",
    "log": "[JobID: e05a43d2] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:04:17.698944+05"
  },
  {
    "job_id": "de61ba06",
    "source": "Glue",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:05:10.698944+05",
    "log": "[JobID: de61ba06] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:05:10.698944+05"
  },
  {
    "job_id": "e05a43d2",
    "source": "Glue",
    "filename": "countries21.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:05:12.698944+05",
    "log": "[JobID: e05a43d2] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:05:12.698944+05"
  },
  {
    "job_id": "3e1d2cf4",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:05:43.698944+05",
    "log": "[JobID: 3e1d2cf4] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:05:43.698944+05"
  },
  {
    "job_id": "55a0e72d",
    "source": "Kafka",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:05:48.698944+05",
    "log": "[JobID: 55a0e72d] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:05:48.698944+05"
  },
  {
    "job_id": "bc7c3a9c",
    "source": "Flink",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:05:50.698944+05",
    "log": "[JobID: bc7c3a9c] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:05:50.698944+05"
  },
  {
    "job_id": "a31d3062",
    "source": "Spark",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:05:56.698944+05",
    "log": "[JobID: a31d3062] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:05:56.698944+05"
  },
  {
    "job_id": "73004c1d",
    "source": "Spark",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:06:06.698944+05",
    "log": "[JobID: 73004c1d] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Spark | Timestamp: 2025-06-12T11:06:06.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "97d66ea9",
    "source": "Flink",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:06:28.698944+05",
    "log": "[JobID: 97d66ea9] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:06:28.698944+05"
  },
  {
    "job_id": "7d40ff41",
    "source": "Hadoop",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:06:35.698944+05",
    "log": "[JobID: 7d40ff41] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:06:35.698944+05"
  },
  {
    "job_id": "3ab2b31c",
    "source": "Spark",
    "filename": "countries9.csv",
    "output_file": "sorted_countries9.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:06:42.698944+05",
    "log": "[JobID: 3ab2b31c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries9.csv' | Source: Spark | Timestamp: 2025-06-12T11:06:42.698944+05"
  },
  {
    "job_id": "de61ba06",
    "source": "Glue",
    "filename": "countries26.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:06:56.698944+05",
    "log": "[JobID: de61ba06] Execution failed | Status: FAILED | Error: org.apache.spark.sql.AnalysisException: cannot resolve '`missingColumn`' given input columns: [id, name, age] | Source: Glue | Timestamp: 2025-06-12T11:06:56.698944+05\norg.apache.spark.sql.AnalysisException: cannot resolve '`missingColumn`' given input columns: [id, name, age]\n\tat org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.error(AnalysisError.scala:46)\n\tat org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.error(AnalysisError.scala:26)"
  },
  {
    "job_id": "36273de0",
    "source": "Kafka",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:07:15.698944+05",
    "log": "[JobID: 36273de0] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:07:15.698944+05"
  },
  {
    "job_id": "7b9ac9ae",
    "source": "Kafka",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:07:37.698944+05",
    "log": "[JobID: 7b9ac9ae] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:07:37.698944+05"
  },
  {
    "job_id": "1974a7a7",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:07:53.698944+05",
    "log": "[JobID: 1974a7a7] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:07:53.698944+05"
  },
  {
    "job_id": "99588196",
    "source": "Glue",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:07:54.698944+05",
    "log": "[JobID: 99588196] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:07:54.698944+05"
  },
  {
    "job_id": "d77a13fb",
    "source": "Kafka",
    "filename": "countries72.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:08:19.698944+05",
    "log": "[JobID: d77a13fb] Execution failed | Status: FAILED | Error: java.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod() | Source: Kafka | Timestamp: 2025-06-12T11:08:19.698944+05\njava.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod()\n\tat com.example.Updater.runUpdate(Updater.java:47)\n\tat com.example.Main.start(Main.java:30)"
  },
  {
    "job_id": "7d40ff41",
    "source": "Hadoop",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:08:32.698944+05",
    "log": "[JobID: 7d40ff41] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:08:32.698944+05"
  },
  {
    "job_id": "03a7c153",
    "source": "Spark",
    "filename": "countries55.csv",
    "output_file": "sorted_countries55.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:08:32.698944+05",
    "log": "[JobID: 03a7c153] Execution completed | Status: SUCCESS | Output file: 'sorted_countries55.csv' | Source: Spark | Timestamp: 2025-06-12T11:08:32.698944+05"
  },
  {
    "job_id": "55a0e72d",
    "source": "Kafka",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:09:25.698944+05",
    "log": "[JobID: 55a0e72d] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:09:25.698944+05"
  },
  {
    "job_id": "3e1d2cf4",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:09:30.698944+05",
    "log": "[JobID: 3e1d2cf4] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:09:30.698944+05"
  },
  {
    "job_id": "bc7c3a9c",
    "source": "Flink",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:09:35.698944+05",
    "log": "[JobID: bc7c3a9c] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:09:35.698944+05"
  },
  {
    "job_id": "a31d3062",
    "source": "Spark",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:09:36.698944+05",
    "log": "[JobID: a31d3062] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:09:36.698944+05"
  },
  {
    "job_id": "7d40ff41",
    "source": "Hadoop",
    "filename": "countries40.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:10:00.698944+05",
    "log": "[JobID: 7d40ff41] Execution failed | Status: FAILED | Error: org.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file | Source: Hadoop | Timestamp: 2025-06-12T11:10:00.698944+05\norg.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file\n\tat org.apache.hadoop.hdfs.DFSUtilClient.call(DFSUtilClient.java:103)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.exists(DistributedFileSystem.java:219)"
  },
  {
    "job_id": "4e9f1d3e",
    "source": "Airflow",
    "filename": "countries7.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:10:15.698944+05",
    "log": "[JobID: 4e9f1d3e] Execution failed | Status: FAILED | Error: org.apache.spark.SparkException: Job aborted due to stage failure | Source: Airflow | Timestamp: 2025-06-12T11:10:15.698944+05\norg.apache.spark.SparkException: Job aborted due to stage failure\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)"
  },
  {
    "job_id": "99588196",
    "source": "Glue",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:10:15.698944+05",
    "log": "[JobID: 99588196] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:10:15.698944+05"
  },
  {
    "job_id": "97d66ea9",
    "source": "Flink",
    "filename": "countries68.csv",
    "output_file": "sorted_countries68.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:10:49.698944+05",
    "log": "[JobID: 97d66ea9] Execution completed | Status: SUCCESS | Output file: 'sorted_countries68.csv' | Source: Flink | Timestamp: 2025-06-12T11:10:49.698944+05"
  },
  {
    "job_id": "36273de0",
    "source": "Kafka",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:10:49.698944+05",
    "log": "[JobID: 36273de0] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:10:49.698944+05"
  },
  {
    "job_id": "456556e8",
    "source": "Glue",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:11:13.698944+05",
    "log": "[JobID: 456556e8] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:11:13.698944+05"
  },
  {
    "job_id": "3b2211a9",
    "source": "Airflow",
    "filename": "countries60.csv",
    "output_file": "sorted_countries60.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:11:14.698944+05",
    "log": "[JobID: 3b2211a9] Execution completed | Status: SUCCESS | Output file: 'sorted_countries60.csv' | Source: Airflow | Timestamp: 2025-06-12T11:11:14.698944+05"
  },
  {
    "job_id": "f71fbfee",
    "source": "Flink",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:11:51.698944+05",
    "log": "[JobID: f71fbfee] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:11:51.698944+05"
  },
  {
    "job_id": "424a3bfd",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:11:54.698944+05",
    "log": "[JobID: 424a3bfd] Execution failed | Status: FAILED | Error: ValueError: invalid literal for int() with base 10: 'abc' | Source: Spark | Timestamp: 2025-06-12T11:11:54.698944+05\nValueError: invalid literal for int() with base 10: 'abc'\n\tat pandas_read.py:127\n\tat data_processing.py:42"
  },
  {
    "job_id": "bc7c3a9c",
    "source": "Flink",
    "filename": "countries36.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:12:13.698944+05",
    "log": "[JobID: bc7c3a9c] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:12:13.698944+05"
  },
  {
    "job_id": "99588196",
    "source": "Glue",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:12:13.698944+05",
    "log": "[JobID: 99588196] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:12:13.698944+05"
  },
  {
    "job_id": "c90a5b33",
    "source": "Flink",
    "filename": "countries99.csv",
    "output_file": "sorted_countries99.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:12:22.698944+05",
    "log": "[JobID: c90a5b33] Execution completed | Status: SUCCESS | Output file: 'sorted_countries99.csv' | Source: Flink | Timestamp: 2025-06-12T11:12:22.698944+05"
  },
  {
    "job_id": "7b9ac9ae",
    "source": "Kafka",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:12:26.698944+05",
    "log": "[JobID: 7b9ac9ae] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:12:26.698944+05"
  },
  {
    "job_id": "8fa046ba",
    "source": "Glue",
    "filename": "countries49.csv",
    "output_file": "sorted_countries49.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:12:38.698944+05",
    "log": "[JobID: 8fa046ba] Execution completed | Status: SUCCESS | Output file: 'sorted_countries49.csv' | Source: Glue | Timestamp: 2025-06-12T11:12:38.698944+05"
  },
  {
    "job_id": "1974a7a7",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:12:38.698944+05",
    "log": "[JobID: 1974a7a7] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:12:38.698944+05"
  },
  {
    "job_id": "456556e8",
    "source": "Glue",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:13:04.698944+05",
    "log": "[JobID: 456556e8] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:13:04.698944+05"
  },
  {
    "job_id": "3e1d2cf4",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:13:44.698944+05",
    "log": "[JobID: 3e1d2cf4] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:13:44.698944+05"
  },
  {
    "job_id": "456556e8",
    "source": "Glue",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:14:05.698944+05",
    "log": "[JobID: 456556e8] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:14:05.698944+05"
  },
  {
    "job_id": "f71fbfee",
    "source": "Flink",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:14:11.698944+05",
    "log": "[JobID: f71fbfee] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:14:11.698944+05"
  },
  {
    "job_id": "e05a43d2",
    "source": "Glue",
    "filename": "countries21.csv",
    "output_file": "sorted_countries21.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:14:17.698944+05",
    "log": "[JobID: e05a43d2] Execution completed | Status: SUCCESS | Output file: 'sorted_countries21.csv' | Source: Glue | Timestamp: 2025-06-12T11:14:17.698944+05"
  },
  {
    "job_id": "36273de0",
    "source": "Kafka",
    "filename": "countries53.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:14:20.698944+05",
    "log": "[JobID: 36273de0] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:14:20.698944+05"
  },
  {
    "job_id": "a31d3062",
    "source": "Spark",
    "filename": "countries41.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:14:21.698944+05",
    "log": "[JobID: a31d3062] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:14:21.698944+05"
  },
  {
    "job_id": "55a0e72d",
    "source": "Kafka",
    "filename": "countries11.csv",
    "output_file": "sorted_countries11.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:14:25.698944+05",
    "log": "[JobID: 55a0e72d] Execution completed | Status: SUCCESS | Output file: 'sorted_countries11.csv' | Source: Kafka | Timestamp: 2025-06-12T11:14:25.698944+05"
  },
  {
    "job_id": "26fc32c2",
    "source": "Hadoop",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:14:52.698944+05",
    "log": "[JobID: 26fc32c2] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:14:52.698944+05"
  },
  {
    "job_id": "36273de0",
    "source": "Kafka",
    "filename": "countries53.csv",
    "output_file": "sorted_countries53.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:15:05.698944+05",
    "log": "[JobID: 36273de0] Execution completed | Status: SUCCESS | Output file: 'sorted_countries53.csv' | Source: Kafka | Timestamp: 2025-06-12T11:15:05.698944+05"
  },
  {
    "job_id": "d85dc258",
    "source": "Hadoop",
    "filename": "countries34.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:15:29.698944+05",
    "log": "[JobID: d85dc258] Execution failed | Status: FAILED | Error: org.apache.spark.SparkException: Job aborted due to stage failure | Source: Hadoop | Timestamp: 2025-06-12T11:15:29.698944+05\norg.apache.spark.SparkException: Job aborted due to stage failure\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)"
  },
  {
    "job_id": "7b9ac9ae",
    "source": "Kafka",
    "filename": "countries46.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:16:42.698944+05",
    "log": "[JobID: 7b9ac9ae] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:16:42.698944+05"
  },
  {
    "job_id": "80dcfa58",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:18:07.698944+05",
    "log": "[JobID: 80dcfa58] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:18:07.698944+05"
  },
  {
    "job_id": "b642eb1a",
    "source": "Spark",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:18:37.698944+05",
    "log": "[JobID: b642eb1a] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:18:37.698944+05"
  },
  {
    "job_id": "84bd3463",
    "source": "Hadoop",
    "filename": "countries51.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:18:52.698944+05",
    "log": "[JobID: 84bd3463] Execution failed | Status: FAILED | Error: ValueError: math domain error | Source: Hadoop | Timestamp: 2025-06-12T11:18:52.698944+05\nValueError: math domain error\n\tat compute_math.py:88\n\tat process.py:15"
  },
  {
    "job_id": "f71fbfee",
    "source": "Flink",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:19:05.698944+05",
    "log": "[JobID: f71fbfee] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:19:05.698944+05"
  },
  {
    "job_id": "b642eb1a",
    "source": "Spark",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:19:13.698944+05",
    "log": "[JobID: b642eb1a] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:19:13.698944+05"
  },
  {
    "job_id": "26fc32c2",
    "source": "Hadoop",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:19:20.698944+05",
    "log": "[JobID: 26fc32c2] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:19:20.698944+05"
  },
  {
    "job_id": "33564564",
    "source": "Spark",
    "filename": "countries56.csv",
    "output_file": "sorted_countries56.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:19:49.698944+05",
    "log": "[JobID: 33564564] Execution completed | Status: SUCCESS | Output file: 'sorted_countries56.csv' | Source: Spark | Timestamp: 2025-06-12T11:19:49.698944+05"
  },
  {
    "job_id": "26fc32c2",
    "source": "Hadoop",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:20:05.698944+05",
    "log": "[JobID: 26fc32c2] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:20:05.698944+05"
  },
  {
    "job_id": "b642eb1a",
    "source": "Spark",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:21:04.698944+05",
    "log": "[JobID: b642eb1a] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:21:04.698944+05"
  },
  {
    "job_id": "80dcfa58",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:21:19.698944+05",
    "log": "[JobID: 80dcfa58] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:21:19.698944+05"
  },
  {
    "job_id": "bc7c3a9c",
    "source": "Flink",
    "filename": "countries36.csv",
    "output_file": "sorted_countries36.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:21:20.698944+05",
    "log": "[JobID: bc7c3a9c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries36.csv' | Source: Flink | Timestamp: 2025-06-12T11:21:20.698944+05"
  },
  {
    "job_id": "1f7ddc6c",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:21:35.698944+05",
    "log": "[JobID: 1f7ddc6c] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:21:35.698944+05"
  },
  {
    "job_id": "1f7ddc6c",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:22:10.698944+05",
    "log": "[JobID: 1f7ddc6c] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:22:10.698944+05"
  },
  {
    "job_id": "80dcfa58",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:22:28.698944+05",
    "log": "[JobID: 80dcfa58] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:22:28.698944+05"
  },
  {
    "job_id": "39a4a72f",
    "source": "Glue",
    "filename": "countries67.csv",
    "output_file": "sorted_countries67.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:22:33.698944+05",
    "log": "[JobID: 39a4a72f] Execution completed | Status: SUCCESS | Output file: 'sorted_countries67.csv' | Source: Glue | Timestamp: 2025-06-12T11:22:33.698944+05"
  },
  {
    "job_id": "7b9ac9ae",
    "source": "Kafka",
    "filename": "countries46.csv",
    "output_file": "sorted_countries46.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:23:14.698944+05",
    "log": "[JobID: 7b9ac9ae] Execution completed | Status: SUCCESS | Output file: 'sorted_countries46.csv' | Source: Kafka | Timestamp: 2025-06-12T11:23:14.698944+05"
  },
  {
    "job_id": "26fc32c2",
    "source": "Hadoop",
    "filename": "countries59.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:24:19.698944+05",
    "log": "[JobID: 26fc32c2] Execution failed | Status: FAILED | Error: java.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod() | Source: Hadoop | Timestamp: 2025-06-12T11:24:19.698944+05\njava.lang.NoSuchMethodError: com.example.LegacyUtil.oldMethod()\n\tat com.example.Updater.runUpdate(Updater.java:47)\n\tat com.example.Main.start(Main.java:30)"
  },
  {
    "job_id": "9610db1b",
    "source": "Glue",
    "filename": "countries33.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:24:20.698944+05",
    "log": "[JobID: 9610db1b] Execution failed | Status: FAILED | Error: TypeError: 'NoneType' object is not callable | Source: Glue | Timestamp: 2025-06-12T11:24:20.698944+05\nTypeError: 'NoneType' object is not callable\n\tat lambda_handler.py:11\n\tat app.py:58"
  },
  {
    "job_id": "a97bbc5e",
    "source": "Hadoop",
    "filename": "countries42.csv",
    "output_file": "sorted_countries42.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:24:27.698944+05",
    "log": "[JobID: a97bbc5e] Execution completed | Status: SUCCESS | Output file: 'sorted_countries42.csv' | Source: Hadoop | Timestamp: 2025-06-12T11:24:27.698944+05"
  },
  {
    "job_id": "aa4d657a",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:25:24.698944+05",
    "log": "[JobID: aa4d657a] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:25:24.698944+05"
  },
  {
    "job_id": "7fe0ea0c",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:25:32.698944+05",
    "log": "[JobID: 7fe0ea0c] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:25:32.698944+05"
  },
  {
    "job_id": "eb8c6fc2",
    "source": "Glue",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:26:28.698944+05",
    "log": "[JobID: eb8c6fc2] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:26:28.698944+05"
  },
  {
    "job_id": "1f7ddc6c",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:27:08.698944+05",
    "log": "[JobID: 1f7ddc6c] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:27:08.698944+05"
  },
  {
    "job_id": "7fe0ea0c",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:27:32.698944+05",
    "log": "[JobID: 7fe0ea0c] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:27:32.698944+05"
  },
  {
    "job_id": "456556e8",
    "source": "Glue",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:27:33.698944+05",
    "log": "[JobID: 456556e8] Execution failed | Status: FAILED | Error: SyntaxError: invalid syntax in ctrl_flow.py | Source: Glue | Timestamp: 2025-06-12T11:27:33.698944+05\nSyntaxError: invalid syntax in ctrl_flow.py\n\tat ctrl_flow.py:101\n\tat main.py:5"
  },
  {
    "job_id": "76684ca1",
    "source": "Flink",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:28:08.698944+05",
    "log": "[JobID: 76684ca1] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:28:08.698944+05"
  },
  {
    "job_id": "aa4d657a",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:28:20.698944+05",
    "log": "[JobID: aa4d657a] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:28:20.698944+05"
  },
  {
    "job_id": "eb8c6fc2",
    "source": "Glue",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:28:23.698944+05",
    "log": "[JobID: eb8c6fc2] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:28:23.698944+05"
  },
  {
    "job_id": "d797ccd6",
    "source": "Spark",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:28:59.698944+05",
    "log": "[JobID: d797ccd6] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:28:59.698944+05"
  },
  {
    "job_id": "314b1271",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": "sorted_countries38.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:29:03.698944+05",
    "log": "[JobID: 314b1271] Execution completed | Status: SUCCESS | Output file: 'sorted_countries38.csv' | Source: Kafka | Timestamp: 2025-06-12T11:29:03.698944+05"
  },
  {
    "job_id": "eb8c6fc2",
    "source": "Glue",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:29:03.698944+05",
    "log": "[JobID: eb8c6fc2] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:29:03.698944+05"
  },
  {
    "job_id": "b642eb1a",
    "source": "Spark",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:29:07.698944+05",
    "log": "[JobID: b642eb1a] Execution failed | Status: FAILED | Error: ZeroDivisionError: division by zero | Source: Spark | Timestamp: 2025-06-12T11:29:07.698944+05\nZeroDivisionError: division by zero\n\tat calculate.py:87\n\tat main.py:54"
  },
  {
    "job_id": "3f7469c5",
    "source": "Hadoop",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:29:16.698944+05",
    "log": "[JobID: 3f7469c5] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:29:16.698944+05"
  },
  {
    "job_id": "17047309",
    "source": "Airflow",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:29:19.698944+05",
    "log": "[JobID: 17047309] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T11:29:19.698944+05"
  },
  {
    "job_id": "a31d3062",
    "source": "Spark",
    "filename": "countries41.csv",
    "output_file": "sorted_countries41.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:29:33.698944+05",
    "log": "[JobID: a31d3062] Execution completed | Status: SUCCESS | Output file: 'sorted_countries41.csv' | Source: Spark | Timestamp: 2025-06-12T11:29:33.698944+05"
  },
  {
    "job_id": "d797ccd6",
    "source": "Spark",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:29:50.698944+05",
    "log": "[JobID: d797ccd6] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:29:50.698944+05"
  },
  {
    "job_id": "6796b8ca",
    "source": "Hadoop",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:30:12.698944+05",
    "log": "[JobID: 6796b8ca] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:30:12.698944+05"
  },
  {
    "job_id": "aa4d657a",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:30:18.698944+05",
    "log": "[JobID: aa4d657a] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:30:18.698944+05"
  },
  {
    "job_id": "d28c3f2f",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:30:22.698944+05",
    "log": "[JobID: d28c3f2f] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:30:22.698944+05"
  },
  {
    "job_id": "c8e14599",
    "source": "Spark",
    "filename": "countries19.csv",
    "output_file": "sorted_countries19.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:31:30.698944+05",
    "log": "[JobID: c8e14599] Execution completed | Status: SUCCESS | Output file: 'sorted_countries19.csv' | Source: Spark | Timestamp: 2025-06-12T11:31:30.698944+05"
  },
  {
    "job_id": "17047309",
    "source": "Airflow",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:31:44.698944+05",
    "log": "[JobID: 17047309] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T11:31:44.698944+05"
  },
  {
    "job_id": "7fe0ea0c",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:31:45.698944+05",
    "log": "[JobID: 7fe0ea0c] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:31:45.698944+05"
  },
  {
    "job_id": "76684ca1",
    "source": "Flink",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:31:51.698944+05",
    "log": "[JobID: 76684ca1] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:31:51.698944+05"
  },
  {
    "job_id": "a1442cde",
    "source": "Kafka",
    "filename": "countries77.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:32:03.698944+05",
    "log": "[JobID: a1442cde] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:32:03.698944+05"
  },
  {
    "job_id": "6796b8ca",
    "source": "Hadoop",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:32:06.698944+05",
    "log": "[JobID: 6796b8ca] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:32:06.698944+05"
  },
  {
    "job_id": "3f7469c5",
    "source": "Hadoop",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:32:31.698944+05",
    "log": "[JobID: 3f7469c5] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:32:31.698944+05"
  },
  {
    "job_id": "6796b8ca",
    "source": "Hadoop",
    "filename": "countries90.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:32:58.698944+05",
    "log": "[JobID: 6796b8ca] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:32:58.698944+05"
  },
  {
    "job_id": "99588196",
    "source": "Glue",
    "filename": "countries51.csv",
    "output_file": "sorted_countries51.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:33:00.698944+05",
    "log": "[JobID: 99588196] Execution completed | Status: SUCCESS | Output file: 'sorted_countries51.csv' | Source: Glue | Timestamp: 2025-06-12T11:33:00.698944+05"
  },
  {
    "job_id": "76684ca1",
    "source": "Flink",
    "filename": "countries64.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:33:09.698944+05",
    "log": "[JobID: 76684ca1] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:33:09.698944+05"
  },
  {
    "job_id": "1974a7a7",
    "source": "Flink",
    "filename": "countries70.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:33:12.698944+05",
    "log": "[JobID: 1974a7a7] Execution failed | Status: FAILED | Error: IndexError: tuple index out of range | Source: Flink | Timestamp: 2025-06-12T11:33:12.698944+05\nIndexError: tuple index out of range\n\tat data_analysis.py:112\n\tat main.py:42"
  },
  {
    "job_id": "4f6df5a4",
    "source": "Glue",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:33:30.698944+05",
    "log": "[JobID: 4f6df5a4] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:33:30.698944+05"
  },
  {
    "job_id": "a1442cde",
    "source": "Kafka",
    "filename": "countries77.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:33:38.698944+05",
    "log": "[JobID: a1442cde] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:33:38.698944+05"
  },
  {
    "job_id": "60f131f8",
    "source": "Hadoop",
    "filename": "countries32.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:33:53.698944+05",
    "log": "[JobID: 60f131f8] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:33:53.698944+05"
  },
  {
    "job_id": "3f7469c5",
    "source": "Hadoop",
    "filename": "countries4.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:34:16.698944+05",
    "log": "[JobID: 3f7469c5] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:34:16.698944+05"
  },
  {
    "job_id": "d797ccd6",
    "source": "Spark",
    "filename": "countries65.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:34:36.698944+05",
    "log": "[JobID: d797ccd6] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:34:36.698944+05"
  },
  {
    "job_id": "d28c3f2f",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:34:41.698944+05",
    "log": "[JobID: d28c3f2f] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:34:41.698944+05"
  },
  {
    "job_id": "a1442cde",
    "source": "Kafka",
    "filename": "countries77.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:34:55.698944+05",
    "log": "[JobID: a1442cde] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:34:55.698944+05"
  },
  {
    "job_id": "4f6df5a4",
    "source": "Glue",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:35:10.698944+05",
    "log": "[JobID: 4f6df5a4] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:35:10.698944+05"
  },
  {
    "job_id": "082dab24",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:35:24.698944+05",
    "log": "[JobID: 082dab24] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:35:24.698944+05"
  },
  {
    "job_id": "17047309",
    "source": "Airflow",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:35:39.698944+05",
    "log": "[JobID: 17047309] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T11:35:39.698944+05"
  },
  {
    "job_id": "8eca6d62",
    "source": "Kafka",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:35:51.698944+05",
    "log": "[JobID: 8eca6d62] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:35:51.698944+05"
  },
  {
    "job_id": "4d4886d2",
    "source": "Kafka",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:37:15.698944+05",
    "log": "[JobID: 4d4886d2] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:37:15.698944+05"
  },
  {
    "job_id": "8eca6d62",
    "source": "Kafka",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:37:32.698944+05",
    "log": "[JobID: 8eca6d62] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:37:32.698944+05"
  },
  {
    "job_id": "80dcfa58",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:37:35.698944+05",
    "log": "[JobID: 80dcfa58] Execution failed | Status: FAILED | Error: java.lang.RuntimeException: Failed to execute the Hadoop job | Source: Spark | Timestamp: 2025-06-12T11:37:35.698944+05\njava.lang.RuntimeException: Failed to execute the Hadoop job\n\tat org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:2119)\n\tat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:145)"
  },
  {
    "job_id": "4f6df5a4",
    "source": "Glue",
    "filename": "countries61.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:37:37.698944+05",
    "log": "[JobID: 4f6df5a4] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:37:37.698944+05"
  },
  {
    "job_id": "082dab24",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:37:59.698944+05",
    "log": "[JobID: 082dab24] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:37:59.698944+05"
  },
  {
    "job_id": "60f131f8",
    "source": "Hadoop",
    "filename": "countries32.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:38:09.698944+05",
    "log": "[JobID: 60f131f8] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:38:09.698944+05"
  },
  {
    "job_id": "3e1d2cf4",
    "source": "Spark",
    "filename": "countries79.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:38:25.698944+05",
    "log": "[JobID: 3e1d2cf4] Execution failed | Status: FAILED | Error: AttributeError: module 'json' has no attribute 'dumps' | Source: Spark | Timestamp: 2025-06-12T11:38:25.698944+05\nAttributeError: module 'json' has no attribute 'dumps'\n\tat data_serializer.py:37\n\tat main.py:12"
  },
  {
    "job_id": "6796b8ca",
    "source": "Hadoop",
    "filename": "countries90.csv",
    "output_file": "sorted_countries90.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:38:30.698944+05",
    "log": "[JobID: 6796b8ca] Execution completed | Status: SUCCESS | Output file: 'sorted_countries90.csv' | Source: Hadoop | Timestamp: 2025-06-12T11:38:30.698944+05"
  },
  {
    "job_id": "d28c3f2f",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:38:40.698944+05",
    "log": "[JobID: d28c3f2f] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:38:40.698944+05"
  },
  {
    "job_id": "17047309",
    "source": "Airflow",
    "filename": "countries86.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:38:45.698944+05",
    "log": "[JobID: 17047309] Execution failed | Status: FAILED | Error: ZeroDivisionError: division by zero | Source: Airflow | Timestamp: 2025-06-12T11:38:45.698944+05\nZeroDivisionError: division by zero\n\tat calculate.py:87\n\tat main.py:54"
  },
  {
    "job_id": "9bbced7a",
    "source": "Kafka",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:39:05.698944+05",
    "log": "[JobID: 9bbced7a] Status update | Status: WAITING | Source: Kafka | Timestamp: 2025-06-12T11:39:05.698944+05"
  },
  {
    "job_id": "082dab24",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:39:11.698944+05",
    "log": "[JobID: 082dab24] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:39:11.698944+05"
  },
  {
    "job_id": "7fe0ea0c",
    "source": "Kafka",
    "filename": "countries38.csv",
    "output_file": "sorted_countries38.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:39:15.698944+05",
    "log": "[JobID: 7fe0ea0c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries38.csv' | Source: Kafka | Timestamp: 2025-06-12T11:39:15.698944+05"
  },
  {
    "job_id": "4d4886d2",
    "source": "Kafka",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:39:25.698944+05",
    "log": "[JobID: 4d4886d2] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:39:25.698944+05"
  },
  {
    "job_id": "12996e3c",
    "source": "Spark",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:40:20.698944+05",
    "log": "[JobID: 12996e3c] Status update | Status: WAITING | Source: Spark | Timestamp: 2025-06-12T11:40:20.698944+05"
  },
  {
    "job_id": "8eca6d62",
    "source": "Kafka",
    "filename": "countries85.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:40:27.698944+05",
    "log": "[JobID: 8eca6d62] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:40:27.698944+05"
  },
  {
    "job_id": "2b3cb1bd",
    "source": "Hadoop",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:40:49.698944+05",
    "log": "[JobID: 2b3cb1bd] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:40:49.698944+05"
  },
  {
    "job_id": "12996e3c",
    "source": "Spark",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:41:02.698944+05",
    "log": "[JobID: 12996e3c] Status update | Status: PENDING | Source: Spark | Timestamp: 2025-06-12T11:41:02.698944+05"
  },
  {
    "job_id": "60f131f8",
    "source": "Hadoop",
    "filename": "countries32.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:41:11.698944+05",
    "log": "[JobID: 60f131f8] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:41:11.698944+05"
  },
  {
    "job_id": "de697df5",
    "source": "Hadoop",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:41:16.698944+05",
    "log": "[JobID: de697df5] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:41:16.698944+05"
  },
  {
    "job_id": "a45a9769",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:42:00.698944+05",
    "log": "[JobID: a45a9769] Status update | Status: WAITING | Source: Flink | Timestamp: 2025-06-12T11:42:00.698944+05"
  },
  {
    "job_id": "7f610375",
    "source": "Airflow",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:42:01.698944+05",
    "log": "[JobID: 7f610375] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T11:42:01.698944+05"
  },
  {
    "job_id": "1f7ddc6c",
    "source": "Spark",
    "filename": "countries83.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:42:07.698944+05",
    "log": "[JobID: 1f7ddc6c] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms | Source: Spark | Timestamp: 2025-06-12T11:42:07.698944+05\norg.apache.kafka.common.errors.TimeoutException: Topic partition assignment timeout after 60000 ms\n\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:350)\n\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1245)"
  },
  {
    "job_id": "4d4886d2",
    "source": "Kafka",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:42:15.698944+05",
    "log": "[JobID: 4d4886d2] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:42:15.698944+05"
  },
  {
    "job_id": "9bbced7a",
    "source": "Kafka",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:42:23.698944+05",
    "log": "[JobID: 9bbced7a] Status update | Status: PENDING | Source: Kafka | Timestamp: 2025-06-12T11:42:23.698944+05"
  },
  {
    "job_id": "2b3cb1bd",
    "source": "Hadoop",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:42:38.698944+05",
    "log": "[JobID: 2b3cb1bd] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:42:38.698944+05"
  },
  {
    "job_id": "a45a9769",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:42:47.698944+05",
    "log": "[JobID: a45a9769] Status update | Status: PENDING | Source: Flink | Timestamp: 2025-06-12T11:42:47.698944+05"
  },
  {
    "job_id": "12996e3c",
    "source": "Spark",
    "filename": "countries88.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:42:51.698944+05",
    "log": "[JobID: 12996e3c] Status update | Status: RUNNING | Source: Spark | Timestamp: 2025-06-12T11:42:51.698944+05"
  },
  {
    "job_id": "15d229f8",
    "source": "Airflow",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:43:16.698944+05",
    "log": "[JobID: 15d229f8] Status update | Status: WAITING | Source: Airflow | Timestamp: 2025-06-12T11:43:16.698944+05"
  },
  {
    "job_id": "f71fbfee",
    "source": "Flink",
    "filename": "countries79.csv",
    "output_file": "sorted_countries79.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:43:42.698944+05",
    "log": "[JobID: f71fbfee] Execution completed | Status: SUCCESS | Output file: 'sorted_countries79.csv' | Source: Flink | Timestamp: 2025-06-12T11:43:42.698944+05"
  },
  {
    "job_id": "a45a9769",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:43:47.698944+05",
    "log": "[JobID: a45a9769] Status update | Status: RUNNING | Source: Flink | Timestamp: 2025-06-12T11:43:47.698944+05"
  },
  {
    "job_id": "2e951216",
    "source": "Hadoop",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:44:07.698944+05",
    "log": "[JobID: 2e951216] Status update | Status: WAITING | Source: Hadoop | Timestamp: 2025-06-12T11:44:07.698944+05"
  },
  {
    "job_id": "de697df5",
    "source": "Hadoop",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:44:43.698944+05",
    "log": "[JobID: de697df5] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:44:43.698944+05"
  },
  {
    "job_id": "2b3cb1bd",
    "source": "Hadoop",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:45:16.698944+05",
    "log": "[JobID: 2b3cb1bd] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:45:16.698944+05"
  },
  {
    "job_id": "6bb9c57f",
    "source": "Glue",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "WAITING",
    "timestamp": "2025-06-12T11:45:27.698944+05",
    "log": "[JobID: 6bb9c57f] Status update | Status: WAITING | Source: Glue | Timestamp: 2025-06-12T11:45:27.698944+05"
  },
  {
    "job_id": "9bbced7a",
    "source": "Kafka",
    "filename": "countries27.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:45:34.698944+05",
    "log": "[JobID: 9bbced7a] Status update | Status: RUNNING | Source: Kafka | Timestamp: 2025-06-12T11:45:34.698944+05"
  },
  {
    "job_id": "7f610375",
    "source": "Airflow",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:46:00.698944+05",
    "log": "[JobID: 7f610375] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T11:46:00.698944+05"
  },
  {
    "job_id": "2b3cb1bd",
    "source": "Hadoop",
    "filename": "countries2.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:46:10.698944+05",
    "log": "[JobID: 2b3cb1bd] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Hadoop | Timestamp: 2025-06-12T11:46:10.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "aa4d657a",
    "source": "Spark",
    "filename": "countries1.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:46:19.698944+05",
    "log": "[JobID: aa4d657a] Execution failed | Status: FAILED | Error: com.amazonaws.services.glue.GlueException: Failed to connect to Glue metadata store | Source: Spark | Timestamp: 2025-06-12T11:46:19.698944+05\ncom.amazonaws.services.glue.GlueException: Failed to connect to Glue metadata store\n\tat com.amazonaws.services.glue.AWSGlueClient.invoke(AWSGlueClient.java:235)\n\tat com.amazonaws.services.glue.AWSGlueClient.getDatabase(AWSGlueClient.java:97)"
  },
  {
    "job_id": "2e951216",
    "source": "Hadoop",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:46:23.698944+05",
    "log": "[JobID: 2e951216] Status update | Status: PENDING | Source: Hadoop | Timestamp: 2025-06-12T11:46:23.698944+05"
  },
  {
    "job_id": "6bb9c57f",
    "source": "Glue",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:47:07.698944+05",
    "log": "[JobID: 6bb9c57f] Status update | Status: RUNNING | Source: Glue | Timestamp: 2025-06-12T11:47:07.698944+05"
  },
  {
    "job_id": "2e951216",
    "source": "Hadoop",
    "filename": "countries28.csv",
    "output_file": "sorted_countries28.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:08.698944+05",
    "log": "[JobID: 2e951216] Execution completed | Status: SUCCESS | Output file: 'sorted_countries28.csv' | Source: Hadoop | Timestamp: 2025-06-12T11:47:08.698944+05"
  },
  {
    "job_id": "3f7469c5",
    "source": "Hadoop",
    "filename": "countries4.csv",
    "output_file": "sorted_countries4.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:09.698944+05",
    "log": "[JobID: 3f7469c5] Execution completed | Status: SUCCESS | Output file: 'sorted_countries4.csv' | Source: Hadoop | Timestamp: 2025-06-12T11:47:09.698944+05"
  },
  {
    "job_id": "4d4886d2",
    "source": "Kafka",
    "filename": "countries60.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:09.698944+05",
    "log": "[JobID: 4d4886d2] Execution failed | Status: FAILED | Error: NameError: name 'config' is not defined | Source: Kafka | Timestamp: 2025-06-12T11:47:09.698944+05\nNameError: name 'config' is not defined\n\tat config_reader.py:22\n\tat boot.py:11"
  },
  {
    "job_id": "082dab24",
    "source": "Flink",
    "filename": "countries55.csv",
    "output_file": "sorted_countries55.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:11.698944+05",
    "log": "[JobID: 082dab24] Execution completed | Status: SUCCESS | Output file: 'sorted_countries55.csv' | Source: Flink | Timestamp: 2025-06-12T11:47:11.698944+05"
  },
  {
    "job_id": "eb8c6fc2",
    "source": "Glue",
    "filename": "countries86.csv",
    "output_file": "sorted_countries86.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:11.698944+05",
    "log": "[JobID: eb8c6fc2] Execution completed | Status: SUCCESS | Output file: 'sorted_countries86.csv' | Source: Glue | Timestamp: 2025-06-12T11:47:11.698944+05"
  },
  {
    "job_id": "7f610375",
    "source": "Airflow",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:12.698944+05",
    "log": "[JobID: 7f610375] Execution failed | Status: FAILED | Error: IndexError: tuple index out of range | Source: Airflow | Timestamp: 2025-06-12T11:47:12.698944+05\nIndexError: tuple index out of range\n\tat data_analysis.py:112\n\tat main.py:42"
  },
  {
    "job_id": "de697df5",
    "source": "Hadoop",
    "filename": "countries11.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:47:12.698944+05",
    "log": "[JobID: de697df5] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:47:12.698944+05"
  },
  {
    "job_id": "d28c3f2f",
    "source": "Hadoop",
    "filename": "countries68.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:13.698944+05",
    "log": "[JobID: d28c3f2f] Execution failed | Status: FAILED | Error: TypeError: 'int' object is not subscriptable | Source: Hadoop | Timestamp: 2025-06-12T11:47:13.698944+05\nTypeError: 'int' object is not subscriptable\n\tat list_ops.py:77\n\tat main.py:58"
  },
  {
    "job_id": "7f610375",
    "source": "Airflow",
    "filename": "countries84.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:47:14.698944+05",
    "log": "[JobID: 7f610375] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T11:47:14.698944+05"
  },
  {
    "job_id": "9bbced7a",
    "source": "Kafka",
    "filename": "countries27.csv",
    "output_file": "sorted_countries27.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:22.698944+05",
    "log": "[JobID: 9bbced7a] Execution completed | Status: SUCCESS | Output file: 'sorted_countries27.csv' | Source: Kafka | Timestamp: 2025-06-12T11:47:22.698944+05"
  },
  {
    "job_id": "6bb9c57f",
    "source": "Glue",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:47:23.698944+05",
    "log": "[JobID: 6bb9c57f] Status update | Status: PENDING | Source: Glue | Timestamp: 2025-06-12T11:47:23.698944+05"
  },
  {
    "job_id": "a45a9769",
    "source": "Flink",
    "filename": "countries2.csv",
    "output_file": "sorted_countries2.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:25.698944+05",
    "log": "[JobID: a45a9769] Execution completed | Status: SUCCESS | Output file: 'sorted_countries2.csv' | Source: Flink | Timestamp: 2025-06-12T11:47:25.698944+05"
  },
  {
    "job_id": "60f131f8",
    "source": "Hadoop",
    "filename": "countries32.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:29.698944+05",
    "log": "[JobID: 60f131f8] Execution failed | Status: FAILED | Error: org.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file | Source: Hadoop | Timestamp: 2025-06-12T11:47:29.698944+05\norg.apache.hadoop.ipc.RemoteException: File /user/hadoop/input.txt is not an HDFS file\n\tat org.apache.hadoop.hdfs.DFSUtilClient.call(DFSUtilClient.java:103)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.exists(DistributedFileSystem.java:219)"
  },
  {
    "job_id": "a1442cde",
    "source": "Kafka",
    "filename": "countries77.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:34.698944+05",
    "log": "[JobID: a1442cde] Execution failed | Status: FAILED | Error: java.lang.IllegalArgumentException: Port number out of range: 70000 | Source: Kafka | Timestamp: 2025-06-12T11:47:34.698944+05\njava.lang.IllegalArgumentException: Port number out of range: 70000\n\tat java.net.ServerSocket.bind(ServerSocket.java:223)\n\tat com.example.NetworkService.start(NetworkService.java:89)"
  },
  {
    "job_id": "12996e3c",
    "source": "Spark",
    "filename": "countries88.csv",
    "output_file": "sorted_countries88.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:34.698944+05",
    "log": "[JobID: 12996e3c] Execution completed | Status: SUCCESS | Output file: 'sorted_countries88.csv' | Source: Spark | Timestamp: 2025-06-12T11:47:34.698944+05"
  },
  {
    "job_id": "8eca6d62",
    "source": "Kafka",
    "filename": "countries85.csv",
    "output_file": "sorted_countries85.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:35.698944+05",
    "log": "[JobID: 8eca6d62] Execution completed | Status: SUCCESS | Output file: 'sorted_countries85.csv' | Source: Kafka | Timestamp: 2025-06-12T11:47:35.698944+05"
  },
  {
    "job_id": "d797ccd6",
    "source": "Spark",
    "filename": "countries65.csv",
    "output_file": "sorted_countries65.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:35.698944+05",
    "log": "[JobID: d797ccd6] Execution completed | Status: SUCCESS | Output file: 'sorted_countries65.csv' | Source: Spark | Timestamp: 2025-06-12T11:47:35.698944+05"
  },
  {
    "job_id": "de697df5",
    "source": "Hadoop",
    "filename": "countries11.csv",
    "output_file": "sorted_countries11.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:39.698944+05",
    "log": "[JobID: de697df5] Execution completed | Status: SUCCESS | Output file: 'sorted_countries11.csv' | Source: Hadoop | Timestamp: 2025-06-12T11:47:39.698944+05"
  },
  {
    "job_id": "76684ca1",
    "source": "Flink",
    "filename": "countries64.csv",
    "output_file": "sorted_countries64.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:41.698944+05",
    "log": "[JobID: 76684ca1] Execution completed | Status: SUCCESS | Output file: 'sorted_countries64.csv' | Source: Flink | Timestamp: 2025-06-12T11:47:41.698944+05"
  },
  {
    "job_id": "15d229f8",
    "source": "Airflow",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:41.698944+05",
    "log": "[JobID: 15d229f8] Execution failed | Status: FAILED | Error: IndexError: tuple index out of range | Source: Airflow | Timestamp: 2025-06-12T11:47:41.698944+05\nIndexError: tuple index out of range\n\tat data_analysis.py:112\n\tat main.py:42"
  },
  {
    "job_id": "15d229f8",
    "source": "Airflow",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:47:44.698944+05",
    "log": "[JobID: 15d229f8] Status update | Status: RUNNING | Source: Airflow | Timestamp: 2025-06-12T11:47:44.698944+05"
  },
  {
    "job_id": "4f6df5a4",
    "source": "Glue",
    "filename": "countries61.csv",
    "output_file": "sorted_countries61.csv",
    "status": "SUCCESS",
    "timestamp": "2025-06-12T11:47:52.698944+05",
    "log": "[JobID: 4f6df5a4] Execution completed | Status: SUCCESS | Output file: 'sorted_countries61.csv' | Source: Glue | Timestamp: 2025-06-12T11:47:52.698944+05"
  },
  {
    "job_id": "15d229f8",
    "source": "Airflow",
    "filename": "countries98.csv",
    "output_file": null,
    "status": "PENDING",
    "timestamp": "2025-06-12T11:47:53.698944+05",
    "log": "[JobID: 15d229f8] Status update | Status: PENDING | Source: Airflow | Timestamp: 2025-06-12T11:47:53.698944+05"
  },
  {
    "job_id": "2e951216",
    "source": "Hadoop",
    "filename": "countries28.csv",
    "output_file": null,
    "status": "RUNNING",
    "timestamp": "2025-06-12T11:47:55.698944+05",
    "log": "[JobID: 2e951216] Status update | Status: RUNNING | Source: Hadoop | Timestamp: 2025-06-12T11:47:55.698944+05"
  },
  {
    "job_id": "6bb9c57f",
    "source": "Glue",
    "filename": "countries8.csv",
    "output_file": null,
    "status": "FAILED",
    "timestamp": "2025-06-12T11:47:56.698944+05",
    "log": "[JobID: 6bb9c57f] Execution failed | Status: FAILED | Error: org.apache.kafka.common.errors.AuthenticationException: The broker requires authentication | Source: Glue | Timestamp: 2025-06-12T11:47:56.698944+05\norg.apache.kafka.common.errors.AuthenticationException: The broker requires authentication\n\tat org.apache.kafka.clients.NetworkClient.initiateHandshake(NetworkClient.java:450)\n\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:45)"
  }
]